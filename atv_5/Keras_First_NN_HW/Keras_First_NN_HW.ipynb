{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Keras_First_NN_HW.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzDW3aHSS388"
      },
      "source": [
        "## Using Keras to Build and Train Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZcGBEd9S39C"
      },
      "source": [
        "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
        "\n",
        "## UCI Pima Diabetes Dataset\n",
        "\n",
        "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
        "\n",
        "\n",
        "### Attributes: (all numeric-valued)\n",
        "   1. Number of times pregnant\n",
        "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "   3. Diastolic blood pressure (mm Hg)\n",
        "   4. Triceps skin fold thickness (mm)\n",
        "   5. 2-Hour serum insulin (mu U/ml)\n",
        "   6. Body mass index (weight in kg/(height in m)^2)\n",
        "   7. Diabetes pedigree function\n",
        "   8. Age (years)\n",
        "   9. Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4tTxbjZS39D"
      },
      "source": [
        "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySbF2p0MS39D"
      },
      "source": [
        "#Preliminaries\n",
        "\n",
        "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmkVQMq1S39E"
      },
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUQCAEceS39F"
      },
      "source": [
        "## Load in the data set (Internet Access needed)\n",
        "\n",
        "##url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv('pima-indians-diabetes.data', names=names)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEUEJI19S39G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "9486ed49-0178-4378-ffe5-e7021f073de0"
      },
      "source": [
        "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>3</td>\n",
              "      <td>180</td>\n",
              "      <td>64</td>\n",
              "      <td>25</td>\n",
              "      <td>70</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.271</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>8</td>\n",
              "      <td>74</td>\n",
              "      <td>70</td>\n",
              "      <td>40</td>\n",
              "      <td>49</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.705</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>8</td>\n",
              "      <td>154</td>\n",
              "      <td>78</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>32.4</td>\n",
              "      <td>0.443</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>1</td>\n",
              "      <td>79</td>\n",
              "      <td>80</td>\n",
              "      <td>25</td>\n",
              "      <td>37</td>\n",
              "      <td>25.4</td>\n",
              "      <td>0.583</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>64</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>29.7</td>\n",
              "      <td>0.368</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  ...  age  has_diabetes\n",
              "40                3                     180  ...   26             0\n",
              "462               8                      74  ...   39             0\n",
              "754               8                     154  ...   45             1\n",
              "232               1                      79  ...   22             0\n",
              "163               2                     100  ...   21             0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hVVqkavS39G"
      },
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVvGrsnjS39H"
      },
      "source": [
        "# Split the data to Train, and Test (75%, 25%)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzZSZtrxS39H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b257df8f-08d7-4036-c234-5ad874ff3941"
      },
      "source": [
        "np.mean(y), np.mean(1-y)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZOK4fjNS39H"
      },
      "source": [
        "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
        "## Exercise: Get a baseline performance using Random Forest\n",
        "To begin, and get a baseline for classifier performance:\n",
        "1. Train a Random Forest model with 200 trees on the training data.\n",
        "2. Calculate the accuracy and roc_auc_score of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ_bZB67S39I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061d30e9-6e42-43cf-ee23-51b9ec9789a7"
      },
      "source": [
        "## Train the RF Model\n",
        "rf_model = RandomForestClassifier(n_estimators=200)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmTfTXs3S39I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd239eb-0968-4952-c714-c6ea5a371c5f"
      },
      "source": [
        "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
        "y_pred_class_rf = rf_model.predict(X_test)\n",
        "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
        "\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy is 0.771\n",
            "roc-auc is 0.832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw0PrlGPS39I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "fab5395e-958a-4d98-c675-6222f139a324"
      },
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYzWU4z4S39J"
      },
      "source": [
        "## Build a Single Hidden Layer Neural Network\n",
        "\n",
        "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQr8jwlsS39J"
      },
      "source": [
        "## First let's normalize the data\n",
        "## This aids the training of neural nets by providing numerical stability\n",
        "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
        "\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3rvFpL-S39J"
      },
      "source": [
        "# Define the Model \n",
        "# Input size is 8-dimensional\n",
        "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
        "\n",
        "model_1 = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlbl2lV4S39K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c14e5b-4907-4c47-8c2c-5dc85a2fad9e"
      },
      "source": [
        "#  This is a nice tool to view the model you have created and count the parameters\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_13 (Dense)             (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvkspPWCS39K"
      },
      "source": [
        "### Comprehension question:\n",
        "Why do we have 121 parameters?  Does that make sense?\n",
        "\n",
        "\n",
        "Let's fit our model for 200 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkDUyV9ZS39K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58c4fe4-f8c1-4b9c-a1f9-66e9a7b7ee8c"
      },
      "source": [
        "# Fit(Train) the Model\n",
        "\n",
        "# Compile the model with Optimizer, Loss Function and Metrics\n",
        "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
        "\n",
        "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
        "# the fit function returns the run history. \n",
        "# It is very convenient, as it contains information about the model fit, iterations etc."
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.7406 - accuracy: 0.4955 - val_loss: 0.7021 - val_accuracy: 0.4896\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7012 - accuracy: 0.5299 - val_loss: 0.6945 - val_accuracy: 0.5104\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7252 - accuracy: 0.4714 - val_loss: 0.6874 - val_accuracy: 0.5208\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.5636 - val_loss: 0.6808 - val_accuracy: 0.5365\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.5796 - val_loss: 0.6745 - val_accuracy: 0.5521\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5782 - val_loss: 0.6687 - val_accuracy: 0.5625\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.5874 - val_loss: 0.6631 - val_accuracy: 0.5729\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.6026 - val_loss: 0.6579 - val_accuracy: 0.5885\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.5759 - val_loss: 0.6529 - val_accuracy: 0.5990\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.6078 - val_loss: 0.6482 - val_accuracy: 0.6094\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.6418 - val_loss: 0.6438 - val_accuracy: 0.6094\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.6588 - val_loss: 0.6395 - val_accuracy: 0.6354\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.6519 - val_loss: 0.6355 - val_accuracy: 0.6510\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.6232 - val_loss: 0.6317 - val_accuracy: 0.6510\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6524 - val_loss: 0.6281 - val_accuracy: 0.6510\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.6477 - val_loss: 0.6246 - val_accuracy: 0.6615\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6732 - val_loss: 0.6213 - val_accuracy: 0.6719\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.6967 - val_loss: 0.6181 - val_accuracy: 0.6719\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.7081 - val_loss: 0.6152 - val_accuracy: 0.6667\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.6876 - val_loss: 0.6123 - val_accuracy: 0.6667\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6226 - accuracy: 0.6877 - val_loss: 0.6096 - val_accuracy: 0.6719\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.6883 - val_loss: 0.6070 - val_accuracy: 0.6823\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.6788 - val_loss: 0.6045 - val_accuracy: 0.6875\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6869 - val_loss: 0.6021 - val_accuracy: 0.6823\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.6870 - val_loss: 0.5998 - val_accuracy: 0.6927\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.7344 - val_loss: 0.5976 - val_accuracy: 0.7031\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7131 - val_loss: 0.5955 - val_accuracy: 0.6979\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.7410 - val_loss: 0.5935 - val_accuracy: 0.6979\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.6889 - val_loss: 0.5915 - val_accuracy: 0.7083\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.7089 - val_loss: 0.5896 - val_accuracy: 0.7031\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.7260 - val_loss: 0.5878 - val_accuracy: 0.7083\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.7189 - val_loss: 0.5860 - val_accuracy: 0.7083\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7140 - val_loss: 0.5843 - val_accuracy: 0.7083\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.6967 - val_loss: 0.5826 - val_accuracy: 0.7083\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7349 - val_loss: 0.5810 - val_accuracy: 0.7135\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.7176 - val_loss: 0.5794 - val_accuracy: 0.7135\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7464 - val_loss: 0.5778 - val_accuracy: 0.7135\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7024 - val_loss: 0.5763 - val_accuracy: 0.7135\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.6979 - val_loss: 0.5748 - val_accuracy: 0.7188\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7205 - val_loss: 0.5733 - val_accuracy: 0.7188\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7233 - val_loss: 0.5719 - val_accuracy: 0.7240\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7183 - val_loss: 0.5705 - val_accuracy: 0.7240\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7415 - val_loss: 0.5692 - val_accuracy: 0.7240\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7151 - val_loss: 0.5679 - val_accuracy: 0.7240\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7111 - val_loss: 0.5666 - val_accuracy: 0.7240\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.7122 - val_loss: 0.5654 - val_accuracy: 0.7240\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7401 - val_loss: 0.5642 - val_accuracy: 0.7240\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7295 - val_loss: 0.5630 - val_accuracy: 0.7240\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.7031 - val_loss: 0.5619 - val_accuracy: 0.7240\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7377 - val_loss: 0.5607 - val_accuracy: 0.7240\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7146 - val_loss: 0.5596 - val_accuracy: 0.7240\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7406 - val_loss: 0.5586 - val_accuracy: 0.7188\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7258 - val_loss: 0.5575 - val_accuracy: 0.7188\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7447 - val_loss: 0.5565 - val_accuracy: 0.7188\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7582 - val_loss: 0.5555 - val_accuracy: 0.7188\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7350 - val_loss: 0.5546 - val_accuracy: 0.7135\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7247 - val_loss: 0.5536 - val_accuracy: 0.7083\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7360 - val_loss: 0.5527 - val_accuracy: 0.7083\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7441 - val_loss: 0.5518 - val_accuracy: 0.7083\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7450 - val_loss: 0.5509 - val_accuracy: 0.7083\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7300 - val_loss: 0.5500 - val_accuracy: 0.7083\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7399 - val_loss: 0.5492 - val_accuracy: 0.7135\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7382 - val_loss: 0.5483 - val_accuracy: 0.7135\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.6959 - val_loss: 0.5475 - val_accuracy: 0.7135\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7355 - val_loss: 0.5467 - val_accuracy: 0.7188\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7376 - val_loss: 0.5459 - val_accuracy: 0.7188\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7329 - val_loss: 0.5451 - val_accuracy: 0.7188\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7120 - val_loss: 0.5443 - val_accuracy: 0.7240\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7128 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7320 - val_loss: 0.5428 - val_accuracy: 0.7292\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7425 - val_loss: 0.5421 - val_accuracy: 0.7292\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7138 - val_loss: 0.5414 - val_accuracy: 0.7448\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7268 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7228 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7472 - val_loss: 0.5394 - val_accuracy: 0.7448\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7408 - val_loss: 0.5387 - val_accuracy: 0.7448\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7158 - val_loss: 0.5380 - val_accuracy: 0.7448\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7354 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7747 - val_loss: 0.5368 - val_accuracy: 0.7448\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7678 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7239 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7558 - val_loss: 0.5351 - val_accuracy: 0.7448\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7553 - val_loss: 0.5346 - val_accuracy: 0.7448\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7304 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7643 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7495 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7541 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7581 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7753 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7415 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7550 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7661 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7589 - val_loss: 0.5296 - val_accuracy: 0.7500\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7277 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7487 - val_loss: 0.5287 - val_accuracy: 0.7396\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7358 - val_loss: 0.5282 - val_accuracy: 0.7396\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7847 - val_loss: 0.5278 - val_accuracy: 0.7448\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7104 - val_loss: 0.5273 - val_accuracy: 0.7448\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7551 - val_loss: 0.5269 - val_accuracy: 0.7448\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7397 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7484 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7613 - val_loss: 0.5256 - val_accuracy: 0.7448\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7724 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7631 - val_loss: 0.5248 - val_accuracy: 0.7448\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7613 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7742 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7767 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7644 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7310 - val_loss: 0.5229 - val_accuracy: 0.7396\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7773 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7422 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7539 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7738 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7494 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7647 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7769 - val_loss: 0.5205 - val_accuracy: 0.7448\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7467 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7738 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7435 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7638 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7624 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7377 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7589 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7609 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7657 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7587 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7410 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7937 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7510 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7745 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7782 - val_loss: 0.5160 - val_accuracy: 0.7500\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7608 - val_loss: 0.5158 - val_accuracy: 0.7500\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7784 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7387 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7741 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7417 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7421 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7619 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7769 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7661 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7845 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7692 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.7459 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7689 - val_loss: 0.5131 - val_accuracy: 0.7500\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7391 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7525 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7667 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7607 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7660 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7677 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7672 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7678 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7523 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.7683 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7455 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7816 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7716 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7481 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7945 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7591 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7898 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7627 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7836 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7924 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7670 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7678 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7708 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7632 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7631 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7869 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7792 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7875 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7735 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7779 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7880 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7741 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7685 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7633 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7818 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7649 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7942 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7714 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7680 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7741 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7547 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7447 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7493 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7486 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7642 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7976 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7695 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7763 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7517 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7501 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7859 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7668 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7706 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.7764 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7825 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7657 - val_loss: 0.5071 - val_accuracy: 0.7656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHIvIi-9S39L"
      },
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
        "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siS4x34MS39L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104691a9-85fa-4ab1-8edf-d9e8da5dcab0"
      },
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Gx_uPMS39M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca1753e-9ed2-4b9c-f277-011d749e9bc3"
      },
      "source": [
        "y_pred_prob_nn_1[:10]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.46318468],\n",
              "       [0.5891896 ],\n",
              "       [0.2817614 ],\n",
              "       [0.309277  ],\n",
              "       [0.19577691],\n",
              "       [0.5088138 ],\n",
              "       [0.0408552 ],\n",
              "       [0.22239089],\n",
              "       [0.7761401 ],\n",
              "       [0.19161904]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JklKOLtsS39M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "f35a7a00-ca03-454a-b5a6-f6e6d01c2736"
      },
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy is 0.766\n",
            "roc-auc is 0.815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZLTwA1rS39M"
      },
      "source": [
        "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLQYE7oDS39N"
      },
      "source": [
        "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibfTJ2fZS39N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd21e5c-bfbd-4a34-9a96-d0f8eb9f773e"
      },
      "source": [
        "run_hist_1.history.keys()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0u-ANKYS39N"
      },
      "source": [
        "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxC1HYFsS39N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "bb9a55c7-cc69-4880-f576-b9e8e55f48d4"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7e5c946990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7hIE_WSS39O"
      },
      "source": [
        "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WgNDscc7S39O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d202dfef-c02c-4c71-cf06-995d294dc8b6"
      },
      "source": [
        "## Note that when we call \"fit\" again, it picks up where it left off\n",
        "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.7691 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7674 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7656 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7656 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7656 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7656 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7656 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7656 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7656 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7656 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7656 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7656 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7656 - val_loss: 0.5067 - val_accuracy: 0.7760\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7656 - val_loss: 0.5067 - val_accuracy: 0.7760\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7656 - val_loss: 0.5067 - val_accuracy: 0.7760\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7656 - val_loss: 0.5066 - val_accuracy: 0.7760\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7656 - val_loss: 0.5066 - val_accuracy: 0.7760\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7622 - val_loss: 0.5066 - val_accuracy: 0.7760\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7622 - val_loss: 0.5066 - val_accuracy: 0.7760\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7622 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7604 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7622 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7604 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7604 - val_loss: 0.5064 - val_accuracy: 0.7760\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7587 - val_loss: 0.5064 - val_accuracy: 0.7812\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7604 - val_loss: 0.5064 - val_accuracy: 0.7812\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7587 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7604 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7587 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7604 - val_loss: 0.5062 - val_accuracy: 0.7865\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7587 - val_loss: 0.5062 - val_accuracy: 0.7865\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7604 - val_loss: 0.5062 - val_accuracy: 0.7865\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7604 - val_loss: 0.5061 - val_accuracy: 0.7812\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7604 - val_loss: 0.5061 - val_accuracy: 0.7812\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7604 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7604 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7604 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7587 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7604 - val_loss: 0.5059 - val_accuracy: 0.7760\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7604 - val_loss: 0.5059 - val_accuracy: 0.7760\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7604 - val_loss: 0.5058 - val_accuracy: 0.7760\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7604 - val_loss: 0.5058 - val_accuracy: 0.7760\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7604 - val_loss: 0.5058 - val_accuracy: 0.7760\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7604 - val_loss: 0.5057 - val_accuracy: 0.7760\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7639 - val_loss: 0.5057 - val_accuracy: 0.7760\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7656 - val_loss: 0.5057 - val_accuracy: 0.7760\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7674 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7656 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7674 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7674 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7674 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7708 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7708 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7708 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7708 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7708 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7691 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7691 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7691 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7691 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7691 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7726 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7726 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7726 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7726 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7760 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7743 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7743 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7743 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7795 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7778 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7795 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7795 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7795 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7795 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7795 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7795 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7795 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7795 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7795 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7778 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7726 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7726 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7726 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7726 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7726 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7708 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7760 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7812\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7812\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7812\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7812\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7812\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7812\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7812\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7812\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7812\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7812\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7812\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7812\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7760 - val_loss: 0.5057 - val_accuracy: 0.7812\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7760 - val_loss: 0.5058 - val_accuracy: 0.7812\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.5058 - val_accuracy: 0.7812\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.5058 - val_accuracy: 0.7812\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7760 - val_loss: 0.5058 - val_accuracy: 0.7812\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7760 - val_loss: 0.5058 - val_accuracy: 0.7812\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7760 - val_loss: 0.5058 - val_accuracy: 0.7812\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7760 - val_loss: 0.5058 - val_accuracy: 0.7812\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7760 - val_loss: 0.5058 - val_accuracy: 0.7812\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7760 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7743 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.7760 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7760 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7760 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7760 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7760 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7812\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7760 - val_loss: 0.5061 - val_accuracy: 0.7812\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7760 - val_loss: 0.5061 - val_accuracy: 0.7812\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7812\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7812\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7760 - val_loss: 0.5061 - val_accuracy: 0.7812\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7760\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7760\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7760\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7743 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7743 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7743 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7743 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7726 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7743 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7743 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7726 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7760 - val_loss: 0.5062 - val_accuracy: 0.7812\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7726 - val_loss: 0.5062 - val_accuracy: 0.7812\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7726 - val_loss: 0.5062 - val_accuracy: 0.7812\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7726 - val_loss: 0.5062 - val_accuracy: 0.7812\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7743 - val_loss: 0.5062 - val_accuracy: 0.7812\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7726 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7743 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7726 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7743 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7743 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7743 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7708 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7726 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7743 - val_loss: 0.5063 - val_accuracy: 0.7865\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7708 - val_loss: 0.5064 - val_accuracy: 0.7865\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7726 - val_loss: 0.5064 - val_accuracy: 0.7865\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7726 - val_loss: 0.5064 - val_accuracy: 0.7865\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7726 - val_loss: 0.5064 - val_accuracy: 0.7865\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7743 - val_loss: 0.5064 - val_accuracy: 0.7865\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7726 - val_loss: 0.5064 - val_accuracy: 0.7865\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7726 - val_loss: 0.5064 - val_accuracy: 0.7865\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7726 - val_loss: 0.5064 - val_accuracy: 0.7865\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7726 - val_loss: 0.5064 - val_accuracy: 0.7865\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7743 - val_loss: 0.5065 - val_accuracy: 0.7865\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7726 - val_loss: 0.5065 - val_accuracy: 0.7917\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7726 - val_loss: 0.5065 - val_accuracy: 0.7917\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7726 - val_loss: 0.5065 - val_accuracy: 0.7969\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7726 - val_loss: 0.5065 - val_accuracy: 0.7969\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7726 - val_loss: 0.5065 - val_accuracy: 0.7969\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7726 - val_loss: 0.5065 - val_accuracy: 0.7969\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7743 - val_loss: 0.5065 - val_accuracy: 0.7969\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7726 - val_loss: 0.5065 - val_accuracy: 0.7969\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7726 - val_loss: 0.5066 - val_accuracy: 0.7969\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7726 - val_loss: 0.5066 - val_accuracy: 0.7969\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7726 - val_loss: 0.5066 - val_accuracy: 0.7969\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7726 - val_loss: 0.5066 - val_accuracy: 0.7969\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7743 - val_loss: 0.5066 - val_accuracy: 0.7969\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7743 - val_loss: 0.5066 - val_accuracy: 0.7969\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7743 - val_loss: 0.5067 - val_accuracy: 0.7969\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.5067 - val_accuracy: 0.7969\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.5067 - val_accuracy: 0.7969\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7760 - val_loss: 0.5067 - val_accuracy: 0.7969\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5067 - val_accuracy: 0.7969\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5067 - val_accuracy: 0.7969\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7760 - val_loss: 0.5067 - val_accuracy: 0.7969\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7969\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7778 - val_loss: 0.5068 - val_accuracy: 0.7969\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7795 - val_loss: 0.5068 - val_accuracy: 0.7969\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.5068 - val_accuracy: 0.7969\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5068 - val_accuracy: 0.7969\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5068 - val_accuracy: 0.7969\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.5068 - val_accuracy: 0.7969\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7795 - val_loss: 0.5069 - val_accuracy: 0.7969\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.5069 - val_accuracy: 0.7969\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7795 - val_loss: 0.5069 - val_accuracy: 0.7969\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.5069 - val_accuracy: 0.7969\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7812 - val_loss: 0.5069 - val_accuracy: 0.7969\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7795 - val_loss: 0.5069 - val_accuracy: 0.7969\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5069 - val_accuracy: 0.7969\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5070 - val_accuracy: 0.7969\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.5070 - val_accuracy: 0.7969\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.5070 - val_accuracy: 0.7969\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7795 - val_loss: 0.5070 - val_accuracy: 0.7969\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.5070 - val_accuracy: 0.7969\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.5070 - val_accuracy: 0.7969\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5070 - val_accuracy: 0.7969\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7969\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7795 - val_loss: 0.5071 - val_accuracy: 0.7969\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7969\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7969\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7969\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7969\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7969\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7969\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7969\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7969\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7969\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7969\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7969\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7969\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7969\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7969\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7969\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7969\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7969\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7969\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7969\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7969\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7969\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7969\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7969\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7969\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7969\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7969\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7969\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7969\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7969\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7969\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5076 - val_accuracy: 0.7969\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.5076 - val_accuracy: 0.7969\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5076 - val_accuracy: 0.7969\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7795 - val_loss: 0.5076 - val_accuracy: 0.7969\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.5076 - val_accuracy: 0.7969\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5076 - val_accuracy: 0.7969\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5077 - val_accuracy: 0.7969\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.5077 - val_accuracy: 0.7969\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7795 - val_loss: 0.5077 - val_accuracy: 0.7969\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7795 - val_loss: 0.5077 - val_accuracy: 0.7969\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7795 - val_loss: 0.5077 - val_accuracy: 0.7969\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7795 - val_loss: 0.5077 - val_accuracy: 0.7969\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7795 - val_loss: 0.5078 - val_accuracy: 0.7969\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7795 - val_loss: 0.5078 - val_accuracy: 0.7969\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7795 - val_loss: 0.5078 - val_accuracy: 0.7969\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7795 - val_loss: 0.5078 - val_accuracy: 0.7969\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7795 - val_loss: 0.5078 - val_accuracy: 0.7969\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7795 - val_loss: 0.5079 - val_accuracy: 0.7969\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7795 - val_loss: 0.5079 - val_accuracy: 0.7969\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7795 - val_loss: 0.5079 - val_accuracy: 0.7969\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7795 - val_loss: 0.5079 - val_accuracy: 0.7969\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7795 - val_loss: 0.5079 - val_accuracy: 0.7969\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7795 - val_loss: 0.5079 - val_accuracy: 0.7969\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7795 - val_loss: 0.5080 - val_accuracy: 0.7969\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7795 - val_loss: 0.5080 - val_accuracy: 0.7969\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7795 - val_loss: 0.5080 - val_accuracy: 0.7969\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7795 - val_loss: 0.5080 - val_accuracy: 0.7969\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7795 - val_loss: 0.5080 - val_accuracy: 0.7969\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7795 - val_loss: 0.5080 - val_accuracy: 0.7969\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7795 - val_loss: 0.5081 - val_accuracy: 0.7917\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7795 - val_loss: 0.5081 - val_accuracy: 0.7917\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7795 - val_loss: 0.5081 - val_accuracy: 0.7917\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7795 - val_loss: 0.5081 - val_accuracy: 0.7917\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7795 - val_loss: 0.5081 - val_accuracy: 0.7917\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.5081 - val_accuracy: 0.7917\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.5082 - val_accuracy: 0.7917\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.5082 - val_accuracy: 0.7917\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.5082 - val_accuracy: 0.7917\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.5082 - val_accuracy: 0.7917\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.5082 - val_accuracy: 0.7917\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.5082 - val_accuracy: 0.7917\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.5082 - val_accuracy: 0.7917\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7795 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7795 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7795 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7778 - val_loss: 0.5084 - val_accuracy: 0.7917\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7778 - val_loss: 0.5085 - val_accuracy: 0.7917\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7778 - val_loss: 0.5085 - val_accuracy: 0.7917\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7778 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7778 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7778 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7778 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7778 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7778 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7795 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7795 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7795 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7795 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7812 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.8021\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7847 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7969\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7969\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7969\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7969\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7969\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7969\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7969\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7969\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7969\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7969\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7969\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7969\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7969\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7969\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7969\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7969\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7969\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7969\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7969\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7969\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7969\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7969\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7969\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7969\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7969\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7969\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7969\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7969\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7969\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7969\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7969\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.5090 - val_accuracy: 0.7969\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7969\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7969\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7969\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7969\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7969\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7865 - val_loss: 0.5091 - val_accuracy: 0.7969\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7969\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7969\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7969\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7969\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7865 - val_loss: 0.5092 - val_accuracy: 0.7969\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7969\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7969\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7969\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7865 - val_loss: 0.5093 - val_accuracy: 0.7969\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7969\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7969\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7969\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7969\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7865 - val_loss: 0.5094 - val_accuracy: 0.7969\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7865 - val_loss: 0.5095 - val_accuracy: 0.7969\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7865 - val_loss: 0.5095 - val_accuracy: 0.7969\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7865 - val_loss: 0.5095 - val_accuracy: 0.7969\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7865 - val_loss: 0.5095 - val_accuracy: 0.7969\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7865 - val_loss: 0.5095 - val_accuracy: 0.7969\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7969\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7969\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7969\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7969\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7865 - val_loss: 0.5096 - val_accuracy: 0.7969\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7969\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7969\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7969\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7969\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7865 - val_loss: 0.5097 - val_accuracy: 0.7969\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7969\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7969\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7969\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7865 - val_loss: 0.5098 - val_accuracy: 0.7969\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7969\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7969\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7969\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7969\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7865 - val_loss: 0.5099 - val_accuracy: 0.7969\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7969\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7969\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7969\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7969\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7969\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7969\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7969\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7969\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7969\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7969\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7969\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7969\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7969\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7969\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7969\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7969\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7969\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7969\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7969\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7969\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7969\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7969\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7969\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7969\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7969\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7969\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7969\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7969\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7969\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7969\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7969\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7969\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7969\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7969\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7969\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7969\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7969\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7969\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7969\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7969\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7969\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7969\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7969\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7969\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7969\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7969\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7969\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7969\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7969\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7969\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7969\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7969\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7969\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7969\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7969\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7969\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7969\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7969\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7969\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7969\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7969\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7969\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7969\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7969\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7969\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7969\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7969\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7969\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7969\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7969\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7969\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7969\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7969\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7969\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7969\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7969\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7969\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7969\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7969\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7969\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7969\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7969\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7969\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7969\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7969\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7969\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7969\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7969\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7969\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7969\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.5113 - val_accuracy: 0.7969\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7969\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7969\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7969\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7969\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7969\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7969\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7969\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7969\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7899 - val_loss: 0.5114 - val_accuracy: 0.7969\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7917\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7917\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7917\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7917\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7917\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7917\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7899 - val_loss: 0.5115 - val_accuracy: 0.7917\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7917\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7917\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7917\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7917\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7917\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7917\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7917\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5116 - val_accuracy: 0.7917\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7917\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7917\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7917\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7917\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7917\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7917\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7899 - val_loss: 0.5117 - val_accuracy: 0.7917\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7917\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7917\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7917\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7917\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7917\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7917\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7899 - val_loss: 0.5118 - val_accuracy: 0.7917\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7899 - val_loss: 0.5119 - val_accuracy: 0.7917\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7917\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7917\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7917\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7917\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7917\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7917 - val_loss: 0.5119 - val_accuracy: 0.7917\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7917\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7917\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7917\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7917\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.5120 - val_accuracy: 0.7917\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7917\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7917\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7917 - val_loss: 0.5121 - val_accuracy: 0.7917\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7917\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.5121 - val_accuracy: 0.7917\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7917 - val_loss: 0.5122 - val_accuracy: 0.7917\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5122 - val_accuracy: 0.7917\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5122 - val_accuracy: 0.7865\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5122 - val_accuracy: 0.7865\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5122 - val_accuracy: 0.7865\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5123 - val_accuracy: 0.7865\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5123 - val_accuracy: 0.7865\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5123 - val_accuracy: 0.7865\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5123 - val_accuracy: 0.7865\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5123 - val_accuracy: 0.7865\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5123 - val_accuracy: 0.7865\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7917 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7917 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7917 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7917 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7917 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7917 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5124 - val_accuracy: 0.7865\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7865\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7865\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7865\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7865\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7865\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7865\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7865\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7917\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7917\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7917\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7917\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5125 - val_accuracy: 0.7917\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7917\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7917 - val_loss: 0.5125 - val_accuracy: 0.7917\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7917\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7917 - val_loss: 0.5126 - val_accuracy: 0.7917\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7917 - val_loss: 0.5126 - val_accuracy: 0.7917\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7917 - val_loss: 0.5126 - val_accuracy: 0.7917\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7917 - val_loss: 0.5126 - val_accuracy: 0.7917\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7917 - val_loss: 0.5126 - val_accuracy: 0.7917\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7917 - val_loss: 0.5126 - val_accuracy: 0.7917\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7917 - val_loss: 0.5126 - val_accuracy: 0.7917\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7917 - val_loss: 0.5126 - val_accuracy: 0.7917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpTHYvyaS39Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "d3d568cb-2b50-40c5-b1bc-8fd887ce532d"
      },
      "source": [
        "n = len(run_hist_1.history[\"loss\"])\n",
        "m = len(run_hist_1b.history['loss'])\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
        "\n",
        "ax.legend()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7e535d1d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqzkOi9YS39R"
      },
      "source": [
        "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CoFgAqm-S39R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fCEp142vS39R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLiaKjjUS39S"
      },
      "source": [
        "## Exercise\n",
        "Now it's your turn.  Do the following in the cells below:\n",
        "- Build a model with two hidden layers, each with 6 nodes\n",
        "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "- Use a learning rate of .003 and train for 1500 epochs\n",
        "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "- Plot the roc curve for the predictions\n",
        "\n",
        "Experiment with different learning rates, numbers of epochs, and network structures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Ukz0re5fS39S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b36664-1de8-47aa-b688-e888a77659bb"
      },
      "source": [
        "# Input size is 8-dimensional\n",
        "# 2 hidden layer, 6 hidden nodes, sigmoid activation\n",
        "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
        "\n",
        "model_2 = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model_2.summary()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 6)                 54        \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 103\n",
            "Trainable params: 103\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rSPOpYx2S39S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e029dec1-edca-4741-a1d6-a4c219af14d0"
      },
      "source": [
        "# treinando o novo modelo\n",
        "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)\n",
        "\n",
        "# preparando para plot e validando para ver se o keras corretamente\n",
        "y_pred_class_nn_1 = model_2.predict_classes(X_test_norm)\n",
        "y_pred_prob_nn_1 = model_2.predict(X_test_norm)\n",
        "y_pred_class_nn_1[:10]\n",
        "y_pred_prob_nn_1[:10]\n",
        "# exibindo a performance do modelo e a curva ROC\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 12ms/step - loss: 0.7337 - accuracy: 0.5239 - val_loss: 0.7440 - val_accuracy: 0.5365\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7414 - accuracy: 0.5265 - val_loss: 0.7393 - val_accuracy: 0.5573\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7276 - accuracy: 0.5372 - val_loss: 0.7348 - val_accuracy: 0.6042\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7105 - accuracy: 0.6303 - val_loss: 0.7304 - val_accuracy: 0.6354\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.6318 - val_loss: 0.7262 - val_accuracy: 0.6510\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7207 - accuracy: 0.5909 - val_loss: 0.7221 - val_accuracy: 0.6562\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7200 - accuracy: 0.6111 - val_loss: 0.7182 - val_accuracy: 0.6562\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6532 - val_loss: 0.7144 - val_accuracy: 0.6667\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7072 - accuracy: 0.6174 - val_loss: 0.7107 - val_accuracy: 0.6719\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.6495 - val_loss: 0.7072 - val_accuracy: 0.6615\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.6503 - val_loss: 0.7038 - val_accuracy: 0.6667\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6955 - accuracy: 0.6137 - val_loss: 0.7005 - val_accuracy: 0.6719\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.6278 - val_loss: 0.6973 - val_accuracy: 0.6771\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6978 - accuracy: 0.6487 - val_loss: 0.6942 - val_accuracy: 0.6771\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.6455 - val_loss: 0.6912 - val_accuracy: 0.6823\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.6413 - val_loss: 0.6882 - val_accuracy: 0.6927\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6823 - accuracy: 0.6754 - val_loss: 0.6853 - val_accuracy: 0.6927\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6753 - accuracy: 0.6501 - val_loss: 0.6825 - val_accuracy: 0.6875\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.6743 - val_loss: 0.6798 - val_accuracy: 0.6927\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.6626 - val_loss: 0.6772 - val_accuracy: 0.6927\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.6781 - val_loss: 0.6746 - val_accuracy: 0.6927\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6711 - accuracy: 0.6513 - val_loss: 0.6721 - val_accuracy: 0.6927\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.6564 - val_loss: 0.6696 - val_accuracy: 0.6927\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.6891 - val_loss: 0.6672 - val_accuracy: 0.6979\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.6921 - val_loss: 0.6649 - val_accuracy: 0.6979\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.7016 - val_loss: 0.6626 - val_accuracy: 0.7031\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.6632 - val_loss: 0.6604 - val_accuracy: 0.7031\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6700 - val_loss: 0.6581 - val_accuracy: 0.7031\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6444 - accuracy: 0.7051 - val_loss: 0.6560 - val_accuracy: 0.7031\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6482 - accuracy: 0.6814 - val_loss: 0.6539 - val_accuracy: 0.7031\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.6899 - val_loss: 0.6519 - val_accuracy: 0.6979\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.6929 - val_loss: 0.6499 - val_accuracy: 0.6979\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.6671 - val_loss: 0.6480 - val_accuracy: 0.6979\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.7008 - val_loss: 0.6461 - val_accuracy: 0.7031\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6871 - val_loss: 0.6443 - val_accuracy: 0.7031\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.6966 - val_loss: 0.6424 - val_accuracy: 0.7083\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6607 - val_loss: 0.6406 - val_accuracy: 0.7083\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.6662 - val_loss: 0.6388 - val_accuracy: 0.7083\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.7060 - val_loss: 0.6371 - val_accuracy: 0.7083\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6866 - val_loss: 0.6353 - val_accuracy: 0.7083\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.6859 - val_loss: 0.6336 - val_accuracy: 0.7135\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.7070 - val_loss: 0.6319 - val_accuracy: 0.7135\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.6952 - val_loss: 0.6303 - val_accuracy: 0.7135\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.6921 - val_loss: 0.6287 - val_accuracy: 0.7188\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.6621 - val_loss: 0.6271 - val_accuracy: 0.7240\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.6749 - val_loss: 0.6256 - val_accuracy: 0.7240\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.6842 - val_loss: 0.6240 - val_accuracy: 0.7240\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.6806 - val_loss: 0.6225 - val_accuracy: 0.7240\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.6628 - val_loss: 0.6210 - val_accuracy: 0.7240\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.6983 - val_loss: 0.6195 - val_accuracy: 0.7240\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6042 - accuracy: 0.7097 - val_loss: 0.6181 - val_accuracy: 0.7240\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.6962 - val_loss: 0.6167 - val_accuracy: 0.7240\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.6907 - val_loss: 0.6152 - val_accuracy: 0.7240\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6746 - val_loss: 0.6138 - val_accuracy: 0.7240\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6745 - val_loss: 0.6125 - val_accuracy: 0.7240\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.7110 - val_loss: 0.6111 - val_accuracy: 0.7240\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.7176 - val_loss: 0.6097 - val_accuracy: 0.7240\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7318 - val_loss: 0.6084 - val_accuracy: 0.7240\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.7289 - val_loss: 0.6071 - val_accuracy: 0.7240\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5998 - accuracy: 0.7226 - val_loss: 0.6058 - val_accuracy: 0.7240\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6984 - val_loss: 0.6045 - val_accuracy: 0.7240\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.7246 - val_loss: 0.6032 - val_accuracy: 0.7292\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.7251 - val_loss: 0.6020 - val_accuracy: 0.7344\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.6994 - val_loss: 0.6008 - val_accuracy: 0.7344\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.6961 - val_loss: 0.5996 - val_accuracy: 0.7344\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6920 - val_loss: 0.5984 - val_accuracy: 0.7344\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.6926 - val_loss: 0.5973 - val_accuracy: 0.7344\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.6922 - val_loss: 0.5961 - val_accuracy: 0.7344\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.7029 - val_loss: 0.5950 - val_accuracy: 0.7344\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.7179 - val_loss: 0.5939 - val_accuracy: 0.7344\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.6928 - val_loss: 0.5927 - val_accuracy: 0.7344\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.7205 - val_loss: 0.5916 - val_accuracy: 0.7344\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7334 - val_loss: 0.5906 - val_accuracy: 0.7344\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.7008 - val_loss: 0.5895 - val_accuracy: 0.7344\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.6817 - val_loss: 0.5885 - val_accuracy: 0.7344\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.7009 - val_loss: 0.5874 - val_accuracy: 0.7344\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.7308 - val_loss: 0.5863 - val_accuracy: 0.7344\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.7242 - val_loss: 0.5853 - val_accuracy: 0.7344\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.7119 - val_loss: 0.5843 - val_accuracy: 0.7344\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7200 - val_loss: 0.5833 - val_accuracy: 0.7344\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7081 - val_loss: 0.5823 - val_accuracy: 0.7396\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7314 - val_loss: 0.5813 - val_accuracy: 0.7396\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7388 - val_loss: 0.5803 - val_accuracy: 0.7396\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.6989 - val_loss: 0.5793 - val_accuracy: 0.7396\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7112 - val_loss: 0.5784 - val_accuracy: 0.7396\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.7039 - val_loss: 0.5774 - val_accuracy: 0.7396\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7312 - val_loss: 0.5765 - val_accuracy: 0.7396\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7221 - val_loss: 0.5756 - val_accuracy: 0.7448\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7179 - val_loss: 0.5746 - val_accuracy: 0.7448\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5664 - accuracy: 0.7185 - val_loss: 0.5737 - val_accuracy: 0.7500\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.7334 - val_loss: 0.5728 - val_accuracy: 0.7500\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6792 - val_loss: 0.5718 - val_accuracy: 0.7500\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7230 - val_loss: 0.5709 - val_accuracy: 0.7500\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.7095 - val_loss: 0.5700 - val_accuracy: 0.7500\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.6921 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.7092 - val_loss: 0.5683 - val_accuracy: 0.7500\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.7288 - val_loss: 0.5674 - val_accuracy: 0.7500\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7133 - val_loss: 0.5666 - val_accuracy: 0.7500\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.7045 - val_loss: 0.5657 - val_accuracy: 0.7500\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7562 - val_loss: 0.5649 - val_accuracy: 0.7500\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7503 - val_loss: 0.5641 - val_accuracy: 0.7448\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7467 - val_loss: 0.5633 - val_accuracy: 0.7448\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.7405 - val_loss: 0.5625 - val_accuracy: 0.7448\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7305 - val_loss: 0.5617 - val_accuracy: 0.7448\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.7184 - val_loss: 0.5609 - val_accuracy: 0.7396\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7278 - val_loss: 0.5601 - val_accuracy: 0.7344\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7157 - val_loss: 0.5593 - val_accuracy: 0.7344\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7328 - val_loss: 0.5585 - val_accuracy: 0.7344\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7044 - val_loss: 0.5578 - val_accuracy: 0.7396\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7320 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7278 - val_loss: 0.5563 - val_accuracy: 0.7396\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7029 - val_loss: 0.5555 - val_accuracy: 0.7396\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.7225 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7574 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.7223 - val_loss: 0.5534 - val_accuracy: 0.7448\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7196 - val_loss: 0.5527 - val_accuracy: 0.7448\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7431 - val_loss: 0.5520 - val_accuracy: 0.7448\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7232 - val_loss: 0.5514 - val_accuracy: 0.7448\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7631 - val_loss: 0.5507 - val_accuracy: 0.7448\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7557 - val_loss: 0.5501 - val_accuracy: 0.7448\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5455 - accuracy: 0.7157 - val_loss: 0.5495 - val_accuracy: 0.7448\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7184 - val_loss: 0.5489 - val_accuracy: 0.7448\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7468 - val_loss: 0.5483 - val_accuracy: 0.7448\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7380 - val_loss: 0.5477 - val_accuracy: 0.7500\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7051 - val_loss: 0.5471 - val_accuracy: 0.7552\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7282 - val_loss: 0.5465 - val_accuracy: 0.7552\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7475 - val_loss: 0.5459 - val_accuracy: 0.7604\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7184 - val_loss: 0.5453 - val_accuracy: 0.7604\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7361 - val_loss: 0.5448 - val_accuracy: 0.7604\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7554 - val_loss: 0.5443 - val_accuracy: 0.7604\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7519 - val_loss: 0.5437 - val_accuracy: 0.7604\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7184 - val_loss: 0.5432 - val_accuracy: 0.7604\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7424 - val_loss: 0.5427 - val_accuracy: 0.7604\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7443 - val_loss: 0.5422 - val_accuracy: 0.7604\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7121 - val_loss: 0.5417 - val_accuracy: 0.7604\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7302 - val_loss: 0.5412 - val_accuracy: 0.7604\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7542 - val_loss: 0.5408 - val_accuracy: 0.7604\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7440 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7596 - val_loss: 0.5398 - val_accuracy: 0.7604\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7431 - val_loss: 0.5394 - val_accuracy: 0.7604\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7394 - val_loss: 0.5389 - val_accuracy: 0.7604\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7360 - val_loss: 0.5384 - val_accuracy: 0.7552\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7262 - val_loss: 0.5380 - val_accuracy: 0.7604\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7257 - val_loss: 0.5376 - val_accuracy: 0.7656\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7660 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7437 - val_loss: 0.5367 - val_accuracy: 0.7656\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7758 - val_loss: 0.5363 - val_accuracy: 0.7656\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7508 - val_loss: 0.5359 - val_accuracy: 0.7656\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7361 - val_loss: 0.5355 - val_accuracy: 0.7656\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7298 - val_loss: 0.5351 - val_accuracy: 0.7656\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7653 - val_loss: 0.5347 - val_accuracy: 0.7656\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7701 - val_loss: 0.5344 - val_accuracy: 0.7656\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7516 - val_loss: 0.5340 - val_accuracy: 0.7656\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7850 - val_loss: 0.5336 - val_accuracy: 0.7656\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7372 - val_loss: 0.5333 - val_accuracy: 0.7656\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7631 - val_loss: 0.5329 - val_accuracy: 0.7656\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7632 - val_loss: 0.5326 - val_accuracy: 0.7656\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5263 - accuracy: 0.7664 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7804 - val_loss: 0.5319 - val_accuracy: 0.7656\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7441 - val_loss: 0.5315 - val_accuracy: 0.7708\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7494 - val_loss: 0.5312 - val_accuracy: 0.7708\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7515 - val_loss: 0.5308 - val_accuracy: 0.7708\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7641 - val_loss: 0.5305 - val_accuracy: 0.7708\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7806 - val_loss: 0.5301 - val_accuracy: 0.7708\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7647 - val_loss: 0.5298 - val_accuracy: 0.7708\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4956 - accuracy: 0.7857 - val_loss: 0.5295 - val_accuracy: 0.7708\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7575 - val_loss: 0.5292 - val_accuracy: 0.7708\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.7512 - val_loss: 0.5289 - val_accuracy: 0.7708\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7749 - val_loss: 0.5286 - val_accuracy: 0.7708\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7565 - val_loss: 0.5284 - val_accuracy: 0.7708\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7773 - val_loss: 0.5281 - val_accuracy: 0.7708\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7869 - val_loss: 0.5278 - val_accuracy: 0.7708\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7709 - val_loss: 0.5275 - val_accuracy: 0.7708\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7755 - val_loss: 0.5273 - val_accuracy: 0.7708\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7842 - val_loss: 0.5270 - val_accuracy: 0.7708\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7712 - val_loss: 0.5267 - val_accuracy: 0.7708\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7581 - val_loss: 0.5264 - val_accuracy: 0.7708\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7619 - val_loss: 0.5261 - val_accuracy: 0.7708\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7620 - val_loss: 0.5258 - val_accuracy: 0.7708\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7376 - val_loss: 0.5256 - val_accuracy: 0.7708\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7619 - val_loss: 0.5253 - val_accuracy: 0.7708\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7797 - val_loss: 0.5250 - val_accuracy: 0.7708\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7851 - val_loss: 0.5248 - val_accuracy: 0.7708\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.8062 - val_loss: 0.5245 - val_accuracy: 0.7708\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7648 - val_loss: 0.5243 - val_accuracy: 0.7708\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7686 - val_loss: 0.5240 - val_accuracy: 0.7708\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7442 - val_loss: 0.5238 - val_accuracy: 0.7708\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7915 - val_loss: 0.5235 - val_accuracy: 0.7708\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7861 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7721 - val_loss: 0.5230 - val_accuracy: 0.7708\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7410 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7699 - val_loss: 0.5226 - val_accuracy: 0.7708\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7781 - val_loss: 0.5224 - val_accuracy: 0.7708\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7925 - val_loss: 0.5222 - val_accuracy: 0.7708\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7924 - val_loss: 0.5220 - val_accuracy: 0.7708\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7651 - val_loss: 0.5218 - val_accuracy: 0.7708\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4907 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7708\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7852 - val_loss: 0.5214 - val_accuracy: 0.7708\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7725 - val_loss: 0.5212 - val_accuracy: 0.7708\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7840 - val_loss: 0.5210 - val_accuracy: 0.7708\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7733 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7709 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7772 - val_loss: 0.5205 - val_accuracy: 0.7708\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7797 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7808 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7557 - val_loss: 0.5200 - val_accuracy: 0.7708\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7886 - val_loss: 0.5198 - val_accuracy: 0.7708\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7725 - val_loss: 0.5197 - val_accuracy: 0.7760\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.8068 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7790 - val_loss: 0.5194 - val_accuracy: 0.7708\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7703 - val_loss: 0.5193 - val_accuracy: 0.7708\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7659 - val_loss: 0.5191 - val_accuracy: 0.7708\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7593 - val_loss: 0.5190 - val_accuracy: 0.7708\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7668 - val_loss: 0.5188 - val_accuracy: 0.7708\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.8042 - val_loss: 0.5187 - val_accuracy: 0.7708\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7543 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7697 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7720 - val_loss: 0.5183 - val_accuracy: 0.7760\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7590 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7588 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7600 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7524 - val_loss: 0.5178 - val_accuracy: 0.7812\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7683 - val_loss: 0.5176 - val_accuracy: 0.7812\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7911 - val_loss: 0.5175 - val_accuracy: 0.7812\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7812\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7549 - val_loss: 0.5173 - val_accuracy: 0.7812\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7864 - val_loss: 0.5172 - val_accuracy: 0.7812\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.8138 - val_loss: 0.5171 - val_accuracy: 0.7812\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7665 - val_loss: 0.5170 - val_accuracy: 0.7812\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7964 - val_loss: 0.5168 - val_accuracy: 0.7812\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7516 - val_loss: 0.5167 - val_accuracy: 0.7812\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7585 - val_loss: 0.5166 - val_accuracy: 0.7812\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7833 - val_loss: 0.5165 - val_accuracy: 0.7812\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7821 - val_loss: 0.5164 - val_accuracy: 0.7812\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7759 - val_loss: 0.5163 - val_accuracy: 0.7812\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7915 - val_loss: 0.5162 - val_accuracy: 0.7812\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.7622 - val_loss: 0.5161 - val_accuracy: 0.7812\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7590 - val_loss: 0.5160 - val_accuracy: 0.7812\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7910 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7790 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7733 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7868 - val_loss: 0.5157 - val_accuracy: 0.7760\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7701 - val_loss: 0.5156 - val_accuracy: 0.7760\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.8032 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7718 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7808 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7637 - val_loss: 0.5153 - val_accuracy: 0.7760\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7742 - val_loss: 0.5152 - val_accuracy: 0.7812\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7548 - val_loss: 0.5151 - val_accuracy: 0.7812\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7776 - val_loss: 0.5150 - val_accuracy: 0.7812\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7717 - val_loss: 0.5149 - val_accuracy: 0.7812\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7605 - val_loss: 0.5148 - val_accuracy: 0.7812\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7982 - val_loss: 0.5147 - val_accuracy: 0.7812\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7713 - val_loss: 0.5147 - val_accuracy: 0.7812\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7800 - val_loss: 0.5146 - val_accuracy: 0.7812\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7657 - val_loss: 0.5145 - val_accuracy: 0.7812\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7784 - val_loss: 0.5144 - val_accuracy: 0.7812\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7748 - val_loss: 0.5143 - val_accuracy: 0.7812\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7728 - val_loss: 0.5142 - val_accuracy: 0.7760\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7795 - val_loss: 0.5141 - val_accuracy: 0.7760\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7883 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.7602 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7676 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7802 - val_loss: 0.5137 - val_accuracy: 0.7760\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7647 - val_loss: 0.5136 - val_accuracy: 0.7760\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7726 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7498 - val_loss: 0.5134 - val_accuracy: 0.7760\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7729 - val_loss: 0.5133 - val_accuracy: 0.7760\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7881 - val_loss: 0.5132 - val_accuracy: 0.7760\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.8050 - val_loss: 0.5131 - val_accuracy: 0.7760\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7693 - val_loss: 0.5130 - val_accuracy: 0.7760\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7690 - val_loss: 0.5129 - val_accuracy: 0.7760\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7656 - val_loss: 0.5129 - val_accuracy: 0.7760\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.8109 - val_loss: 0.5128 - val_accuracy: 0.7760\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7543 - val_loss: 0.5127 - val_accuracy: 0.7760\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7934 - val_loss: 0.5126 - val_accuracy: 0.7760\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7369 - val_loss: 0.5126 - val_accuracy: 0.7760\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7729 - val_loss: 0.5125 - val_accuracy: 0.7760\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7378 - val_loss: 0.5124 - val_accuracy: 0.7760\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7704 - val_loss: 0.5123 - val_accuracy: 0.7760\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7769 - val_loss: 0.5123 - val_accuracy: 0.7760\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7988 - val_loss: 0.5122 - val_accuracy: 0.7760\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7674 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7664 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7915 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7951 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7458 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7437 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7779 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7724 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7824 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5215 - accuracy: 0.7497 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.8036 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7755 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7594 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7795 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7773 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7599 - val_loss: 0.5112 - val_accuracy: 0.7708\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7787 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7756 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7903 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7784 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7849 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7649 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7655 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7995 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7834 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7594 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7630 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7732 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.7812 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8080 - val_loss: 0.5104 - val_accuracy: 0.7708\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7860 - val_loss: 0.5104 - val_accuracy: 0.7708\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7817 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7763 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7745 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7581 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7687 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7805 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7973 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7886 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7888 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7701 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7789 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7485 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8164 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7993 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7922 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7941 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7936 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7773 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7680 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8104 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7751 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7614 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7785 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7725 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7685 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7741 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7673 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7890 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7886 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7713 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.7802 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7721 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7853 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7628 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7960 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7570 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7904 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.7625 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7807 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7722 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7811 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7852 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7935 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7664 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7820 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7668 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7857 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7796 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7742 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7794 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7613 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7793 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7749 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7670 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8145 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7745 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7940 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7888 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7936 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7891 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7717 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7797 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7831 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.8074 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7658 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7623 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7783 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7700 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7936 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7781 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7900 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7894 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7725 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.8031 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8057 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7944 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7979 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7926 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7893 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8119 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7717 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7627 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7930 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7705 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7597 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7807 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7936 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8209 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7724 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7811 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7852 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7925 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7936 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7709 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7403 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7843 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7959 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8007 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7648 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7475 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7994 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7734 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7745 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.8005 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7887 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7897 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7764 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8028 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7698 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7925 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7983 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7892 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7688 - val_loss: 0.5062 - val_accuracy: 0.7708\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7963 - val_loss: 0.5062 - val_accuracy: 0.7708\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7733 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7809 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4958 - accuracy: 0.7526 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7537 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4829 - accuracy: 0.7683 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.8064 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7899 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7939 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7816 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7709 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7598 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7933 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7696 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8172 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7906 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7856 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7923 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7870 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7764 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7862 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7744 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7922 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7931 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7885 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.8004 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7807 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7948 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7894 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7839 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4881 - accuracy: 0.7645 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.7637 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7718 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7939 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7618 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8125 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7606 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7780 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7699 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.8005 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7915 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7632 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7848 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7661 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7916 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7682 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7576 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7979 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.8029 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7640 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7653 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7566 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7472 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.7930 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7871 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7858 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7689 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8033 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7675 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7824 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8060 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7897 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7753 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7806 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7976 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7876 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7834 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8027 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7966 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7772 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7923 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7940 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.8092 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7962 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7852 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7882 - val_loss: 0.5048 - val_accuracy: 0.7708\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7772 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.8002 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7727 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.8031 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7794 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7787 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.8158 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7778 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8215 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7892 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7728 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7737 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7931 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7932 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5037 - accuracy: 0.7540 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.7534 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8054 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7725 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7762 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7493 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7750 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7938 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7863 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7905 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7799 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.8001 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7850 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7697 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8302 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7890 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7913 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8004 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7745 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7794 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7760 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.8062 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.8164 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7843 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7869 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7875 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7880 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8106 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7785 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8254 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7853 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7950 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7894 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7878 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8004 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.8188 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7973 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7777 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7841 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7840 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7782 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8051 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7992 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7938 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7936 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7796 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7784 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7797 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7875 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.8052 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8041 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7977 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8123 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7980 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7936 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7855 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7920 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7987 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7838 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7775 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7949 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7898 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7549 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7654 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7867 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7688 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7851 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7776 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7910 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8059 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7782 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7688 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7858 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7929 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7889 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7827 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7760 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7618 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7949 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7727 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7920 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7699 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7937 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7994 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7914 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7988 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7962 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7587 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7974 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7952 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7675 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7750 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7787 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7915 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4926 - accuracy: 0.7599 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8011 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7997 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7749 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7742 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7737 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7973 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7667 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7833 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7729 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7851 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7855 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8120 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7796 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8342 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8045 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7777 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7968 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7667 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.8029 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7990 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7816 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7963 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7998 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7839 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8014 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7962 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7975 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7856 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7877 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7918 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7714 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7761 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7869 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7863 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7894 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8191 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7601 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7970 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7747 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7723 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7777 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8052 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7909 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7668 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8032 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.8009 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7911 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4892 - accuracy: 0.7559 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7829 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7580 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7643 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7731 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8019 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8137 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7901 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7768 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7986 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8065 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7966 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7739 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7981 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8053 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.7937 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7779 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7616 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7527 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7875 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7806 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7571 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.7787 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7944 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.7991 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7822 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7856 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7798 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7972 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.7945 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7541 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7860 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7926 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8027 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7526 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7974 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7950 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8059 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7907 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7710 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7937 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7626 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7860 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7973 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7875 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.7824 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7912 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7858 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7878 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7603 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7803 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.7919 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7903 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.8001 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8051 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7724 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8139 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7828 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7894 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7848 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7438 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8109 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8220 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.7875 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8083 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.7976 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7907 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8061 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7813 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7927 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7826 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7913 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7909 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8079 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7800 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7867 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7645 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7595 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7725 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7989 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7734 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7482 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7681 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.7760 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7751 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7964 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.7800 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8031 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8004 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7729 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.7926 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7658 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7710 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7853 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8008 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.7972 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7640 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7985 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8121 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7814 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7700 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8175 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7595 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7956 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7928 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7788 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7607 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8040 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7976 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7813 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7861 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7790 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7923 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8052 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8000 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7889 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7828 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7763 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8000 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8179 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7770 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7878 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8045 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7801 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7858 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7893 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.7989 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8038 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8010 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7875 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7889 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8100 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7885 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7725 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7806 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.8001 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8068 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7979 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7717 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7929 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7780 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7866 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7964 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7798 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7837 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8134 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7922 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7836 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7868 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8009 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.8119 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8114 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7879 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.8062 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8192 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.7943 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7695 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8198 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7632 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.8017 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.7991 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8324 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8105 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7950 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7840 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7803 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8148 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7877 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7936 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8113 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8018 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8093 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8256 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8013 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8062 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7851 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8071 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7920 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.8008 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7803 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8023 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7935 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7798 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8113 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7943 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8170 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7881 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7948 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7687 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7977 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7889 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7842 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7650 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7881 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7673 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.8049 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8098 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8029 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8015 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8178 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8172 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8032 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7895 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8174 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7725 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7923 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7931 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8139 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8066 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7893 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8048 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7985 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7980 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7768 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8070 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7832 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7890 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7967 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8117 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8097 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7831 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7688 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8037 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7890 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7843 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7992 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7907 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8390 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7899 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8008 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7923 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.8008 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7766 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7748 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7964 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7705 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.7998 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7871 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.8091 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7992 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8130 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7699 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7968 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8089 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7976 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8085 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8064 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8098 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8013 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8027 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7796 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7906 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8176 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8018 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8136 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8009 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7907 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7868 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7869 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8274 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8037 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8263 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7913 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7867 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7975 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.7850 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8179 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8141 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8058 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8097 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8013 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.8158 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8226 - val_loss: 0.5104 - val_accuracy: 0.7708\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7852 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7830 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.7985 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8154 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7955 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8100 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7658 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7633 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8094 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7937 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8097 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7961 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7938 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8133 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.8122 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7894 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7902 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8140 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7815 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8180 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7933 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7909 - val_loss: 0.5112 - val_accuracy: 0.7708\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.7989 - val_loss: 0.5112 - val_accuracy: 0.7708\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8053 - val_loss: 0.5112 - val_accuracy: 0.7708\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8172 - val_loss: 0.5113 - val_accuracy: 0.7708\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7604 - val_loss: 0.5113 - val_accuracy: 0.7708\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.7977 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7721 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7715 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7885 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7741 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7743 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8146 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7936 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8061 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7784 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7693 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8029 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7990 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8163 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7693 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7934 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.7953 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8113 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7909 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7888 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8007 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.7948 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7851 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8153 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.7950 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8091 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8094 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7975 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7901 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8165 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8137 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7712 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7766 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.7975 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7947 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7795 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7821 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.7980 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7803 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7966 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8292 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7843 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7830 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7958 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7841 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7920 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8051 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7871 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7991 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7804 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8012 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7860 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8157 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7992 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8024 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8048 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8091 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7788 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8079 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7972 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7925 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7962 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7862 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7864 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.7947 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.8048 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7709 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8170 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7886 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7953 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8338 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8077 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7803 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7930 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7898 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8169 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8020 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7898 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7932 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7881 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7942 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8098 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7876 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7985 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.8136 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7836 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7983 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7933 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7590 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7852 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7906 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7839 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7622 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8103 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7809 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7920 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7884 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8019 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.7971 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.8021 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8007 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8148 - val_loss: 0.5133 - val_accuracy: 0.7760\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8113 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7999 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7904 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7959 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7778 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7648 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7962 - val_loss: 0.5132 - val_accuracy: 0.7760\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8249 - val_loss: 0.5133 - val_accuracy: 0.7760\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7714 - val_loss: 0.5134 - val_accuracy: 0.7760\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8077 - val_loss: 0.5134 - val_accuracy: 0.7760\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7742 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8250 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7912 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7855 - val_loss: 0.5136 - val_accuracy: 0.7760\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8097 - val_loss: 0.5137 - val_accuracy: 0.7760\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7917 - val_loss: 0.5137 - val_accuracy: 0.7760\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7738 - val_loss: 0.5137 - val_accuracy: 0.7760\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7884 - val_loss: 0.5137 - val_accuracy: 0.7760\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8172 - val_loss: 0.5137 - val_accuracy: 0.7760\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.8122 - val_loss: 0.5137 - val_accuracy: 0.7760\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8136 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.7913 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7931 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.8118 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7768 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8100 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8029 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7947 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8146 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8165 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8008 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7929 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8010 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.7982 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.8038 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8007 - val_loss: 0.5141 - val_accuracy: 0.7760\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8101 - val_loss: 0.5141 - val_accuracy: 0.7760\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.7989 - val_loss: 0.5141 - val_accuracy: 0.7760\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7848 - val_loss: 0.5141 - val_accuracy: 0.7760\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7834 - val_loss: 0.5142 - val_accuracy: 0.7760\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7749 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7965 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.7936 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8119 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8083 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7809 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8200 - val_loss: 0.5145 - val_accuracy: 0.7760\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.7965 - val_loss: 0.5146 - val_accuracy: 0.7760\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.7755 - val_loss: 0.5145 - val_accuracy: 0.7760\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7747 - val_loss: 0.5145 - val_accuracy: 0.7760\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7855 - val_loss: 0.5146 - val_accuracy: 0.7760\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.7950 - val_loss: 0.5146 - val_accuracy: 0.7760\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8126 - val_loss: 0.5145 - val_accuracy: 0.7760\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7658 - val_loss: 0.5146 - val_accuracy: 0.7760\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7827 - val_loss: 0.5145 - val_accuracy: 0.7760\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.7946 - val_loss: 0.5146 - val_accuracy: 0.7760\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8157 - val_loss: 0.5146 - val_accuracy: 0.7760\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.7955 - val_loss: 0.5147 - val_accuracy: 0.7760\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8135 - val_loss: 0.5146 - val_accuracy: 0.7760\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8166 - val_loss: 0.5147 - val_accuracy: 0.7760\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8073 - val_loss: 0.5147 - val_accuracy: 0.7760\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.7963 - val_loss: 0.5148 - val_accuracy: 0.7760\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.7801 - val_loss: 0.5148 - val_accuracy: 0.7760\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7723 - val_loss: 0.5148 - val_accuracy: 0.7760\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8170 - val_loss: 0.5149 - val_accuracy: 0.7760\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7849 - val_loss: 0.5149 - val_accuracy: 0.7760\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.7810 - val_loss: 0.5150 - val_accuracy: 0.7760\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8037 - val_loss: 0.5150 - val_accuracy: 0.7760\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7853 - val_loss: 0.5150 - val_accuracy: 0.7760\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.7744 - val_loss: 0.5151 - val_accuracy: 0.7760\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7654 - val_loss: 0.5151 - val_accuracy: 0.7760\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.8037 - val_loss: 0.5151 - val_accuracy: 0.7760\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7960 - val_loss: 0.5151 - val_accuracy: 0.7760\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7848 - val_loss: 0.5151 - val_accuracy: 0.7760\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7836 - val_loss: 0.5152 - val_accuracy: 0.7760\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.7944 - val_loss: 0.5152 - val_accuracy: 0.7760\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7891 - val_loss: 0.5152 - val_accuracy: 0.7760\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7943 - val_loss: 0.5153 - val_accuracy: 0.7760\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7926 - val_loss: 0.5153 - val_accuracy: 0.7760\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.7969 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7728 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7776 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7969 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8082 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7766 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.7992 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7942 - val_loss: 0.5156 - val_accuracy: 0.7760\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7697 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8066 - val_loss: 0.5156 - val_accuracy: 0.7760\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7868 - val_loss: 0.5156 - val_accuracy: 0.7760\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7986 - val_loss: 0.5157 - val_accuracy: 0.7760\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7936 - val_loss: 0.5157 - val_accuracy: 0.7760\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7886 - val_loss: 0.5157 - val_accuracy: 0.7760\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8104 - val_loss: 0.5157 - val_accuracy: 0.7760\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8000 - val_loss: 0.5157 - val_accuracy: 0.7760\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8026 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8080 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7946 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8150 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.7988 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7925 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.7974 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.7953 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7907 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8192 - val_loss: 0.5160 - val_accuracy: 0.7760\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8109 - val_loss: 0.5160 - val_accuracy: 0.7760\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7974 - val_loss: 0.5160 - val_accuracy: 0.7760\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8064 - val_loss: 0.5160 - val_accuracy: 0.7760\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8261 - val_loss: 0.5161 - val_accuracy: 0.7760\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8119 - val_loss: 0.5161 - val_accuracy: 0.7760\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8033 - val_loss: 0.5161 - val_accuracy: 0.7760\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7928 - val_loss: 0.5161 - val_accuracy: 0.7760\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7883 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7888 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8200 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7851 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7926 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7745 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - accuracy: 0.7753 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8085 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7852 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8035 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7866 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7800 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8025 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7884 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7912 - val_loss: 0.5166 - val_accuracy: 0.7760\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8150 - val_loss: 0.5166 - val_accuracy: 0.7760\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7809 - val_loss: 0.5167 - val_accuracy: 0.7760\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8228 - val_loss: 0.5167 - val_accuracy: 0.7760\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8069 - val_loss: 0.5166 - val_accuracy: 0.7760\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7876 - val_loss: 0.5166 - val_accuracy: 0.7760\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8009 - val_loss: 0.5167 - val_accuracy: 0.7760\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7949 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7903 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7992 - val_loss: 0.5169 - val_accuracy: 0.7760\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7919 - val_loss: 0.5170 - val_accuracy: 0.7760\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7981 - val_loss: 0.5170 - val_accuracy: 0.7760\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7804 - val_loss: 0.5170 - val_accuracy: 0.7760\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8146 - val_loss: 0.5170 - val_accuracy: 0.7760\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7966 - val_loss: 0.5170 - val_accuracy: 0.7760\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8036 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7829 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.7839 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7856 - val_loss: 0.5171 - val_accuracy: 0.7760\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8019 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8100 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7884 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7616 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8112 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8127 - val_loss: 0.5174 - val_accuracy: 0.7760\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8037 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7956 - val_loss: 0.5174 - val_accuracy: 0.7760\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7837 - val_loss: 0.5174 - val_accuracy: 0.7760\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8086 - val_loss: 0.5174 - val_accuracy: 0.7760\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.8054 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7968 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7785 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.8047 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.7940 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7868 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8146 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8116 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7956 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8138 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.7938 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7936 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7771 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7753 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7942 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7690 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7739 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7992 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8024 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8112 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8051 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8119 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7770 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7668 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8055 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.8006 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8014 - val_loss: 0.5183 - val_accuracy: 0.7760\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8007 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8082 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8105 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.7984 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.7928 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8164 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8101 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7918 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8037 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8155 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.7982 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.7906 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8060 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7974 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8081 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8018 - val_loss: 0.5188 - val_accuracy: 0.7760\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7855 - val_loss: 0.5188 - val_accuracy: 0.7760\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7925 - val_loss: 0.5188 - val_accuracy: 0.7760\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.8032 - val_loss: 0.5188 - val_accuracy: 0.7760\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7777 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8007 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8028 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7890 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7952 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8237 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8076 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7967 - val_loss: 0.5191 - val_accuracy: 0.7760\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7916 - val_loss: 0.5191 - val_accuracy: 0.7760\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8075 - val_loss: 0.5191 - val_accuracy: 0.7760\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8045 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8064 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7837 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7965 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.7981 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8145 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7731 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7774 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7879 - val_loss: 0.5193 - val_accuracy: 0.7708\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8058 - val_loss: 0.5193 - val_accuracy: 0.7708\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7705 - val_loss: 0.5193 - val_accuracy: 0.7708\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7758 - val_loss: 0.5194 - val_accuracy: 0.7708\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8024 - val_loss: 0.5194 - val_accuracy: 0.7708\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.7954 - val_loss: 0.5193 - val_accuracy: 0.7708\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8092 - val_loss: 0.5194 - val_accuracy: 0.7708\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7913 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.7973 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7983 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8234 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7990 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8181 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7705 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.7934 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7921 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8082 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7867 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.7975 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.7916 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7613 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.7926 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8264 - val_loss: 0.5198 - val_accuracy: 0.7708\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7948 - val_loss: 0.5198 - val_accuracy: 0.7708\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8088 - val_loss: 0.5198 - val_accuracy: 0.7708\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.8059 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8050 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7808 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8150 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7887 - val_loss: 0.5200 - val_accuracy: 0.7708\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8138 - val_loss: 0.5200 - val_accuracy: 0.7708\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8109 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3699 - accuracy: 0.8127 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7850 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7786 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.7989 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8263 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8004 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.7780 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7955 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7935 - val_loss: 0.5204 - val_accuracy: 0.7708\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7936 - val_loss: 0.5204 - val_accuracy: 0.7708\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.7977 - val_loss: 0.5204 - val_accuracy: 0.7708\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8111 - val_loss: 0.5204 - val_accuracy: 0.7708\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.7867 - val_loss: 0.5204 - val_accuracy: 0.7708\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.7950 - val_loss: 0.5204 - val_accuracy: 0.7708\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8198 - val_loss: 0.5204 - val_accuracy: 0.7708\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8219 - val_loss: 0.5206 - val_accuracy: 0.7708\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.7966 - val_loss: 0.5205 - val_accuracy: 0.7708\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8165 - val_loss: 0.5205 - val_accuracy: 0.7708\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7901 - val_loss: 0.5205 - val_accuracy: 0.7708\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8206 - val_loss: 0.5206 - val_accuracy: 0.7708\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7900 - val_loss: 0.5206 - val_accuracy: 0.7708\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8176 - val_loss: 0.5206 - val_accuracy: 0.7708\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8011 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7978 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8285 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7896 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8018 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8140 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7827 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7619 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8042 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8176 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8153 - val_loss: 0.5209 - val_accuracy: 0.7708\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8094 - val_loss: 0.5209 - val_accuracy: 0.7708\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8060 - val_loss: 0.5209 - val_accuracy: 0.7708\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8026 - val_loss: 0.5209 - val_accuracy: 0.7708\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7921 - val_loss: 0.5209 - val_accuracy: 0.7708\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8059 - val_loss: 0.5209 - val_accuracy: 0.7708\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.7998 - val_loss: 0.5210 - val_accuracy: 0.7708\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.7991 - val_loss: 0.5210 - val_accuracy: 0.7708\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.7961 - val_loss: 0.5210 - val_accuracy: 0.7708\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7771 - val_loss: 0.5209 - val_accuracy: 0.7604\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.8068 - val_loss: 0.5210 - val_accuracy: 0.7708\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7924 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8051 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8056 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7900 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7956 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8079 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7821 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7865 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7958 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.8023 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3585 - accuracy: 0.8428 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8364 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8108 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7946 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7817 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8140 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.7999 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8261 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8099 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.7999 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8116 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8309 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7854 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7774 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7983 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7798 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7896 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.7962 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.7961 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.7879 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8089 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8007 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8028 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7741 - val_loss: 0.5215 - val_accuracy: 0.7604\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8167 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8043 - val_loss: 0.5217 - val_accuracy: 0.7604\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7875 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8055 - val_loss: 0.5218 - val_accuracy: 0.7604\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7826 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.7976 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8066 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7729 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8071 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8006 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7826 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8183 - val_loss: 0.5219 - val_accuracy: 0.7604\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7940 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.8130 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8017 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.7957 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7919 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.8000 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.7964 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8035 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7788 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7944 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7915 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8125 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.7921 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8315 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.7992 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.7933 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3691 - accuracy: 0.8197 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.7956 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7796 - val_loss: 0.5224 - val_accuracy: 0.7604\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.7824 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8051 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7957 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7988 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.7731 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8034 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.7985 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8131 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.7882 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.7938 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8039 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8145 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7808 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8115 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.7718 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.7995 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.7942 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7900 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8205 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8013 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7946 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8009 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7866 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8098 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8171 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8050 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8025 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.7962 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.7929 - val_loss: 0.5232 - val_accuracy: 0.7656\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8062 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.7973 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7861 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.7831 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8224 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8001 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.7896 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.7951 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.7894 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7540 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7676 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7759 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.7885 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8047 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7817 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8157 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8150 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.7903 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.7883 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7869 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.7818 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8161 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7995 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7630 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8073 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8458 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8120 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8007 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7854 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8201 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.7979 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8038 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8290 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
            "accuracy is 0.760\n",
            "roc-auc is 0.807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Cutcq36sS39S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a162d2c1-b43b-463b-a160-5546509e8063"
      },
      "source": [
        "# gráfico de perca\n",
        "run_hist_2.history.keys()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_2.history[\"accuracy\"], 'y', marker='.', label='Train Accuracy')\n",
        "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.plot(run_hist_2.history[\"val_accuracy\"], 'g', marker='.', label=\"Validation Accuracy\")\n",
        "ax.legend()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7e52cb5d50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}