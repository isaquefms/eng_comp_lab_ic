{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Keras_First_NN_HW.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzDW3aHSS388"
      },
      "source": [
        "## Using Keras to Build and Train Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZcGBEd9S39C"
      },
      "source": [
        "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
        "\n",
        "## UCI Pima Diabetes Dataset\n",
        "\n",
        "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
        "\n",
        "\n",
        "### Attributes: (all numeric-valued)\n",
        "   1. Number of times pregnant\n",
        "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "   3. Diastolic blood pressure (mm Hg)\n",
        "   4. Triceps skin fold thickness (mm)\n",
        "   5. 2-Hour serum insulin (mu U/ml)\n",
        "   6. Body mass index (weight in kg/(height in m)^2)\n",
        "   7. Diabetes pedigree function\n",
        "   8. Age (years)\n",
        "   9. Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4tTxbjZS39D"
      },
      "source": [
        "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySbF2p0MS39D"
      },
      "source": [
        "#Preliminaries\n",
        "\n",
        "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmkVQMq1S39E"
      },
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUQCAEceS39F"
      },
      "source": [
        "## Load in the data set (Internet Access needed)\n",
        "\n",
        "##url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv('pima-indians-diabetes.data', names=names)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEUEJI19S39G",
        "outputId": "739d18bf-d5fc-4da5-a978-1e1fc0d76aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>32.3</td>\n",
              "      <td>0.660</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>6</td>\n",
              "      <td>194</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.5</td>\n",
              "      <td>0.129</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>9</td>\n",
              "      <td>112</td>\n",
              "      <td>82</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>28.2</td>\n",
              "      <td>1.282</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>2</td>\n",
              "      <td>84</td>\n",
              "      <td>50</td>\n",
              "      <td>23</td>\n",
              "      <td>76</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.968</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>189</td>\n",
              "      <td>60</td>\n",
              "      <td>23</td>\n",
              "      <td>846</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.398</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  ...  age  has_diabetes\n",
              "386               5                     116  ...   35             1\n",
              "319               6                     194  ...   59             1\n",
              "618               9                     112  ...   50             1\n",
              "508               2                      84  ...   21             0\n",
              "13                1                     189  ...   59             1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hVVqkavS39G"
      },
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVvGrsnjS39H"
      },
      "source": [
        "# Split the data to Train, and Test (75%, 25%)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzZSZtrxS39H",
        "outputId": "ec51edab-1809-48aa-d703-5eaff6945cf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.mean(y), np.mean(1-y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZOK4fjNS39H"
      },
      "source": [
        "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
        "## Exercise: Get a baseline performance using Random Forest\n",
        "To begin, and get a baseline for classifier performance:\n",
        "1. Train a Random Forest model with 200 trees on the training data.\n",
        "2. Calculate the accuracy and roc_auc_score of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ_bZB67S39I",
        "outputId": "11479b3d-e0c9-4340-da17-8aa516d34e14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Train the RF Model\n",
        "rf_model = RandomForestClassifier(n_estimators=200)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmTfTXs3S39I",
        "outputId": "2d0a6615-6148-49c5-aa81-93511d6a0719",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
        "y_pred_class_rf = rf_model.predict(X_test)\n",
        "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
        "\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy is 0.771\n",
            "roc-auc is 0.827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw0PrlGPS39I",
        "outputId": "63ae1d73-fc84-4c93-9935-4f371eb9b33f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUZeL28e9DCEWkSe+ogIiogCDiuiuLWBAFldVXUNFV14rSCb1L778FFQsuuogVRQUFlYCiiIAgvSO9hxJIz/P+MYMbYwIpM/NMuT/XlYucOWdm7jkZ5p7nzDlnjLUWERERCR4FXAcQERGRP1I5i4iIBBmVs4iISJBROYuIiAQZlbOIiEiQUTmLiIgEGZWzRCRjTFFjzGfGmJPGmA9c54kkxpjHjDHfZ5iON8ZcloPr1TTGWGNMQf8mdOdCj9EYM9gY806gc0ngqZwjgDFmlzEmwfsieNAY85Yx5uJMy9xojPnWGHPaW1ifGWPqZVqmhDFmkjFmt/e2tnuny2Zzv8YY86IxZp0x5owxZq8x5gNjzNX+fLw59A+gAlDGWnt/fm/MGNPcGJPuXS+njTGbjTH/zLSM9a6HeO/Pifzebw5yvWWMSfbe33FjzEJjTF3vvD+80HvzHc5YDMaYaO9lfzohgve2U40xlfKT0Vp7sbV2R35u40IiodglvKicI8fd1tqLgQZAQ6DPuRnGmGbAAuBToDJwKbAGWHpuRGOMKQR8A1wF3AGUAJoBx4Drs7nPyUBn4EXgEqAO8AnQOrfh/fCiWgPYYq1N9WGW/d51XALoCrxmjLki0zLXesvoYmttqdzedx6N8eaqChwG3jrPsnFAqwzTrbyX/YExphjQDjgJPOyzpGFObw4kp1TOEcZaexD4Ck9JnzMGmGmtnWytPW2tPW6t7Q8sAwZ7l+kIVAfutdZusNamW2sPW2uHWWvnZb4fY0xt4HmgvbX2W2ttkrX2rLX2v9baUd5lYo0xT2a4TubNndYY87wxZiuw1RjzsjFmXKb7+dQY0837e2VjzEfGmCPGmJ3GmBezWgfGmCHAQOD/eUeUTxhjChhj+htjfvOOFGcaY0p6lz836nrCGLMb+PYC69h618lx4JrzLZtNvpxkedS7BeOoMaZfTm7XWnsWmAXUP89ib+P5W5/TEZiZxXLtgBPAUODRCzyeMsaYucaYU8aY5cDlmeZbY0wt7++tjTG/eJfdY4wZnMVNPm6M2W+MOWCM6ZHhdgoYY3p7t+gcM8a8b4y5xDt7ifffE96/eTPvdR43xmw0xsQZY74yxtTwXm6MMRO96/+UMWatMSbL9eZ9Ho80xiz3LvvpufvN6rlzvr/vhR5jFvd9gzHmB2PMCWPMGmNM80y5hnvnxxvP1rAyxpj/enP+bIypmd1ti2PWWv2E+Q+wC2jp/b0qsBaY7J2+CEgD/p7F9f4JHPD+Phv4Ty7u8xngtwssEws8mWH6MeD7DNMWWIhn1F0U+BuwBzDe+aWBBDyj/QLASjylWwi4DNgB3J7NfQ8G3skw/TiwzXu9i4GPgbe982p6s8wEigFFs7i95sBe7+8FgDZAOtAw0+OplYN1l5Msr3nXybVAEnBlNrf1FjDc+/vFeMr5u2zWgcVT3IeAUt71e8h7mc10u9/geVNXAUgFrjvP45kNvO9dd/WBfVn8nWtlWI9Xe9fhNd77vyfTY3/Xe1tXA0f433O7M543lFWBwsCrwLuZrlsww/229a7nK4GCQH/gB++8273Pp1KA8S5T6TzP433ex1YM+Ojces3quZPDv292j3FwhtuugmfL1Z3e9XWrd7pchlzb8LwZKglsALYALb2PdyYww/Xrk36y+X/jOoB+AvBH9pRzPHDa+x//G6CUd15V72V1s7jeHUCK9/eFwKhc3Gc/YNkFlonlwuXcIsO0AXYDf/NO/wv41vt7U2B3ptvvk92LD38upm+A5zJMXwGkeF/Ezr1gXnaex9IcTxmfwFOWaUCXTMtY4JR3mRPAlGxuKydZqmaYvxx4MJvbegtI9N7fQWAucHk268ACtYDXgafxvMF6zXuZzbBcde9jbeCd/grvm70s7j/Km71uhstGZPF3zvJNCzAJmOj9/dxjz3hbY4A3vL9vBG7JMK9SFustYznPB57IMF0AOIvnI48WeIrsBqBADp7HozJM1wOSvY/9T8+dHP59s3uMv//NgBi8pZ5h2a+ARzPk6pdh3nhgfobpu4HVOf0/rZ/A/mizduS4x1pbHE+J1AXO7cQVh+eFNqudeioBR72/H8tmmezkdvns7Dn3i/W8oswG2nsv6gD81/t7DaCyd/PeCePZ2aovnpFdTlQGfssw/RueF8uM19/D+e23ns+RSwBT8LzAZ9bIWlvK+5PlZvccZjmY4fezeEZg2Rnnvb+K1to21trtF3gcM/Fszs5uk/YjwEZr7Wrv9H+BDsaY6CyWLefNnnHd/ZbFcgAYY5oaYxZ5P5o4iecNQuYdDjPfVmXv7zWAORn+/hvxvEnK7jlQA5icYfnjeN4AVrHWfgv8G5gKHDbGTDfGlMgudxaZojPlzjg/t8+1jI8xc/77Mz3nb+KP/+8OZfg9IYvp8z1vxCGVc4Sx1i7GM5oa550+A/wIZLXH8gN43uUDfA3cbjw7AuXEN0BVY0zj8yxzBs9m9XMqZhU50/S7wD+8nw02xbMJETwvZjszFF8pa21xa+2dOcy7H8+L3TnV8WyuzfhilqOvcLPWJuEZ1VxtjLknh/ef2yz+9B2eF/gKwPdZzO8IXGY8e/4fBCbgKaKs1vURPNmrZbis+nnuexae0X01a21J4BU8hZlR5tva7/19D9Aq03OgiLV2H1n/7fYAT2davqi19gcAa+0Ua+11eEbCdYCe58mdOVMK/3tjS6b7z8nfN7vHmDn/25nyF7PefToktKmcI9Mk4FZjzLXe6d7Ao8Zz2FNxY0xpY8xwPHtjD/Eu8zaeF4OPjDF1vTu1lDHG9DXG/OlF2Vq7FZgGvGs8hxkVMsYUMcY8aIzp7V1sNXCfMeYi7w5BT1wouLX2Fzwveq8DX1lrzx2OtBw4bYyJMZ5jmKOMMfWNMU1yuE7eBboaYy41nsPMRgDv2Tzsze3NmYxnM+LAPFzdp1lyy7uF4m6gjff333l3pLoczx76Dbw/9fGUasdMN4W1Ng3PZ6qDvX/nepx/B7LiwHFrbaIx5no8W0cyG+C9ravw7BfxnvfyV4CXMuzUVc4Y09Y77wieLUQZj6d+BejjvR2MMSWNMfd7f2/iHcVH43kTmei9fnYeNsbUM8ZchGcnuQ+9jz0rOfn7ZvcYM3oHuNsYc7v3+V7E+3+t6nlySohQOUcga+0RPJsrB3qnv8ezA8x9wAE8m9EaAjd5S/bcaLAlsAnP58+n8BRiWeCnbO7qRf63afAEsB24F/jMO38ins/mDgH/4X+bqC9kljfLrAyPKQ24C09Z7OR/BZ55L9jsvInnDcgS7/UTgRdyeN3z3WZ1Y8zdebier7PkirV2vbV2fRazHgU+tdautdYePPeD57C5u8z/9o7OqBOezacH8Wy1mXGeu34OGGqMOY3n+fl+FsssxrOj0zd4Ntkv8F4+Gc+oe4H3+svwbF3BevZUfwnP4YEnjDE3WGvnAKOB2caYU8A6/ncYWQk8n7fH4fn/cAwYe57cb3sf20GgCJ7nfnZy8vfN7jH+zlq7B89ObX3xvPnYg2d0r9f1MGAyvTEWEZFcMMbE4tlJ63XXWSR86B2WiIhIkFE5i4iIBBlt1hYREQkyGjmLiIgEGZWziIhIkLngN6QYY97Ec4jKYWvtn078bowxeA5huBPPmYoes9auutDtli1b1tasWfP36TNnzlCsWE7PbyG5pfXrX1q//qN1619av/6Ted2uXLnyqLW2XE6um5OvL3sLz7GqWZ3GDzzHBdb2/jQFXvb+e141a9ZkxYoVv0/HxsbSvHnzHMSRvND69S+tX//RuvUvrV//ybxujTHZnro2swtu1rbWLsFzztnstMXzdYPWWrsMKGXy+eXrIiIikcwXX/xdhT+epH2v97IDPrhtEREJoCVLljBnzhzS0893tlLJiTNnzuR5q4QvyjnHjDFPAU8BVKhQgdjY2N/nxcfH/2FafEvr17+0fv1H69a/zq3fgwcP8sorr7B48WIKFy5MdHRWXzImOWGtJTk5mapVq+b5ueuLct7HH79Bpar3sj+x1k4HpgM0btzYZnxHoc89/Evr17+0fv1H69a/5s+fz7fffsvYsWMxxjB06FB69OhB0aJFXUcLSenp6WzcuJFChQqxb9++PD93fXEo1Vygo/G4AThprdUmbRGRIGatZdasWXTs2JFhw4Zx7733snnzZgYMGKBiziNrLX369MFaS+3atfN1Wzk5lOpdoDlQ1hizFxiE54vEsda+AszDcxjVNjyHUv0zX4lERMSvVq5cyYsvvsgPP/xA7dq1mTNnDjfddJPrWCEtJSWFpUuX0rt3b0qXLp3v27tgOVtr219gvgWez3cSERHxq4MHD9KvXz9mzJhBuXLleOONN6hZs6aK2QeGDRtGx44dfVLMEOAdwkREwlVCQgJz5swhISHBdZQs7d27l/Hjx5OYmEj37t0ZMGAAJUqU0M52+ZSUlMRHH33EoEGDiIqK8tntqpxFRPLpyJEjtGnThmXLlrmOcl533XUX48ePp06dOq6jhI1p06bRrl07nxYzqJxFRPJly5YttGrViv379zNr1qyg3UQcHR1NxYoVXccIG2fOnOHVV1+lW7dufrl9lbOISB5999133HPPPURFRbFo0SJuuOEG15EkQD755BM6dOjgt9vXt1KJiOTB7NmzadmyJWXLluXHH39UMUeIkydPEhMTQ4cOHfy6JULlLCKSC9ZaRo0aRfv27WnatCk//vgjl19+uetYEgDJycksX76cmJgYPF/I6D/arC0ikkFKSgq//vprtueWfu2113jttddo3749M2bMoHDhwgFOKC4cPXqUQYMGMXHiRAoVKuT3+1M5i4hkMHbsWPr163feZfr27cuwYcMoUEAbHyPBsWPH+O233xg5cmRAihlUziIif3Dy5Emio6OZM2dOlvMrVKhA48aNA5xKXDlw4ADDhw9nzJgxFCtWLGD3q3IWEckkKiqK1q1bu44hju3du5e4uDjGjh3LRRddFND71jYZERGRTA4cOMCYMWOoXbt2wIsZNHIWERH5g+3bt3P69GnGjh3rbIc/lbOI+IW1lqSkpHzfTnJyMomJiT5IlDOpqakBuy8JPqdOneLll19m5MiRREdHO8uhchYRn9uzZw/33HMPq1atch0lTy6++GLXEcSBDRs2cOjQIcaOHev345gvROUsIj61evVqWrduTXx8PIMHD873ZsEdO3Zw2WWX+ShdztSrVy+g9yfupaam8tFHH9G3b1/nxQwqZxHxofnz5/PAAw9QunRpli5dSv369fN9m7GxsTRv3jz/4USysWrVKnbs2MGAAQNcR/md9tYWEZ949dVXufvuu6lTpw7Lli3zSTGL+Ju1lp9//pl27dq5jvIHGjmLSL6kp6fTp08fxowZQ+vWrZk9e7Y+s5WQsHTpUtatW8fTTz/tOsqfqJxFJM8SEhJ49NFH+eCDD3j22WeZMmUKBQvqZUWC35kzZ4iLi+Opp55yHSVL+l8kInnWvn17Pv30U8aOHUv37t2DYkcakQv5+uuvWb9+PZ07d3YdJVsqZxHJs2XLltGxY0d69OjhOopIjuzcuZMyZcoEdTGDdggTkXwqWrSo6wgiOfL5558zf/58GjZs6DrKBWnkLCIiYe/777+nSZMm3HXXXa6j5IhGziIiEtbmzZvHtm3bqFChgusoOaaRs4iIhK2PP/6Y2267LeQO79PIWUREwtKSJUtITk4OuWIGlbOIiIShN954g/r16/Pggw+6jpInKmcREQkr69ato2zZslxyySWuo+SZyllERMLG5MmTueiii2jbtq3rKPmichYRkbCwZ88e6tWrF/CvGPUHlbOIiIQ0ay2jRo3i6NGj3Hrrra7j+ITKWUREQpa1lr179/L3v/89JM78lVMqZxHJk7Vr13LkyJGQOrGDhBdrLUOGDOHgwYM0bdrUdRyf0klIRCTXrLV07tyZUqVKBf0XCEh4Sk9PZ/369Tz88MPUqlXLdRyf08hZRHLtk08+YdGiRQwZMiSkD1eR0GStpX///qSnp4dlMYNGziKSS4mJifTo0YOrrrqKZ555xnUciTCpqanExsYSExNDyZIlXcfxG42cRSRXJk2axI4dO5g4cSIFC+r9vQTWiBEjqFatWlgXM2jkLCIXsGrVKnbv3g1ASkoKL730Em3atAmbQ1YkNCQnJ/Pee+/Rv39/ChQI/3GlyllEspWamkqzZs1ITk7+/bKLLrqIcePGOUwlkei1116jdevWEVHMoHIWkfNIT08nOTmZ559/nieffBKAypUrU758ecfJJFIkJCTw73//m549e7qOElAqZxG5oMqVK9OgQQPXMSTCWGv57LPPeOihh1xHCbjI2D4gIiIh5fTp0/Ts2ZN//OMfVK5c2XWcgFM5i4hIUElMTGTlypX07t07Yj5jzkybtUWEw4cPEx8f/6fLM+4IJhIIx48fp3///kyYMIEiRYq4juOMylkkgh06dIh+/frx5ptvYq3NdrnChQsHMJVEqmPHjrF7925GjhwZ0cUMKmeRiJScnMyUKVMYOnQoCQkJdO7cOdtv9ClYsCCtW7cOcEKJNIcOHWLo0KGMGjWK4sWLu47jnMpZJIJYa/niiy/o1q0bW7dupXXr1owfP54rrrjCdTSJYPv37+fo0aOMGTOGYsWKuY4TFCLzk3aRCLRx40ZatWrF3XffTYECBZg3bx6ff/65ilmcOnLkCKNGjaJ27doq5gxUziJh7sSJE3Tt2pVrrrmGZcuWMWHCBNauXUurVq1cR5MIt2vXLnbv3s3YsWMpWrSo6zhBReUsEqbS0tJ49dVXqV27NpMnT+bxxx9ny5YtdO3alejoaNfxJMKdPXuW//u//+Pqq6/WDodZ0GfOIkHs+PHjtGjRgq1bt+b6umlpaSQlJfG3v/2NSZMmZbvDl0igbd68mV27djFu3DiMMa7jBCWVs0gQGzx4MGvXruWFF17I02i3WbNm3HvvvXoBlKCRlpbGhx9+SExMjJ6X56FyFglSGzZsYNq0aTz11FNMmjTJdRyRfFuzZg3r1q2jX79+rqMEPX3mLBKErLV07dqV4sWLM3ToUNdxRPItPT2dn3/+mfbt27uOEhI0chYJQl988QULFixg4sSJlCtXznUckXxZtmwZP//8My+88ILrKCFDI2eRIJOcnEy3bt2oW7cuzz//vOs4Ivly+vRp4uLi6NSpk+soIUUjZxE/GTx4MF999VWur3f69Gm2bt3KvHnzdMiThLTY2FhWrFhBjx49XEcJOSpnET/49ttvGTJkCNdddx1lypTJ1XVLlCjBAw88oJOESEjbtm0bl1xyiYo5j1TOIj6WmppKly5dqFmzJt9//33Ef7uORJ4vv/ySLVu28OKLL7qOErJUziI+9tprr7F27Vo+/PBDFbNEnCVLltCoUSPuuOMO11FCmnYIE/GhuLg4BgwYwM0338x9993nOo5IQC1YsIDNmzdTvnx511FCnkbOIj40ZMgQ4uLimDRpks5+JBHl448/pmXLltx2222uo4QFjZxFfGTTpk1MnTqVJ598kgYNGriOIxIwP/30EwkJCZQoUcJ1lLChchbxkW7dulGsWDGGDx/uOopIwMyYMYOaNWvy0EMPuY4SVrRZW8QHli1bxvz58xk/frzO6CURY+vWrZQoUYIKFSq4jhJ2NHIWyafk5GSmTZtGnTp1dBYkiRhTp04lLS2Ndu3auY4SljRyFsmnqVOnsmfPHj7//HMKFSrkOo6I3x08eJBatWpRt25d11HClkbOIvlw5MgRhgwZQpMmTbjzzjtdxxHxK2st48aNY/fu3dx+++2u44Q1jZwlIiQlJTFr1izOnj3r09v96quviI+P57nnntOhUxLWrLXs27ePm266ieuvv951nLCncpaIsGjRIh5//HG/3Hbfvn2pWbOmX25bJBhYaxk+fDgtW7akWbNmruNEBJWzRISUlBQAFi5cyLXXXuuz2y1QoABlypQhNjbWZ7cpEkystaxdu5YOHTpw+eWXu44TMVTOElFKly6tQ51EcmHw4MG0bdtWxRxgKmcREfmTtLQ0vv76a3r06EHx4sVdx4k42ltbRET+ZMyYMVSrVk3F7IhGzhJSkpKSWLFiBenp6bm63vr16/2USCS8pKSk8M477xATE0OBAhq/uaJylpAybtw4+vfvn+frX3zxxT5MIxJ+3nrrLVq0aKFidkzlLCHl9OnTFCxYkC+//DLX1y1VqhRXXHGFH1KJhL7ExETGjx9P3759dcx+EMhRORtj7gAmA1HA69baUZnmVwf+A5TyLtPbWjvPx1lFAIiKiuKWW25xHUMkbFhrmT9/Po8++qiKOUhccLuFMSYKmAq0AuoB7Y0x9TIt1h9431rbEHgQmObroCIi4nsJCQl069aNu+++m6pVq7qOI145+VDhemCbtXaHtTYZmA20zbSMBc59y3ZJYL/vIoqIiD8kJCSwbds2+vTpQ8GC+pQzmOTkr1EF2JNhei/QNNMyg4EFxpgXgGJAy6xuyBjzFPAUQIUKFf5wVqX4+HidZcmPwmX97t69m/T09KB7LOGyfoOR1q1/xMfH89prr/Hwww+zYcMGNmzY4DpS2MnPc9dXb5XaA29Za8cbY5oBbxtj6ltr/3C8i7V2OjAdoHHjxrZ58+a/z4uNjSXjtPhWuKzfd955h+jo6KB7LOGyfoOR1q3vHT9+nD179vDWW2+xZs0arV8/yc9zNyebtfcB1TJMV/VeltETwPsA1tofgSJA2TwlEsnG1q1bmTlzJg8++KDrKCIh6+jRowwYMICaNWtSunRp13EkGzkp55+B2saYS40xhfDs8DU30zK7gVsAjDFX4innI74MKtKjRw+KFCnCSy+95DqKSEg6ePAg+/btY9SoUZQsWdJ1HDmPC5aztTYV6AR8BWzEs1f2emPMUGNMG+9i3YF/GWPWAO8Cj1lrrb9CS+RZuHAhc+fOpX///lSsWNF1HJGQExcXx7Bhw6hVq5ZOyRkCcvSZs/eY5XmZLhuY4fcNwF98G03EIzU1lS5dunD55ZfTuXNn13FEQs7u3bvZv38/EyZMoHDhwq7jSA7o/GwS9F555RU2bNjAuHHj9MIikktJSUlMnjyZhg0b6v9PCNGBbeJEr169mD17do6WPXToELfccgtt22Y+vF5Ezmfr1q1s3ryZcePG6cxfIUblLAG3ePFixo4dS4sWLahRo8YFly9SpAgxMTF6cRHJBWstH374IT179tT/nRCkcpaASktLo3PnztSoUYPPP/+cokWLuo4kEnbWrVvHihUr6NOnj+sokkcqZwmoN954gzVr1vDee++pmEX8ID09nRUrVtCxY0fXUSQfVM4SMCdOnKBfv3789a9/5f7773cdRyTsrFixgiVLltCtWzfXUSSftLe2BMywYcM4duwYkydP1mdgIj528uRJjh8/TteuXV1HER/QyFn8ZuzYsSxevBjw7JyyYMECHn/8cRo2bOg4mUh4+e6771i6dCm9e/d2HUV8ROUsfvN///d/nDlzhksvvRSA22+/nREjRjhOJRJeNm/ezCWXXEJMTIzrKOJDKmfxq7Zt2/Lmm2+6jiESlr7++mt+/fVXfcYchlTOIiIhaMmSJVxzzTW0bNnSdRTxA+0QJiISYmJjY9mwYQPly5d3HUX8RCNnEZEQMmfOHJo3b07z5s1dRxE/0shZRCRErF69mlOnTlG6dGnXUcTPVM7iF2vXrmXfvn1UrlzZdRSRsPD2229TpkwZHn30UddRJABUzuJz1lq6du1KyZIldUIEER/YvXs3hQsXplq1aq6jSIConMXn5s6dyzfffMOQIUMoU6aM6zgiIe3VV18lLi6OBx54wHUUCSCVs/hUUlIS3bt358orr+SZZ55xHUckpB05coTq1atz7bXXuo4iAaa9tcWnJk+ezPbt2/nyyy+Jjo52HUckZE2cOJEmTZrQqlUr11HEAZWz+MzBgwcZNmwYd911F7fffrvrOCIhyVrLvn37uPHGG2natKnrOOKINmuLT/z222+0bNmS5ORkxo8f7zqOSEiy1jJy5Eh27typYo5wGjlLvq1cuZK77rqLhIQE5s+fT506dVxHEgk51lpWr15N+/btf/+yGIlcGjlLvnz++ef87W9/o1ChQixdupQWLVq4jiQSkoYPH05qaqqKWQCNnCUfpk2bxgsvvEDDhg35/PPPqVixoutIIiEnPT2defPm0a1bN4oVK+Y6jgQJjZwl19LT0+nZsyfPP/88rVu3ZvHixSpmkTyaMGECNWrUUDHLH2jkLLmSkJDAI488wkcffUSnTp2YNGkSUVFRrmOJhJzU1FRmzJhB9+7dMca4jiNBRiNnyZWJEyfy0UcfMWHCBKZMmaJiFsmjd955h5tvvlnFLFnSyFly5ejRoxQvXlznzBbJo6SkJEaPHs2AAQNUzJItjZxFRALEWsvXX3/No48+qmKW81I5i4gEwNmzZ+natSu33norNWrUcB1HgpzKWUTEzxISEli7di29e/emUKFCruNICFA5i4j40alTp+jRowd169bVIYeSYypn+ZPBgwdTsGDBLH8mTpxIgQJ62ojkRFxcHDt37mTo0KGULFnSdRwJIdpbW/5k3bp1lC5dmqeffjrL+ddcc02AE4mEnuPHjzNgwABeeuklSpUq5TqOhBiVs2SpQoUKDB8+3HUMkZB05MgR9u3bx8iRIylRooTrOBKCtH1SRMSHTp8+zZAhQ6hVq5aKWfJMI2cRER/Zt28fO3fuZMKECdorW/JFI2cRER9ITU1l8uTJNG7cWMUs+aaRs3D06FHatWvHqVOnANi5cydVq1Z1nEokdOzYsYM1a9YwZswY11EkTGjkLGzevJklS5ZQpEgRqlevzs0338zzzz/vOpZISLDW8tFHH3HXXXe5jiJhRCNn+d3QoUO59dZbXccQCRkbN27ku+++o2fPnjuAagUAACAASURBVK6jSJjRyFlEJA/S0tJYuXIlTzzxhOsoEoY0chYRyaVffvmFBQsWEBMT4zqKhCmNnEVEciEuLo64uDhtyha/0sg5jL3yyiv8+OOPABw8eJAZM2Zkudzhw4cDGUskZP3www98++239O/f33UUCXMq5zA2ZMgQ4uPjKVu2LImJiWzZsiXbZevXr0+dOnUCmE4ktGzcuJHSpUvTr18/11EkAqicw1yHDh149dVXiY2NpXnz5q7jiISkxYsXs3z5cnr06IExxnUciQAqZxGR81i8eDF169bl5ptvdh1FIoh2CBMRycYPP/zA2rVrqVChgusoEmE0chYRycKnn37KjTfeyI033ug6ikQgjZxFRDLZsGEDR48epVy5cq6jSIRSOYuIZPDf//6XwoUL68xf4pTKWUTE6+DBgxQoUIDLL7/cdRSJcCpnERHg9ddfZ8+ePbRv3951FBGVs4jI8ePHqVSpEk2aNHEdRQTQ3toiEuGmTJnC1VdfTevWrV1HEfmdyjnErV+/nv3792c5LykpKcBpRELL3r17adq0KU2bNnUdReQPVM4hylrLhAkT6NmzJ9babJcrUaJEAFOJhI5Ro0bRtGlT/v73v7uOIvInKucQlJqaSufOnZk2bRr/+Mc/6Ny5c5bn+zXG0LBhQwcJRYKXtZaVK1fSoUMHqlev7jqOSJZUziEmPj6eBx98kC+++IKePXsyatQoChTQfn0iOTV69GhuvvlmFbMENZVzCDlw4AB33XUXq1evZurUqTz33HOuI4mEjPT0dD777DM6d+5M0aJFXccROS+Vc4hYv349d955J8eOHWPu3Lnas1Qkl6ZOncpf//pXFbOEBJVzCPjmm2+47777KFasGEuWLKFRo0auI4mEjLS0NF577TU6deqk72KWkKEPK4Pc2rVradWqFdWrV2fZsmUqZpFceu+992jevLmKWUKKRs5BzFpLly5dKF68OIsWLaJs2bKuI4mEjOTkZEaMGMHAgQO106SEHJVzEPv000/59ttv+fe//61iFsmF9PR0Fi9ezKOPPqpilpCkZ22QSkpKonv37lx11VU8/fTTruOIhIyEhAS6du3KTTfdxKWXXuo6jkieaOQcpCZNmsSOHTtYuHAhBQvqzySSE2fPnmXjxo306tVLe2VLSNPIOQgdOHCA4cOH06ZNG1q2bOk6jkhIOH36ND179qRmzZpUqVLFdRyRfNGQzJEXXniB999/P8t5CQkJJCUlMW7cuACnEglNJ0+eZNeuXQwePJgyZcq4jiOSbypnR7777juKFi1Kq1atspx/xx13ULt27QCnEgk9J06coG/fvgwfPpxLLrnEdRwRn1A5O9SgQQNefvll1zFEQtbRo0fZvXs3I0eOpGTJkq7jiPiMPnMWkZCUkJDA4MGDqV27topZwo5GziIScg4cOMDGjRuZOHEi0dHRruOI+JxGziISUtLT05k0aRI33HCDilnClkbOAbJ9+3ZefPFFkpKSANi2bRs1a9Z0G0okxOzatYtly5YxevRo11FE/CpHI2djzB3GmM3GmG3GmN7ZLPOAMWaDMWa9MWaWb2OGvqVLlzJv3jxOnDhBYmIiDRo0oF27dq5jiYSUjz/+mPvuu891DBG/u+DI2RgTBUwFbgX2Aj8bY+ZaazdkWKY20Af4i7U2zhhT3l+BQ93777/PZZdd5jqGSEjZvHkzCxcupFu3bq6jiARETkbO1wPbrLU7rLXJwGygbaZl/gVMtdbGAVhrD/s2pohEqrS0NFatWsUzzzzjOopIwOSknKsAezJM7/VellEdoI4xZqkxZpkx5g5fBRSRyPXrr78ya9Ys2rdvr3PMS0Tx1bO9IFAbaA5UBZYYY6621p7IuJAx5ingKYAKFSoQGxv7+7z4+Pg/TIebjRs3ArBs2TJ2794d8PsP9/Xrmtav7508eZKdO3fStm1brVs/0nPXf/KzbnNSzvuAahmmq3ovy2gv8JO1NgXYaYzZgqesf864kLV2OjAdoHHjxrZ58+a/z4uNjSXjdLg5V8g33HCDk8+cw339uqb161vLly9n0aJFDBkyROvWz7R+/Sc/6zYnm7V/BmobYy41xhQCHgTmZlrmEzyjZowxZfFs5t6Rp0QiEtHWr19PyZIlGTx4sOsoIs5csJyttalAJ+ArYCPwvrV2vTFmqDGmjXexr4BjxpgNwCKgp7X2mL9Ci0h4Wrp0KXPnzqVOnToYY1zHEXEmR585W2vnAfMyXTYww+8W6Ob9ERHJtSVLllCnTh1uvPFGFbNEPJ2+U0ScW7FiBatWraJixYoqZhFUziLi2GeffUblypXp0qWL6ygiQUPlLCLObN++nQMHDlC5cmXXUUSCispZRJx47733SEpK4qmnnnIdRSToqJxFJOCOHTtGamoq9erVcx1FJCjpfHgiElBvvfUWtWrV4qGHHnIdRSRoaeQsIgFz8uRJypUrx0033eQ6ikhQ08hZRAJi2rRp1KpVi9atW7uOIhL0VM4+lJqayrp160hPT//TvF27dgU+kEiQ2LNnD02aNKFJkyauo4iEBJWzD40ePZr+/fufd5miRYsGKI1IcBg/fjzXXHMNt956q+soIiFD5exDn3zyCddeey1Dhw7Ncn65cuWoVKlSgFOJuGGtZfny5Tz44INUqZL5K+BF5HxUzj5y6NAhVqxYwbBhw2jTps2FryAS5iZMmMANN9ygYhbJA5Wzj3z11VcA3HnnnY6TiLhlrWXOnDk8//zzFClSxHUckZCkQ6l8ZN68eVSsWJEGDRq4jiLi1PTp06lRo4aKWSQfNHL2gdTUVBYsWMA999xDgQJ6vyORKS0tjWnTptGpUyd9s5RIPqlJfOCnn34iLi6OVq1auY4i4szHH39MixYtVMwiPqBy9oF58+YRFRWlQ0UkIqWkpDBgwADuvfderrrqKtdxRMKCytkH5s2bx1/+8hdKlSrlOopIQKWnp7N06VIeffRRChbUp2QivqJyzqf9+/ezevVqbdKWiJOYmEjXrl257rrrqFWrlus4ImFFb3Xz6csvvwR0CJVEloSEBDZv3kyPHj0oXry46zgiYUcj53yaN28eVapU4eqrr3YdRSQgzpw5Q8+ePalcuTLVqlVzHUckLGnknEszZ85k9OjRWGsB2LZtG4899pj2UJWIcPr0aXbu3MmAAQMoX7686zgiYUsj51zYt28fzz33HMYY6tevT/369WnXrh0vvvii62gifnf69Gl69+5N5cqVqVChgus4ImFNI+dc6NOnDykpKcydO5fLLrvMdRyRgDl+/Dg7duxgxIgRlCxZ0nUckbCnkXMO/fTTT7z99tt0795dxSwRJTk5mYEDB1K7dm0Vs0iAaOScA+np6XTu3JmKFSvSp08f13FEAubQoUOsXr2aSZMm6ThmkQDSyDkHZs2axU8//cSoUaN02IhEDGstU6ZM4aabblIxiwSY/sddQHx8PDExMTRp0oRHHnnEdRyRgNizZw+xsbG89NJLrqOIRCSV8wWMHj2a/fv38+GHH+obpyRifPLJJ/zrX/9yHUMkYqmcz2PXrl2MHTuWDh060KxZM9dxRPxu+/btzJ07l65du7qOIhLRNBQ8j169ehEVFcXo0aNdRxHxu5SUFFatWkWnTp1cRxGJeCrnbCxevJgPPviAmJgYqlat6jqOiF+tX7+e4cOHc//99xMdHe06jkjEUzlnIS0tjS5dulCtWjV69OjhOo6IXx0+fJgTJ04wcOBA11FExEvlnIUZM2awevVqxo4dy0UXXeQ6jojfrFy5kilTpnDjjTcSFRXlOo6IeKmcs/Dxxx9zxRVX8MADD7iOIuI369ato3jx4gwbNkxf3CISZFTOWUhPT6dUqVJ6wZKwtXz5cj755BNq166t57lIEFI5i0SY7777jqpVq9KvXz8Vs0iQUjmLRJBff/2V5cuXU7lyZRWzSBBTOYtEiHnz5lGyZEm6d+/uOoqIXIDKWSQC7Nmzh127dlGjRg3XUUQkB1TOImHuww8/5NixYzz33HOuo4hIDqmcRcLYyZMnSUhIoEGDBq6jiEgu6IsvRMLU22+/TZUqVfRVpyIhSCNnkTB06tQpypQpQ4sWLVxHEZE80MhZJMy8+uqrVK1aldatW7uOIiJ5pHIWCSO//fYbjRs35rrrrnMdRUTyQZu1RcLE5MmT2bBhg4pZJAxo5CwS4qy1/PDDDzzwwANUqlTJdRwR8QGNnEVC3JQpU0hNTVUxi4QRjZxFQpS1lg8++IBnnnmGwoULu44jIj6kkbNIiJoxYwY1atRQMYuEIY2cRUJMeno6U6ZMoXPnzvpmKZEwpZGzSIj5/PPPadGihYpZJIypnEVCRGpqKgMGDOD222/nmmuucR1HRPxI5SwSAtLS0li+fDmPPPKIPmMWiQAqZ5Egl5ycTI8ePbjyyiupU6eO6zgiEgDaIUwkiCUmJrJlyxa6dOlC6dKlXccRkQDRyFkkSJ09e5aePXtSrlw5atSo4TqOiASQRs4iQejMmTNs376dvn376sxfIhFII2eRIHPmzBl69epFxYoVVcwiEUojZ5EgcuLECTZv3syIESMoWbKk6zgi4ohGziJBIjU1lYEDB1KnTh0Vs0iE08hZJAgcOXKEn376iYkTJxIVFeU6jog4ppGziGPWWv7973/TvHlzFbOIABo5izi1b98+vvrqK4YMGeI6iogEEY2cRRyx1jJ37lzat2/vOoqIBBmNnEUc2LlzJ++99x69e/d2HUVEgpBGziIBlpSUxOrVq+nWrZvrKCISpFTOIgG0ceNGhgwZwr333kuhQoVcxxGRIKVyFgmQgwcPcvLkSYYNG+Y6iogEOZWzSACsXr2ayZMnc/311+twKRG5IJWziJ+tW7eOYsWK8dJLL1GggP7LiciF6ZVCxI9WrVrFhx9+SK1atVTMIpJjerUQ8ZOlS5dStmxZBg0ahDHGdRwRCSEqZxE/2LRpE99//z3VqlVTMYtIrqmcRXxswYIFFChQgJiYGBWziORJjsrZGHOHMWazMWabMSbbUxoZY9oZY6wxprHvIvqftZY1a9bwww8/8MMPPxAXF+c6koSoQ4cOsWnTJurUqeM6ioiEsAuevtMYEwVMBW4F9gI/G2PmWms3ZFquONAZ+MkfQf1p2bJl3HjjjX+47JZbbnGURkLVJ598QqVKlXjxxRddRxGREJeTc2tfD2yz1u4AMMbMBtoCGzItNwwYDfT0acIAOHXqFAATJ06kXr16AFx99dUuI0mISUhI4NSpU9xzzz2uo4hIGMhJOVcB9mSY3gs0zbiAMaYRUM1a+4UxJuTK+ZymTZvSrFkz1zEkxLz77rvs2bOHXr16uY4iImEi399KZYwpAEwAHsvBsk8BTwFUqFCB2NjY3+fFx8f/YTqQ1qxZA3iOSU1KSnKSwd9crt9wdubMGX777Tfq16+v9esneu76l9av/+Rn3eaknPcB1TJMV/Vedk5xoD4Q690ztSIw1xjTxlq7IuMNWWunA9MBGjdubJs3b/77vNjYWDJOB9K5Qm7UqFHYjpxdrt9w9eabb3LJJZfQu3dvrV8/0rr1L61f/8nPus1JOf8M1DbGXIqnlB8EOpybaa09CZQ9N22MiQV6ZC5mkXCyY8cOGjVqRIMGDVxHEZEwdMFDqay1qUAn4CtgI/C+tXa9MWaoMaaNvwMGwrFjxwB0ekXJkalTp7J+/XoVs4j4TY4+c7bWzgPmZbpsYDbLNs9/rMBJSUlh2LBhXH755XqxlQv67rvvuP/++ylfvrzrKCISxvK9Q1ioe/nll9m0aROffvophQsXdh1HgtjLL7/MFVdcoWIWEb+L6HI+duwYgwcPpmXLltx9992u40iQstYye/ZsnnzySaKjo13HEZEIENEfsg4aNIhTp04xceJEnQNZsjVr1ixq1qypYhaRgInYkfO6det4+eWXefbZZ6lfv77rOBKE0tPTmTRpEp07dyYqKsp1HBGJIGFdzvfddx+rV6/Ocl5cXBwlS5ZkyJAhAU4loWLBggX8/e9/VzGLSMCFbTkfPnyYOXPm0KxZM2rVqpXlMo899hhlypQJcDIJdmlpaQwaNIi+ffty0UUXuY4jIhEobMv5l19+AWDEiBE6+43kWFpaGqtWreKhhx5SMYuIM2G7Q9i5ctaxy5JTKSkp9OzZkxo1anDllVe6jiMiESxsR86rVq3i0ksvpVSpUq6jSAhISkpi69atdOrUSccxi4hzYT1ybtiwoesYEgISExPp2bMnpUqV4rLLLnMdR0QkPMv51KlTbNu2TeUsF3T27Fm2bNlC7969qVq1qus4IiJAmJbzue9nVjnL+SQmJtKrVy/Kly9P5cqVXccREfldWH7mfG5nMJWzZOfUqVOsXbuWESNGUKJECddxRET+ICxHzr/88gvly5enUqVKrqNIEEpPT2fAgAHUrVtXxSwiQSlsR84NGzbU+bLlT44dO8aSJUuYOHGivr9bRIJW2L06JSUlsX79em3SlixNmzaNW265RcUsIkEt7EbO69atIzU1lUaNGrmOIkHk4MGDfPrppwwYMMB1FBGRCwq74YN2BpPMrLV89tlnPPLII66jiIjkSNiNnH/55ReKFy+uk0kIAL/99hszZ87UiFlEQkpYjpwbNGigzxSFxMREfv31V3r16uU6iohIroRVg6WlpbFmzRpt0ha2bNnCwIEDueuuuyhcuLDrOCIiuRJW5bxlyxbOnj2rco5w+/fv5+TJk4wYMUKH04lISAq5z5wPHz7M4sWLs5z3008/AdoZLJKtXbuWd955hxEjRhAVFeU6johInoRcOQ8aNIhXXnkl2/mlSpWiXr16AUwkwWLdunUUKVKEkSNHap8DEQlpIVfOCQkJVKpUiYULF2Y5v3z58kRHRwc4lbi2bt063n//fQYPHqxiFpGQF3LlDFCoUCGuuuoq1zEkSPz4449UrFiRIUOG6DNmEQkLGmJISNuxYweLFi2iZs2aKmYRCRsqZwlZ33zzDWfPnqVPnz4qZhEJKypnCUnHjx9n3bp11K9fX8UsImEn5D5z3rdvn3b4inCff/45JUuWpHPnzq6jiIj4RUiNnL/++mu+/vprHn/8cddRxJHExESOHz/OX//6V9dRRET8JmRGzqmpqXTp0oVLL72Url27uo4jDrz//vsUKVKEjh07uo4iIuJXIVPO06dPZ/369Xz00UcUKVLEdRwJsFOnTlGiRAnuuOMO11FERPwuJMr5+PHjDBgwgObNm3Pvvfe6jiMB9p///IeLLrqI+++/33UUEZGACIlyHjJkCCdOnGDSpEnaMzfCbN26lUaNGnH11Ve7jiIiEjBBWc5du3Zl2rRpv08nJyfz9NNPc+211zpMJYH26quvUrFiRdq2bes6iohIQAVlOa9Zs4by5cvz8MMPA1C8eHE6derkOJUE0qJFi2jXrh1ly5Z1HUVEJOCCspwBLr30UkaOHOk6hjjw+uuvU716dRWziESsoC1niTzWWt555x0ee+wxChbUU1NEIldInYREwtuHH35IzZo1VcwiEvH0KijOWWuZMGECL774ok7NKiKCRs4SBBYtWsTNN9+sYhYR8VI5izPp6en079+fxo0b07hxY9dxRESChjZrixNpaWmsXbuWBx98kBIlSriOIyISVDRyloBLSUkhJiaGcuXKUb9+fddxRESCjkbOElDJycls27aNp59+mipVqriOIyISlDRyloBJSkqiV69eXHTRRdSuXdt1HBGRoKWRswREQkICW7ZsoWfPnhoxi4hcgEbO4ncpKSn07NmTsmXLqphFRHJAI2fxq9OnT7Nq1SpGjhxJ8eLFXccREQkJGjmL31hrGTx4MPXq1VMxi4jkgkbO4hdxcXEsXLiQsWPHUqCA3gOKiOSGXjXFL6ZPn85tt92mYhYRyQONnMWnDh8+zPvvv09MTIzrKCIiIUvDGvEZay1ffPEF//znP11HEREJaRo5i0/s3buX6dOnM3ToUNdRRERCnkbOkm8JCQmsW7eOvn37uo4iIhIWVM6SL9u3b6dfv37cfvvtFClSxHUcEZGwoHKWPNu7dy8nT55k9OjRGGNcxxERCRsqZ8mTjRs3MmXKFK655hqio6NdxxERCSsqZ8m19evXU7BgQUaOHEnBgtqnUETE11TOkiubNm1i1qxZXH755URFRbmOIyISllTOkmPLly8nKiqK4cOH68xfIiJ+pFdYyZG9e/fy5ZdfUqtWLe38JSLiZ/rAUC5o8eLFFC9enAEDBqiYRUQCQCNnOa/Tp0/zyy+/0LBhQxWziEiAaOQs2Zo/fz7R0dF06dLFdRQRkYiikbNkKTk5mSNHjtCyZUvXUUREIo5GzvInH3/8Menp6XTs2NF1FBGRiKRylj84efIkF198MbfddpvrKCIiEUvlLL975513KFCgAB06dHAdRUQkoqmcBfCc+atRo0bUq1fPdRQRkYgXFOW8ZcsWHnroIay1ABw9epRmzZo5ThU53njjDUqVKkW7du1cRxEREYKonPfv388999xDuXLlAGjTpo3jVJHhm2++4d577+WSSy5xHUVERLyCopzP6devH40bN3YdI2LMnDmTsmXLqphFRIJMUJWzBM7MmTPp0KGDvvJRRCQI6SQkEWju3LlUr15dxSwiEqRyVM7GmDuMMZuNMduMMb2zmN/NGLPBGPOrMeYbY0wN30eV/LLWMn78eG6//XaaN2/uOo6IiGTjguVsjIkCpgKtgHpAe2NM5uNtfgEaW2uvAT4Exvg6qOTf0qVLuemmmyhcuLDrKCIich45GTlfD2yz1u6w1iYDs4G2GRew1i6y1p71Ti4Dqvo2puRHeno6b775JldeeSVNmzZ1HUdERC4gJx86VgH2ZJjeC5zvFf4JYH5WM4wxTwFPAVSoUIHY2FgA1q5dC8DKlSuJj4/PQSTJqbS0NHbv3k2TJk1+X8/ie/Hx8b8/n8W3tG79S+vXf/Kzbn26R5Ax5mGgMXBzVvOttdOB6QCNGze25z73PFfI1113nQ6l8qHU1FT69u3L888/z86dO/U5sx/FxsZq/fqJ1q1/af36T37WbU42a+8DqmWYruq97A+MMS2BfkAba21SntKIz6SkpLBt2zaeeOIJatTQ/nkiIqEkJ+X8M1DbGHOpMaYQ8CAwN+MCxpiGwKt4ivmw72NKbiQnJ9OrVy+io6O54oorXMcREZFcuuBmbWttqjGmE/AVEAW8aa1db4wZCqyw1s4FxgIXAx8YYwB2W2t1/k0HEhMT2bRpEz169KBKlSqu44iISB7k6DNna+08YF6mywZm+L2lj3NJHqSlpdGrVy969uypYhYRCWE6RVSYOHPmDMuWLWPkyJEUK1bMdRwREckHnb4zTAwdOpT69eurmEVEwoBGziHuxIkTfPHFF4waNQrv5/0iIhLiNHIOcW+88QatWrVSMYuIhBGNnEPU0aNHmTlzJt27d3cdRUREfEwj5xBkreXLL7/kX//6l+soIiLiByrnELN//3769u3Lww8/TPHixV3HERERP1A5h5AzZ86wYcMGBg4ceOGFRUQkZKmcQ8SuXbvo27cvLVq0oGjRoq7jiIiIH6mcQ8DevXs5ceIEY8eOpUAB/clERMKdXumD3JYtW5g4cSJXXXUVhQoVch1HREQCQOUcxDZs2ADA6NGjiY6OdpxGREQCReUcpLZv387MmTO5/PLLKVhQh6OLiEQSlXMQWrlyJUlJSYwYMYKoqCjXcUREJMBUzkHm8OHDfPbZZ1x55ZXa+UtEJEJpe2kQ+f777ylYsCCDBw92HUVERBzS0CxIJCQk8PPPP9O0aVPXUURExDGNnIPAwoULSU5OpmvXrq6jiIhIENDI2bGUlBQOHTpE69atXUcREZEgoZGzQ3PnziU+Pp6HH37YdRQREQkiKmdH4uLiKFasGG3atHEdRUREgozK2YHZs2eTnJxMx44dXUcREZEgpHIOsPXr19OwYUOuuOIK11FERCRIaYewAJo5cybr169XMYuIyHlp5BwgCxYsoG3btpQsWdJ1FBERCXIaOQfA7NmzSUpKUjGLiEiOaOTsZ2+99RYPPfSQvvJRRERyTCNnP/ryyy+pWrWqillERHJFI2c/sNYyfvx4nn32WYoVK+Y6joiIhBiNnH3MWsvPP/9Ms2bNVMwiIpInKmcfSk9PZ9CgQVSvXp2//OUvruOIiEiIUjn7SHp6Olu2bOGee+6hYsWKruOIiEgIUzn7QFpaGn369KFgwYI0atTIdRwREQlx2iEsn1JTU9m+fTv//Oc/qVWrlus4IiISBjRyzoeUlBR69eqFMYa6deu6jiMiImFCI+c8SkpKYv369XTv3p0qVaq4jiMiImFEI+c8SE9PJyYmhjJlyqiYRUTE5zRyzqWzZ8+yZMkSRo4cSdGiRV3HERGRMKSRcy699NJLXHvttSpmERHxG42cc+jUqVPMmTOH4cOHY4xxHUdERMKYRs45NGPGDFq3bq1iFhERv9PI+QKOHz/O66+/Tq9evVxHERGRCKGR83mkp6ezcOFCnn76addRREQkgqics3Hw4EFiYmJ44IEHKFmypOs4IiISQVTOWTh9+jSbNm1i8ODB+oxZREQCTuWcye7du+nbty833XSTvo9ZREScUDlnsGfPHk6cOMG4ceMoWFD7yomIiBsqZ6/t27czceJE6tatS+HChV3HERGRCKbhIbBp0yYARo8eTXR0tOM0IiIS6SJ+5Lx7925mzJhB7dq1VcwiIhIUInrkvHr1agoUKMDIkSMpUCDi36eIiEiQiNhGOnHiBHPmzKF+/foqZhERCSoROXJetmwZycnJDBkyxHUUERGRP4m4IWNycjI//vgjf/3rX11HERERyVJEjZy//fZbTpw4QdeuXV1HERERyVbEjJxTUlI4cOAA9913n+soIiIi5xURI+cvvviCI0eO8Nhjj7mOIiIickFhX85Hjx6lWLFitG7diF8pvQAABrhJREFU2nUUERGRHAnrcv7ggw84ffo0jz/+uOsoIiIiORa25fzrr7/SsGFDatWq5TqKiIhIroTlDmHvvvsua9euVTGLiEhICruR8/z582ndujUlSpRwHUVERCRPwqqcP/roIwoUKKBiFhGRkBY25fzWW2/Rvn17fReziIiEvLD4zPnbb7+lYsWKKmYREQkLIT1yttYyYcIEnnzySUqWLOk6joiIiE+E7MjZWsuvv/5KkyZNVMwiIhJWQrKcrbUMGzaM0qVL87e//c11HBEREZ8Kuc3a6enp7Nixg1atWlG9enXXcURERHwupEbO6enp9O/fn5SUFJo0aeI6joiIiF+EzMg5LS2N7du38/DDD3PllVe6jiMiIuI3ITFyTk1NJSYmhrS0NOrVq+c6joiIiF8F/cg5JSWFNWvW0L17dypVquQ6joiIiN8F9cjZWkvv3r255JJLVMwiIhIxgnbknJiYyNdff81LL71EkSJFXMcREREJmKAdOY8ZM4aGDRuqmEVEJOLkqJyNMXcYYzYbY7YZY3pnMb+wMeY97/yfjDE18xooPj6eN954gwEDBlClSpW83oyIiEjIumA5G2OigKlAK6Ae0N4Yk3mX6SeAOGttLWAiMDqvgd5++23atGmDMSavNyEiIhLScjJyvh7YZq3dYa1NBmYDbTMt0xb4j/f3D4FbTB7a9c033+TZZ5+lXLlyub2qiIhI2MhJOVcB9mSY3uu9LMtlrLWpwEmgTG7D3H///bm9ioiISNgJ6N7axpingKcAKlSoQGxsLOA5lnnQoEGcOXPm98vEt+Lj47Vu/Ujr13+0bv1L69d/8rNuc1LO+4BqGaarei/Lapm9xpiCQEngWOYbstZOB6YDNG7c2DZv3vz3eaVLlybjtPhWbGys1q8faf36j9atf2n9+k9+1m1ONmv/DNQ2xlxqjCkEPAjMzbTMXOD/t3fvIHaUYRjH/483RIwXWAQLTRAMGGJh2CI2XlBEtlgLRRSCRoJFRAsNVhaKlqKFIMSIQRQUtZEFlRQaWRBXCARDkkKixhAUElHTBMXLYzFTLIu759uNczvn+cHAnD3nDC8Pw7znm5md7+F6/T7gM9teU0URERETbuTI2fZfkh4H9gHnA3ttH5H0PHDA9hzwBvC2pGPAL1QNPCIiItZAXQ1wJZ0Gflj0pyng506KmQzJt1nJtznJtlnJtzlLs11vu+jfkTprzktJOmB7uus6xlXybVbybU6ybVbybc65ZNvbx3dGRERMqjTniIiInulTc97TdQFjLvk2K/k2J9k2K/k2Z83Z9uaac0RERFT6NHKOiIgIOmjObU4/OYkK8n1K0lFJhyR9Kml9F3UO0ahsF33uXkmWlDtgV6EkX0n31/vvEUnvtF3jUBUcF66VtF/SwfrYMNNFnUMkaa+kU5IOL/O+JL1SZ39I0paiDdtubaF6iMm3wHXARcDXwKYln3kM2F2vPwC812aNQ14K870duKRe35l8/79s68+tA+aBBWC667qHshTuu9cDB4Er69dXdV33EJbCbPcAO+v1TcDxruseygLcAmwBDi/z/gzwCSBgK/BVyXbbHjm3Nv3khBqZr+39ts/WLxeonpUeo5XsuwAvUM1n/nubxY2BknwfBV61/SuA7VMt1zhUJdkauKxevxz4scX6Bs32PNWTMZdzD/CWKwvAFZKuHrXdtptza9NPTqiSfBfbQfWLLkYbmW19uuoa2x+1WdiYKNl3NwIbJX0haUHS3a1VN2wl2T4HbJN0EvgYeKKd0ibCao/LQMtTRkZ/SNoGTAO3dl3LOJB0HvAysL3jUsbZBVSntm+jOuMzL+lG2791WtV4eBB40/ZLkm6mmiths+1/ui5sUrU9cl7N9JOsNP1k/KeSfJF0J/AMMGv7j5ZqG7pR2a4DNgOfSzpOdW1pLjeFFSvZd08Cc7b/tP098A1Vs46VlWS7A3gfwPaXwMVUz4WOc1d0XF6q7eac6SebNTJfSTcBr1E15lyzK7ditrbP2J6yvcH2Bqrr+bO2D3RT7uCUHBs+pBo1I2mK6jT3d20WOVAl2Z4A7gCQdANVcz7dapXjaw54qL5reytwxvZPo77U6mltZ/rJRhXm+yJwKfBBfZ/dCduznRU9EIXZxhoV5rsPuEvSUeBv4GnbOas2QmG2u4DXJT1JdXPY9gyKykh6l+pH41R9zf5Z4EIA27upruHPAMeAs8AjRdtN/hEREf2SJ4RFRET0TJpzREREz6Q5R0RE9Eyac0RERM+kOUdERPRMmnNERETPpDlHRET0TJpzREREz/wLTk3xfdjjF/wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYzWU4z4S39J"
      },
      "source": [
        "## Build a Single Hidden Layer Neural Network\n",
        "\n",
        "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQr8jwlsS39J"
      },
      "source": [
        "## First let's normalize the data\n",
        "## This aids the training of neural nets by providing numerical stability\n",
        "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
        "\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3rvFpL-S39J"
      },
      "source": [
        "# Define the Model \n",
        "# Input size is 8-dimensional\n",
        "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
        "\n",
        "model_1 = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlbl2lV4S39K",
        "outputId": "9e974619-142b-4f07-83d3-fec8e1e8c33b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#  This is a nice tool to view the model you have created and count the parameters\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvkspPWCS39K"
      },
      "source": [
        "### Comprehension question:\n",
        "Why do we have 121 parameters?  Does that make sense?\n",
        "\n",
        "\n",
        "Let's fit our model for 200 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkDUyV9ZS39K",
        "outputId": "b728228a-9055-4331-a5b8-9b9fa0e5723f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fit(Train) the Model\n",
        "\n",
        "# Compile the model with Optimizer, Loss Function and Metrics\n",
        "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
        "\n",
        "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
        "# the fit function returns the run history. \n",
        "# It is very convenient, as it contains information about the model fit, iterations etc."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 14ms/step - loss: 0.7748 - accuracy: 0.4294 - val_loss: 0.7940 - val_accuracy: 0.4375\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7441 - accuracy: 0.4586 - val_loss: 0.7818 - val_accuracy: 0.4531\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.4858 - val_loss: 0.7703 - val_accuracy: 0.4531\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.5178 - val_loss: 0.7595 - val_accuracy: 0.4635\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7177 - accuracy: 0.5046 - val_loss: 0.7493 - val_accuracy: 0.4740\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5795 - val_loss: 0.7396 - val_accuracy: 0.4948\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5651 - val_loss: 0.7304 - val_accuracy: 0.5365\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.6005 - val_loss: 0.7217 - val_accuracy: 0.5573\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.6137 - val_loss: 0.7135 - val_accuracy: 0.5781\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.6584 - val_loss: 0.7057 - val_accuracy: 0.6094\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.6724 - val_loss: 0.6982 - val_accuracy: 0.6198\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.7261 - val_loss: 0.6911 - val_accuracy: 0.6354\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.7261 - val_loss: 0.6844 - val_accuracy: 0.6406\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7143 - val_loss: 0.6779 - val_accuracy: 0.6458\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7459 - val_loss: 0.6717 - val_accuracy: 0.6458\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.7430 - val_loss: 0.6658 - val_accuracy: 0.6562\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.7308 - val_loss: 0.6602 - val_accuracy: 0.6510\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.7463 - val_loss: 0.6548 - val_accuracy: 0.6510\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.7569 - val_loss: 0.6497 - val_accuracy: 0.6562\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.7612 - val_loss: 0.6448 - val_accuracy: 0.6458\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.7348 - val_loss: 0.6401 - val_accuracy: 0.6562\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.7261 - val_loss: 0.6356 - val_accuracy: 0.6562\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.7515 - val_loss: 0.6314 - val_accuracy: 0.6562\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7405 - val_loss: 0.6273 - val_accuracy: 0.6719\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7472 - val_loss: 0.6234 - val_accuracy: 0.6771\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.7646 - val_loss: 0.6197 - val_accuracy: 0.6875\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7530 - val_loss: 0.6161 - val_accuracy: 0.6979\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7436 - val_loss: 0.6127 - val_accuracy: 0.7031\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7384 - val_loss: 0.6095 - val_accuracy: 0.7031\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7394 - val_loss: 0.6064 - val_accuracy: 0.7031\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7428 - val_loss: 0.6034 - val_accuracy: 0.7083\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7277 - val_loss: 0.6006 - val_accuracy: 0.7083\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.7289 - val_loss: 0.5978 - val_accuracy: 0.7083\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7032 - val_loss: 0.5952 - val_accuracy: 0.7083\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7138 - val_loss: 0.5926 - val_accuracy: 0.7031\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7368 - val_loss: 0.5902 - val_accuracy: 0.7031\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7406 - val_loss: 0.5878 - val_accuracy: 0.7135\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7323 - val_loss: 0.5855 - val_accuracy: 0.7135\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7438 - val_loss: 0.5834 - val_accuracy: 0.7135\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7341 - val_loss: 0.5813 - val_accuracy: 0.7135\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7458 - val_loss: 0.5792 - val_accuracy: 0.7135\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7307 - val_loss: 0.5773 - val_accuracy: 0.7188\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7259 - val_loss: 0.5753 - val_accuracy: 0.7135\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7247 - val_loss: 0.5735 - val_accuracy: 0.7135\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7154 - val_loss: 0.5716 - val_accuracy: 0.7188\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7819 - val_loss: 0.5699 - val_accuracy: 0.7188\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7510 - val_loss: 0.5681 - val_accuracy: 0.7188\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7256 - val_loss: 0.5664 - val_accuracy: 0.7188\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7552 - val_loss: 0.5648 - val_accuracy: 0.7188\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7170 - val_loss: 0.5632 - val_accuracy: 0.7188\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7384 - val_loss: 0.5617 - val_accuracy: 0.7188\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7445 - val_loss: 0.5602 - val_accuracy: 0.7188\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7758 - val_loss: 0.5587 - val_accuracy: 0.7240\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7629 - val_loss: 0.5573 - val_accuracy: 0.7240\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7483 - val_loss: 0.5559 - val_accuracy: 0.7188\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7484 - val_loss: 0.5546 - val_accuracy: 0.7083\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7764 - val_loss: 0.5533 - val_accuracy: 0.7083\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7147 - val_loss: 0.5520 - val_accuracy: 0.7135\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7281 - val_loss: 0.5507 - val_accuracy: 0.7083\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7410 - val_loss: 0.5495 - val_accuracy: 0.7083\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7477 - val_loss: 0.5483 - val_accuracy: 0.7083\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7604 - val_loss: 0.5472 - val_accuracy: 0.7083\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7330 - val_loss: 0.5461 - val_accuracy: 0.7083\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7255 - val_loss: 0.5450 - val_accuracy: 0.7135\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7422 - val_loss: 0.5440 - val_accuracy: 0.7135\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7471 - val_loss: 0.5429 - val_accuracy: 0.7135\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7709 - val_loss: 0.5419 - val_accuracy: 0.7135\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7580 - val_loss: 0.5410 - val_accuracy: 0.7135\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7474 - val_loss: 0.5401 - val_accuracy: 0.7135\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7732 - val_loss: 0.5392 - val_accuracy: 0.7135\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7251 - val_loss: 0.5383 - val_accuracy: 0.7135\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7539 - val_loss: 0.5374 - val_accuracy: 0.7135\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7367 - val_loss: 0.5366 - val_accuracy: 0.7135\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7906 - val_loss: 0.5358 - val_accuracy: 0.7135\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7422 - val_loss: 0.5350 - val_accuracy: 0.7135\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7659 - val_loss: 0.5342 - val_accuracy: 0.7135\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7500 - val_loss: 0.5335 - val_accuracy: 0.7135\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7647 - val_loss: 0.5327 - val_accuracy: 0.7135\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7450 - val_loss: 0.5320 - val_accuracy: 0.7135\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7672 - val_loss: 0.5313 - val_accuracy: 0.7188\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7366 - val_loss: 0.5306 - val_accuracy: 0.7188\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7279 - val_loss: 0.5300 - val_accuracy: 0.7240\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7715 - val_loss: 0.5293 - val_accuracy: 0.7240\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7352 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7779 - val_loss: 0.5280 - val_accuracy: 0.7240\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7549 - val_loss: 0.5274 - val_accuracy: 0.7240\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7738 - val_loss: 0.5268 - val_accuracy: 0.7240\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7670 - val_loss: 0.5262 - val_accuracy: 0.7240\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7462 - val_loss: 0.5256 - val_accuracy: 0.7240\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7999 - val_loss: 0.5250 - val_accuracy: 0.7240\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7660 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7417 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7598 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7489 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7739 - val_loss: 0.5224 - val_accuracy: 0.7240\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7443 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7581 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7497 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7630 - val_loss: 0.5205 - val_accuracy: 0.7240\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7295 - val_loss: 0.5201 - val_accuracy: 0.7292\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7896 - val_loss: 0.5196 - val_accuracy: 0.7292\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7590 - val_loss: 0.5192 - val_accuracy: 0.7292\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7334 - val_loss: 0.5188 - val_accuracy: 0.7292\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7591 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7343 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7574 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7562 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7698 - val_loss: 0.5168 - val_accuracy: 0.7292\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7525 - val_loss: 0.5164 - val_accuracy: 0.7240\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7878 - val_loss: 0.5161 - val_accuracy: 0.7240\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7742 - val_loss: 0.5157 - val_accuracy: 0.7240\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7633 - val_loss: 0.5153 - val_accuracy: 0.7240\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7496 - val_loss: 0.5150 - val_accuracy: 0.7240\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7672 - val_loss: 0.5146 - val_accuracy: 0.7240\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7648 - val_loss: 0.5143 - val_accuracy: 0.7292\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7676 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7891 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7700 - val_loss: 0.5134 - val_accuracy: 0.7344\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7688 - val_loss: 0.5131 - val_accuracy: 0.7344\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7490 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7558 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.8005 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7890 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7753 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7462 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7774 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7762 - val_loss: 0.5109 - val_accuracy: 0.7344\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7752 - val_loss: 0.5107 - val_accuracy: 0.7344\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7652 - val_loss: 0.5105 - val_accuracy: 0.7344\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7786 - val_loss: 0.5102 - val_accuracy: 0.7344\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7633 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7734 - val_loss: 0.5098 - val_accuracy: 0.7344\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7549 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7813 - val_loss: 0.5094 - val_accuracy: 0.7344\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7661 - val_loss: 0.5092 - val_accuracy: 0.7344\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7647 - val_loss: 0.5090 - val_accuracy: 0.7344\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7584 - val_loss: 0.5088 - val_accuracy: 0.7344\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7852 - val_loss: 0.5086 - val_accuracy: 0.7344\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7521 - val_loss: 0.5084 - val_accuracy: 0.7344\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7701 - val_loss: 0.5083 - val_accuracy: 0.7344\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7699 - val_loss: 0.5081 - val_accuracy: 0.7344\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7828 - val_loss: 0.5079 - val_accuracy: 0.7344\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7618 - val_loss: 0.5078 - val_accuracy: 0.7344\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7564 - val_loss: 0.5076 - val_accuracy: 0.7344\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7522 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7498 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7687 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7565 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7825 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7471 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7250 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7680 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7654 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7965 - val_loss: 0.5062 - val_accuracy: 0.7500\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7709 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8034 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7865 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7670 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7808 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7722 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7732 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7878 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7717 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7463 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7889 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7606 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7804 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7772 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7915 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7987 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7850 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7908 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7751 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7900 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7997 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7756 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7717 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7762 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7831 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7877 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7915 - val_loss: 0.5040 - val_accuracy: 0.7448\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7719 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7955 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7941 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7916 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7825 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8036 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7619 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7897 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7802 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7866 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8010 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7868 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7810 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7742 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7848 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7956 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7858 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7527 - val_loss: 0.5036 - val_accuracy: 0.7396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHIvIi-9S39L"
      },
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
        "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siS4x34MS39L",
        "outputId": "e5855637-fa6b-4d7d-854d-9f71c0edef32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Gx_uPMS39M",
        "outputId": "967d91a6-2b69-4af8-a7eb-f8a6cb5d371f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred_prob_nn_1[:10]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.42619234],\n",
              "       [0.52599967],\n",
              "       [0.38070685],\n",
              "       [0.33090514],\n",
              "       [0.19912493],\n",
              "       [0.4889481 ],\n",
              "       [0.05452159],\n",
              "       [0.28007782],\n",
              "       [0.9152833 ],\n",
              "       [0.22867048]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JklKOLtsS39M",
        "outputId": "7f8b1403-443f-4d48-9314-7dfac9d1dcf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        }
      },
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy is 0.740\n",
            "roc-auc is 0.811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZLTwA1rS39M"
      },
      "source": [
        "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLQYE7oDS39N"
      },
      "source": [
        "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibfTJ2fZS39N",
        "outputId": "0b75d7ff-7331-43a9-84b3-9e09d1df5bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "run_hist_1.history.keys()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0u-ANKYS39N"
      },
      "source": [
        "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxC1HYFsS39N",
        "outputId": "05bd6dfa-38cf-4808-e416-a0f923424430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7e61905f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7hIE_WSS39O"
      },
      "source": [
        "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WgNDscc7S39O",
        "outputId": "a9fbefc4-9fcf-4de6-dfbb-fc8a810cfa13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## Note that when we call \"fit\" again, it picks up where it left off\n",
        "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7812 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7812 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7812 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7812 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.7344\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7344\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7344\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.7344\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7344\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7344\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5038 - val_accuracy: 0.7344\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7812 - val_loss: 0.5038 - val_accuracy: 0.7344\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7344\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7344\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7344\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7847 - val_loss: 0.5039 - val_accuracy: 0.7344\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7344\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7344\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7847 - val_loss: 0.5040 - val_accuracy: 0.7344\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7344\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7344\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7847 - val_loss: 0.5041 - val_accuracy: 0.7344\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7344\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7344\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7847 - val_loss: 0.5042 - val_accuracy: 0.7344\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7344\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7344\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7344\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7344\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7344\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7344\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7344\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7344\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7344\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7344\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.5046 - val_accuracy: 0.7344\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7344\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7344\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7344\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7344\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7344\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7344\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7865 - val_loss: 0.5049 - val_accuracy: 0.7344\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7865 - val_loss: 0.5049 - val_accuracy: 0.7344\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7344\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7865 - val_loss: 0.5050 - val_accuracy: 0.7344\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7865 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7865 - val_loss: 0.5052 - val_accuracy: 0.7396\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7865 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7865 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7865 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7865 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7865 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7865 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7865 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7865 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.5056 - val_accuracy: 0.7344\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7865 - val_loss: 0.5056 - val_accuracy: 0.7344\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7865 - val_loss: 0.5057 - val_accuracy: 0.7344\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.5057 - val_accuracy: 0.7344\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.5057 - val_accuracy: 0.7344\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7865 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7865 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7865 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.5059 - val_accuracy: 0.7344\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7865 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.5063 - val_accuracy: 0.7344\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.5063 - val_accuracy: 0.7344\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7865 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7865 - val_loss: 0.5065 - val_accuracy: 0.7344\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.5065 - val_accuracy: 0.7344\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7882 - val_loss: 0.5065 - val_accuracy: 0.7344\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7882 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7899 - val_loss: 0.5067 - val_accuracy: 0.7292\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.5067 - val_accuracy: 0.7292\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.5067 - val_accuracy: 0.7292\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7899 - val_loss: 0.5067 - val_accuracy: 0.7292\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.5068 - val_accuracy: 0.7292\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.5068 - val_accuracy: 0.7292\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7899 - val_loss: 0.5068 - val_accuracy: 0.7292\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7899 - val_loss: 0.5068 - val_accuracy: 0.7292\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7899 - val_loss: 0.5069 - val_accuracy: 0.7292\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7899 - val_loss: 0.5069 - val_accuracy: 0.7292\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.5069 - val_accuracy: 0.7292\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.5069 - val_accuracy: 0.7292\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7899 - val_loss: 0.5070 - val_accuracy: 0.7292\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7292\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7292\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7292\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7292\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7292\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7292\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7292\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7934 - val_loss: 0.5071 - val_accuracy: 0.7292\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7292\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7292\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7292\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7934 - val_loss: 0.5071 - val_accuracy: 0.7292\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7934 - val_loss: 0.5072 - val_accuracy: 0.7292\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7934 - val_loss: 0.5072 - val_accuracy: 0.7292\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7292\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.5072 - val_accuracy: 0.7292\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7292\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7292\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7292\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7292\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7292\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7292\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7292\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7292\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7292\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7292\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7292\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7292\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7292\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7917 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7917 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7917 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7934 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7934 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7986 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7986 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7986 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7986 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7396\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7986 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7986 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7986 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7986 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7986 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7986 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7986 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7986 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7969 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7969 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7969 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7969 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7969 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7344\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7344\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7344\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7986 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8021 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7986 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8090 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8038 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8090 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8090 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8090 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8090 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8090 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8056 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8108 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8108 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8108 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8090 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8090 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8090 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8108 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8090 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8090 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8073 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8108 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8108 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8090 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8090 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8108 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8090 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8090 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8090 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8090 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8090 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8090 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8090 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8090 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8108 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8125 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8125 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8108 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8125 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8125 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8108 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8125 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8108 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8108 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8108 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8108 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8108 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8108 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8108 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.8108 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8108 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8108 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8108 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8090 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8125 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8125 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8108 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8125 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8125 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8108 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8090 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8108 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8090 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8125 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8108 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8108 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8108 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8108 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8108 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8125 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8108 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8125 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8108 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8090 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8108 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8142 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8125 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8108 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8108 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8090 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8125 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8125 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8108 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8108 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8108 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8125 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8125 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8125 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8125 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8108 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8108 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8125 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8108 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8125 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8142 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8108 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8125 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8108 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8125 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8125 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8125 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8125 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8125 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8090 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8125 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8125 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8125 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8108 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8125 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8108 - val_loss: 0.5065 - val_accuracy: 0.7396\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8108 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8125 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8090 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8108 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8090 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8108 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8125 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8090 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8108 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8108 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8108 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8125 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8090 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8108 - val_loss: 0.5066 - val_accuracy: 0.7396\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8108 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8090 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8125 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8108 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8090 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8090 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8108 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8090 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8108 - val_loss: 0.5067 - val_accuracy: 0.7396\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8108 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8108 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8125 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8108 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8090 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8090 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8108 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8108 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8090 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8108 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8090 - val_loss: 0.5068 - val_accuracy: 0.7396\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8108 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8090 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8125 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8125 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8108 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8090 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8108 - val_loss: 0.5069 - val_accuracy: 0.7396\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8108 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8090 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8108 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4164 - accuracy: 0.8108 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8108 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8090 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8108 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8108 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8108 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8090 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8108 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8108 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8108 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8108 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.8108 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.8090 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.8108 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8108 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8090 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8090 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8090 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8090 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8108 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8108 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8108 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8090 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8090 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8090 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8090 - val_loss: 0.5071 - val_accuracy: 0.7396\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8090 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8108 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8090 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8090 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8090 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8108 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8090 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8090 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8108 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8108 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8090 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8090 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8108 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8090 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8108 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8108 - val_loss: 0.5073 - val_accuracy: 0.7396\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8108 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8090 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8090 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8108 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8090 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8090 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8090 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8108 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8090 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8125 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8090 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8108 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8125 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8108 - val_loss: 0.5074 - val_accuracy: 0.7396\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8108 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8108 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8090 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8125 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8108 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8108 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8090 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8125 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8090 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8108 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8125 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8125 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8108 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8108 - val_loss: 0.5076 - val_accuracy: 0.7396\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8125 - val_loss: 0.5076 - val_accuracy: 0.7396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpTHYvyaS39Q",
        "outputId": "d415c03a-7eeb-47c1-825d-ede5b81fa44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        }
      },
      "source": [
        "n = len(run_hist_1.history[\"loss\"])\n",
        "m = len(run_hist_1b.history['loss'])\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
        "\n",
        "ax.legend()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7e68e49690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqzkOi9YS39R"
      },
      "source": [
        "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CoFgAqm-S39R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fCEp142vS39R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLiaKjjUS39S"
      },
      "source": [
        "## Exercise\n",
        "Now it's your turn.  Do the following in the cells below:\n",
        "- Build a model with two hidden layers, each with 6 nodes\n",
        "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "- Use a learning rate of .003 and train for 1500 epochs\n",
        "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "- Plot the roc curve for the predictions\n",
        "\n",
        "Experiment with different learning rates, numbers of epochs, and network structures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Ukz0re5fS39S",
        "outputId": "5f068fdb-efe6-46fc-fed8-746655781c24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Input size is 8-dimensional\n",
        "# 2 hidden layer, 6 hidden nodes, sigmoid activation\n",
        "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
        "\n",
        "model_2 = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model_2.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 6)                 54        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 103\n",
            "Trainable params: 103\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rSPOpYx2S39S",
        "outputId": "d4db8126-129f-489b-8f61-a3be45cfb7f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# treinando o novo modelo\n",
        "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)\n",
        "\n",
        "# preparando para plot e validando para ver se o keras corretamente\n",
        "y_pred_class_nn_1 = model_2.predict_classes(X_test_norm)\n",
        "y_pred_prob_nn_1 = model_2.predict(X_test_norm)\n",
        "y_pred_class_nn_1[:10]\n",
        "y_pred_prob_nn_1[:10]\n",
        "# exibindo a performance do modelo e a curva ROC\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.2739 - accuracy: 0.8829 - val_loss: 0.9713 - val_accuracy: 0.6979\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2877 - accuracy: 0.8771 - val_loss: 0.9713 - val_accuracy: 0.6979\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8909 - val_loss: 0.9703 - val_accuracy: 0.6979\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8660 - val_loss: 0.9706 - val_accuracy: 0.6927\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.8725 - val_loss: 0.9711 - val_accuracy: 0.6927\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.8698 - val_loss: 0.9703 - val_accuracy: 0.6979\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8697 - val_loss: 0.9718 - val_accuracy: 0.6927\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2684 - accuracy: 0.8769 - val_loss: 0.9711 - val_accuracy: 0.6979\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.8831 - val_loss: 0.9715 - val_accuracy: 0.6927\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2996 - accuracy: 0.8663 - val_loss: 0.9710 - val_accuracy: 0.6979\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.8833 - val_loss: 0.9704 - val_accuracy: 0.6979\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.8830 - val_loss: 0.9705 - val_accuracy: 0.6927\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2712 - accuracy: 0.8732 - val_loss: 0.9698 - val_accuracy: 0.6979\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.8784 - val_loss: 0.9702 - val_accuracy: 0.6979\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2929 - accuracy: 0.8673 - val_loss: 0.9706 - val_accuracy: 0.7031\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2798 - accuracy: 0.8909 - val_loss: 0.9710 - val_accuracy: 0.6979\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2580 - accuracy: 0.9009 - val_loss: 0.9707 - val_accuracy: 0.6979\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.8748 - val_loss: 0.9710 - val_accuracy: 0.6979\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2658 - accuracy: 0.8747 - val_loss: 0.9720 - val_accuracy: 0.6927\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.8978 - val_loss: 0.9735 - val_accuracy: 0.6927\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.8899 - val_loss: 0.9722 - val_accuracy: 0.6979\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8698 - val_loss: 0.9727 - val_accuracy: 0.6927\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2601 - accuracy: 0.8935 - val_loss: 0.9717 - val_accuracy: 0.6979\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2580 - accuracy: 0.8910 - val_loss: 0.9706 - val_accuracy: 0.6979\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8867 - val_loss: 0.9702 - val_accuracy: 0.6979\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8802 - val_loss: 0.9701 - val_accuracy: 0.7031\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8694 - val_loss: 0.9704 - val_accuracy: 0.6979\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.8893 - val_loss: 0.9706 - val_accuracy: 0.6979\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8839 - val_loss: 0.9707 - val_accuracy: 0.6979\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2682 - accuracy: 0.8844 - val_loss: 0.9710 - val_accuracy: 0.6927\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2726 - accuracy: 0.8657 - val_loss: 0.9705 - val_accuracy: 0.6979\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8699 - val_loss: 0.9707 - val_accuracy: 0.6979\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8697 - val_loss: 0.9709 - val_accuracy: 0.6979\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.8954 - val_loss: 0.9706 - val_accuracy: 0.6979\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.8697 - val_loss: 0.9704 - val_accuracy: 0.6979\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.8916 - val_loss: 0.9706 - val_accuracy: 0.6979\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2557 - accuracy: 0.8825 - val_loss: 0.9705 - val_accuracy: 0.6979\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.8889 - val_loss: 0.9700 - val_accuracy: 0.7031\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.9100 - val_loss: 0.9710 - val_accuracy: 0.6979\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8616 - val_loss: 0.9712 - val_accuracy: 0.6979\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2798 - accuracy: 0.8822 - val_loss: 0.9715 - val_accuracy: 0.6927\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.8714 - val_loss: 0.9709 - val_accuracy: 0.6979\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8705 - val_loss: 0.9717 - val_accuracy: 0.6927\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2584 - accuracy: 0.8943 - val_loss: 0.9715 - val_accuracy: 0.6979\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2748 - accuracy: 0.8864 - val_loss: 0.9714 - val_accuracy: 0.6979\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8754 - val_loss: 0.9716 - val_accuracy: 0.6979\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2634 - accuracy: 0.8845 - val_loss: 0.9710 - val_accuracy: 0.6979\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2711 - accuracy: 0.8747 - val_loss: 0.9710 - val_accuracy: 0.6979\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.8883 - val_loss: 0.9712 - val_accuracy: 0.6979\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.8856 - val_loss: 0.9709 - val_accuracy: 0.6979\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.8755 - val_loss: 0.9710 - val_accuracy: 0.6927\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3086 - accuracy: 0.8628 - val_loss: 0.9707 - val_accuracy: 0.6979\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8772 - val_loss: 0.9722 - val_accuracy: 0.6927\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.8872 - val_loss: 0.9720 - val_accuracy: 0.6927\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8576 - val_loss: 0.9709 - val_accuracy: 0.6979\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.8876 - val_loss: 0.9706 - val_accuracy: 0.6979\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8805 - val_loss: 0.9706 - val_accuracy: 0.6979\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8913 - val_loss: 0.9712 - val_accuracy: 0.6979\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.8839 - val_loss: 0.9713 - val_accuracy: 0.6979\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.8820 - val_loss: 0.9717 - val_accuracy: 0.6979\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.8796 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2887 - accuracy: 0.8638 - val_loss: 0.9720 - val_accuracy: 0.6927\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8430 - val_loss: 0.9713 - val_accuracy: 0.6979\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.8697 - val_loss: 0.9708 - val_accuracy: 0.7031\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8805 - val_loss: 0.9708 - val_accuracy: 0.7031\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2823 - accuracy: 0.8931 - val_loss: 0.9711 - val_accuracy: 0.6979\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2569 - accuracy: 0.8846 - val_loss: 0.9713 - val_accuracy: 0.6979\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2877 - accuracy: 0.8896 - val_loss: 0.9711 - val_accuracy: 0.6979\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.8900 - val_loss: 0.9707 - val_accuracy: 0.6979\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8744 - val_loss: 0.9717 - val_accuracy: 0.6927\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2542 - accuracy: 0.8871 - val_loss: 0.9707 - val_accuracy: 0.6979\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2789 - accuracy: 0.9003 - val_loss: 0.9717 - val_accuracy: 0.6979\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2663 - accuracy: 0.8775 - val_loss: 0.9708 - val_accuracy: 0.6979\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8931 - val_loss: 0.9713 - val_accuracy: 0.6979\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2875 - accuracy: 0.8677 - val_loss: 0.9707 - val_accuracy: 0.6979\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2683 - accuracy: 0.8904 - val_loss: 0.9712 - val_accuracy: 0.6979\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2698 - accuracy: 0.8763 - val_loss: 0.9720 - val_accuracy: 0.6927\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2811 - accuracy: 0.8717 - val_loss: 0.9711 - val_accuracy: 0.6979\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3091 - accuracy: 0.8844 - val_loss: 0.9711 - val_accuracy: 0.6979\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2532 - accuracy: 0.8795 - val_loss: 0.9709 - val_accuracy: 0.6979\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.8587 - val_loss: 0.9711 - val_accuracy: 0.6979\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8500 - val_loss: 0.9718 - val_accuracy: 0.6927\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8863 - val_loss: 0.9725 - val_accuracy: 0.6927\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.8822 - val_loss: 0.9718 - val_accuracy: 0.6979\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2624 - accuracy: 0.8986 - val_loss: 0.9723 - val_accuracy: 0.6927\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2879 - accuracy: 0.8706 - val_loss: 0.9730 - val_accuracy: 0.6927\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2923 - accuracy: 0.8925 - val_loss: 0.9719 - val_accuracy: 0.6927\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.8794 - val_loss: 0.9717 - val_accuracy: 0.6979\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8730 - val_loss: 0.9714 - val_accuracy: 0.6979\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.8686 - val_loss: 0.9711 - val_accuracy: 0.6979\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.8683 - val_loss: 0.9709 - val_accuracy: 0.6979\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.8769 - val_loss: 0.9716 - val_accuracy: 0.6979\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2526 - accuracy: 0.8941 - val_loss: 0.9719 - val_accuracy: 0.6927\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3038 - accuracy: 0.8664 - val_loss: 0.9709 - val_accuracy: 0.6979\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2977 - accuracy: 0.8524 - val_loss: 0.9711 - val_accuracy: 0.6979\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8684 - val_loss: 0.9711 - val_accuracy: 0.6979\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.8720 - val_loss: 0.9708 - val_accuracy: 0.7031\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8779 - val_loss: 0.9719 - val_accuracy: 0.6927\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8697 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.8766 - val_loss: 0.9715 - val_accuracy: 0.6979\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.8862 - val_loss: 0.9723 - val_accuracy: 0.6927\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.8776 - val_loss: 0.9722 - val_accuracy: 0.6927\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2851 - accuracy: 0.8792 - val_loss: 0.9726 - val_accuracy: 0.6927\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2533 - accuracy: 0.8968 - val_loss: 0.9714 - val_accuracy: 0.6979\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2796 - accuracy: 0.8823 - val_loss: 0.9725 - val_accuracy: 0.6927\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.8821 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2781 - accuracy: 0.8719 - val_loss: 0.9712 - val_accuracy: 0.6979\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2762 - accuracy: 0.8810 - val_loss: 0.9718 - val_accuracy: 0.6979\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.8773 - val_loss: 0.9718 - val_accuracy: 0.6927\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.8960 - val_loss: 0.9708 - val_accuracy: 0.6979\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8896 - val_loss: 0.9717 - val_accuracy: 0.6927\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2852 - accuracy: 0.8748 - val_loss: 0.9722 - val_accuracy: 0.6927\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.8893 - val_loss: 0.9714 - val_accuracy: 0.6979\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8578 - val_loss: 0.9712 - val_accuracy: 0.6979\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.8977 - val_loss: 0.9708 - val_accuracy: 0.7031\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2878 - accuracy: 0.8647 - val_loss: 0.9710 - val_accuracy: 0.6979\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.8928 - val_loss: 0.9712 - val_accuracy: 0.6979\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2544 - accuracy: 0.9018 - val_loss: 0.9710 - val_accuracy: 0.7031\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2674 - accuracy: 0.8927 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3079 - accuracy: 0.8639 - val_loss: 0.9704 - val_accuracy: 0.7031\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.8824 - val_loss: 0.9722 - val_accuracy: 0.6979\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8738 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8503 - val_loss: 0.9719 - val_accuracy: 0.6927\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.8695 - val_loss: 0.9715 - val_accuracy: 0.6979\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8687 - val_loss: 0.9710 - val_accuracy: 0.6979\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2795 - accuracy: 0.8773 - val_loss: 0.9711 - val_accuracy: 0.6979\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.9007 - val_loss: 0.9712 - val_accuracy: 0.6979\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3131 - accuracy: 0.8594 - val_loss: 0.9710 - val_accuracy: 0.7031\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2681 - accuracy: 0.8937 - val_loss: 0.9720 - val_accuracy: 0.6979\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8856 - val_loss: 0.9720 - val_accuracy: 0.6979\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2845 - accuracy: 0.8813 - val_loss: 0.9721 - val_accuracy: 0.6979\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.8658 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.8736 - val_loss: 0.9715 - val_accuracy: 0.6979\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2709 - accuracy: 0.8948 - val_loss: 0.9712 - val_accuracy: 0.6979\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.8880 - val_loss: 0.9716 - val_accuracy: 0.6979\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2756 - accuracy: 0.8734 - val_loss: 0.9723 - val_accuracy: 0.6927\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2958 - accuracy: 0.8719 - val_loss: 0.9719 - val_accuracy: 0.6927\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2597 - accuracy: 0.8933 - val_loss: 0.9715 - val_accuracy: 0.6979\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.8674 - val_loss: 0.9721 - val_accuracy: 0.6979\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8860 - val_loss: 0.9718 - val_accuracy: 0.6927\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.8816 - val_loss: 0.9718 - val_accuracy: 0.6979\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8851 - val_loss: 0.9730 - val_accuracy: 0.6927\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.8836 - val_loss: 0.9713 - val_accuracy: 0.7031\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2943 - accuracy: 0.8861 - val_loss: 0.9724 - val_accuracy: 0.6979\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8806 - val_loss: 0.9714 - val_accuracy: 0.7031\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2793 - accuracy: 0.8899 - val_loss: 0.9717 - val_accuracy: 0.6979\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.8890 - val_loss: 0.9717 - val_accuracy: 0.6979\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2698 - accuracy: 0.8821 - val_loss: 0.9717 - val_accuracy: 0.6979\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2986 - accuracy: 0.8855 - val_loss: 0.9726 - val_accuracy: 0.6927\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.8830 - val_loss: 0.9720 - val_accuracy: 0.6979\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3005 - accuracy: 0.8637 - val_loss: 0.9725 - val_accuracy: 0.6927\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2549 - accuracy: 0.8907 - val_loss: 0.9730 - val_accuracy: 0.6927\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2734 - accuracy: 0.8942 - val_loss: 0.9723 - val_accuracy: 0.6979\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.8882 - val_loss: 0.9722 - val_accuracy: 0.6979\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8828 - val_loss: 0.9718 - val_accuracy: 0.6979\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.8823 - val_loss: 0.9720 - val_accuracy: 0.6979\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.8920 - val_loss: 0.9722 - val_accuracy: 0.6979\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.8571 - val_loss: 0.9720 - val_accuracy: 0.6979\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2573 - accuracy: 0.9002 - val_loss: 0.9729 - val_accuracy: 0.6927\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.8941 - val_loss: 0.9725 - val_accuracy: 0.6979\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.8745 - val_loss: 0.9720 - val_accuracy: 0.6979\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2962 - accuracy: 0.8755 - val_loss: 0.9729 - val_accuracy: 0.6927\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8693 - val_loss: 0.9734 - val_accuracy: 0.6927\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.8869 - val_loss: 0.9716 - val_accuracy: 0.6979\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.8790 - val_loss: 0.9721 - val_accuracy: 0.6979\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2678 - accuracy: 0.8956 - val_loss: 0.9716 - val_accuracy: 0.6979\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.8896 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.8702 - val_loss: 0.9715 - val_accuracy: 0.6979\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.8964 - val_loss: 0.9723 - val_accuracy: 0.6979\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.8816 - val_loss: 0.9721 - val_accuracy: 0.6979\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2902 - accuracy: 0.8841 - val_loss: 0.9725 - val_accuracy: 0.6927\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2532 - accuracy: 0.8895 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3018 - accuracy: 0.8761 - val_loss: 0.9722 - val_accuracy: 0.6979\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.8751 - val_loss: 0.9718 - val_accuracy: 0.6927\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2720 - accuracy: 0.8679 - val_loss: 0.9709 - val_accuracy: 0.6979\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.8728 - val_loss: 0.9710 - val_accuracy: 0.6979\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2672 - accuracy: 0.8822 - val_loss: 0.9716 - val_accuracy: 0.6979\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2811 - accuracy: 0.8796 - val_loss: 0.9708 - val_accuracy: 0.7031\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2944 - accuracy: 0.8838 - val_loss: 0.9714 - val_accuracy: 0.6979\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2925 - accuracy: 0.8727 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.8990 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.8917 - val_loss: 0.9725 - val_accuracy: 0.6979\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8676 - val_loss: 0.9727 - val_accuracy: 0.6979\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2674 - accuracy: 0.8840 - val_loss: 0.9725 - val_accuracy: 0.6979\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.8815 - val_loss: 0.9722 - val_accuracy: 0.6979\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.8817 - val_loss: 0.9723 - val_accuracy: 0.6979\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8621 - val_loss: 0.9714 - val_accuracy: 0.7031\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2575 - accuracy: 0.9002 - val_loss: 0.9719 - val_accuracy: 0.7031\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.8988 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2666 - accuracy: 0.8930 - val_loss: 0.9731 - val_accuracy: 0.6927\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.8760 - val_loss: 0.9717 - val_accuracy: 0.6979\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2707 - accuracy: 0.8904 - val_loss: 0.9719 - val_accuracy: 0.7031\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.8830 - val_loss: 0.9724 - val_accuracy: 0.6979\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.8895 - val_loss: 0.9722 - val_accuracy: 0.6979\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2794 - accuracy: 0.8850 - val_loss: 0.9723 - val_accuracy: 0.6979\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2827 - accuracy: 0.8946 - val_loss: 0.9721 - val_accuracy: 0.6927\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2815 - accuracy: 0.8751 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2666 - accuracy: 0.8923 - val_loss: 0.9723 - val_accuracy: 0.6979\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2759 - accuracy: 0.8865 - val_loss: 0.9726 - val_accuracy: 0.6927\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.8824 - val_loss: 0.9720 - val_accuracy: 0.6979\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.8863 - val_loss: 0.9716 - val_accuracy: 0.6979\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2661 - accuracy: 0.8883 - val_loss: 0.9724 - val_accuracy: 0.6979\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2782 - accuracy: 0.8771 - val_loss: 0.9721 - val_accuracy: 0.6979\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8647 - val_loss: 0.9723 - val_accuracy: 0.6979\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2830 - accuracy: 0.8686 - val_loss: 0.9728 - val_accuracy: 0.6927\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2757 - accuracy: 0.8908 - val_loss: 0.9724 - val_accuracy: 0.6927\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.8935 - val_loss: 0.9735 - val_accuracy: 0.6927\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8730 - val_loss: 0.9730 - val_accuracy: 0.6927\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.9011 - val_loss: 0.9727 - val_accuracy: 0.6927\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2400 - accuracy: 0.9041 - val_loss: 0.9735 - val_accuracy: 0.6927\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.8646 - val_loss: 0.9726 - val_accuracy: 0.6927\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.8783 - val_loss: 0.9715 - val_accuracy: 0.6979\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2718 - accuracy: 0.8819 - val_loss: 0.9715 - val_accuracy: 0.6979\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2682 - accuracy: 0.8887 - val_loss: 0.9717 - val_accuracy: 0.6979\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2561 - accuracy: 0.8952 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2732 - accuracy: 0.8775 - val_loss: 0.9723 - val_accuracy: 0.6979\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8885 - val_loss: 0.9716 - val_accuracy: 0.6979\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.8938 - val_loss: 0.9723 - val_accuracy: 0.6979\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3164 - accuracy: 0.8752 - val_loss: 0.9722 - val_accuracy: 0.6979\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.8937 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8448 - val_loss: 0.9724 - val_accuracy: 0.6979\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.8869 - val_loss: 0.9723 - val_accuracy: 0.6979\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.8664 - val_loss: 0.9721 - val_accuracy: 0.6979\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2893 - accuracy: 0.8678 - val_loss: 0.9712 - val_accuracy: 0.7031\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2902 - accuracy: 0.8896 - val_loss: 0.9730 - val_accuracy: 0.6927\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3135 - accuracy: 0.8736 - val_loss: 0.9729 - val_accuracy: 0.6979\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.8781 - val_loss: 0.9721 - val_accuracy: 0.6979\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.8709 - val_loss: 0.9724 - val_accuracy: 0.6979\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3145 - accuracy: 0.8661 - val_loss: 0.9727 - val_accuracy: 0.6927\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8714 - val_loss: 0.9736 - val_accuracy: 0.6927\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2878 - accuracy: 0.8825 - val_loss: 0.9727 - val_accuracy: 0.6979\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2707 - accuracy: 0.8844 - val_loss: 0.9725 - val_accuracy: 0.6979\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2590 - accuracy: 0.8944 - val_loss: 0.9739 - val_accuracy: 0.6927\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8694 - val_loss: 0.9732 - val_accuracy: 0.6979\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2722 - accuracy: 0.8843 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2896 - accuracy: 0.8806 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2815 - accuracy: 0.8866 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8884 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.8743 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2830 - accuracy: 0.8750 - val_loss: 0.9729 - val_accuracy: 0.6927\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2931 - accuracy: 0.8778 - val_loss: 0.9730 - val_accuracy: 0.6979\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.8819 - val_loss: 0.9733 - val_accuracy: 0.6927\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2633 - accuracy: 0.8879 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2722 - accuracy: 0.8823 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2866 - accuracy: 0.8834 - val_loss: 0.9722 - val_accuracy: 0.6979\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.8791 - val_loss: 0.9715 - val_accuracy: 0.6979\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.8786 - val_loss: 0.9722 - val_accuracy: 0.6979\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.8678 - val_loss: 0.9730 - val_accuracy: 0.6979\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2959 - accuracy: 0.8643 - val_loss: 0.9721 - val_accuracy: 0.6979\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2453 - accuracy: 0.8992 - val_loss: 0.9731 - val_accuracy: 0.6979\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8589 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.9008 - val_loss: 0.9725 - val_accuracy: 0.6979\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.9106 - val_loss: 0.9728 - val_accuracy: 0.6927\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.8857 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3040 - accuracy: 0.8695 - val_loss: 0.9725 - val_accuracy: 0.6979\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.8743 - val_loss: 0.9729 - val_accuracy: 0.6979\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2541 - accuracy: 0.8835 - val_loss: 0.9731 - val_accuracy: 0.6927\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2702 - accuracy: 0.8787 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.8694 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8759 - val_loss: 0.9733 - val_accuracy: 0.6927\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2542 - accuracy: 0.9025 - val_loss: 0.9727 - val_accuracy: 0.6927\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2786 - accuracy: 0.8853 - val_loss: 0.9730 - val_accuracy: 0.6927\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2746 - accuracy: 0.8825 - val_loss: 0.9735 - val_accuracy: 0.6979\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3113 - accuracy: 0.8575 - val_loss: 0.9728 - val_accuracy: 0.6927\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2685 - accuracy: 0.8688 - val_loss: 0.9730 - val_accuracy: 0.6927\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8623 - val_loss: 0.9725 - val_accuracy: 0.6979\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2587 - accuracy: 0.8863 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2659 - accuracy: 0.8886 - val_loss: 0.9727 - val_accuracy: 0.6979\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2976 - accuracy: 0.8726 - val_loss: 0.9730 - val_accuracy: 0.6927\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2840 - accuracy: 0.8605 - val_loss: 0.9729 - val_accuracy: 0.6927\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2910 - accuracy: 0.8836 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2711 - accuracy: 0.8742 - val_loss: 0.9730 - val_accuracy: 0.6927\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.8794 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.8857 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2669 - accuracy: 0.8734 - val_loss: 0.9719 - val_accuracy: 0.7031\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.8891 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2670 - accuracy: 0.8742 - val_loss: 0.9721 - val_accuracy: 0.6979\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.8792 - val_loss: 0.9719 - val_accuracy: 0.7031\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8896 - val_loss: 0.9723 - val_accuracy: 0.6979\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2561 - accuracy: 0.9006 - val_loss: 0.9724 - val_accuracy: 0.6979\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.8855 - val_loss: 0.9724 - val_accuracy: 0.7031\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8793 - val_loss: 0.9724 - val_accuracy: 0.6979\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2389 - accuracy: 0.8996 - val_loss: 0.9729 - val_accuracy: 0.6979\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2712 - accuracy: 0.8848 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.8690 - val_loss: 0.9730 - val_accuracy: 0.6979\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2548 - accuracy: 0.8869 - val_loss: 0.9725 - val_accuracy: 0.6979\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2525 - accuracy: 0.9015 - val_loss: 0.9732 - val_accuracy: 0.6979\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.8634 - val_loss: 0.9733 - val_accuracy: 0.6927\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.8896 - val_loss: 0.9724 - val_accuracy: 0.6979\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2768 - accuracy: 0.8731 - val_loss: 0.9736 - val_accuracy: 0.6927\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.8834 - val_loss: 0.9729 - val_accuracy: 0.6979\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2925 - accuracy: 0.8612 - val_loss: 0.9721 - val_accuracy: 0.6927\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.8810 - val_loss: 0.9721 - val_accuracy: 0.6979\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.8917 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.8818 - val_loss: 0.9730 - val_accuracy: 0.6979\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2603 - accuracy: 0.8871 - val_loss: 0.9730 - val_accuracy: 0.6979\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.8715 - val_loss: 0.9737 - val_accuracy: 0.6979\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2921 - accuracy: 0.8743 - val_loss: 0.9740 - val_accuracy: 0.6927\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2631 - accuracy: 0.8848 - val_loss: 0.9737 - val_accuracy: 0.6979\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.9016 - val_loss: 0.9740 - val_accuracy: 0.6979\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.8748 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2646 - accuracy: 0.8823 - val_loss: 0.9743 - val_accuracy: 0.6927\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.8945 - val_loss: 0.9750 - val_accuracy: 0.6927\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2798 - accuracy: 0.8779 - val_loss: 0.9739 - val_accuracy: 0.6927\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2631 - accuracy: 0.8916 - val_loss: 0.9736 - val_accuracy: 0.6927\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.8724 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2735 - accuracy: 0.8868 - val_loss: 0.9724 - val_accuracy: 0.6979\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2858 - accuracy: 0.8879 - val_loss: 0.9719 - val_accuracy: 0.6979\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2988 - accuracy: 0.8835 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2924 - accuracy: 0.8824 - val_loss: 0.9722 - val_accuracy: 0.6979\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2583 - accuracy: 0.8985 - val_loss: 0.9721 - val_accuracy: 0.6979\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.8612 - val_loss: 0.9729 - val_accuracy: 0.6979\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8627 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2953 - accuracy: 0.8686 - val_loss: 0.9726 - val_accuracy: 0.6979\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8754 - val_loss: 0.9733 - val_accuracy: 0.6979\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2737 - accuracy: 0.8862 - val_loss: 0.9735 - val_accuracy: 0.6927\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2793 - accuracy: 0.8868 - val_loss: 0.9729 - val_accuracy: 0.6979\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2781 - accuracy: 0.8832 - val_loss: 0.9732 - val_accuracy: 0.6927\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2640 - accuracy: 0.8911 - val_loss: 0.9727 - val_accuracy: 0.6979\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.8733 - val_loss: 0.9739 - val_accuracy: 0.6927\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8658 - val_loss: 0.9741 - val_accuracy: 0.6927\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2942 - accuracy: 0.8772 - val_loss: 0.9740 - val_accuracy: 0.6927\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2838 - accuracy: 0.8760 - val_loss: 0.9739 - val_accuracy: 0.6979\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.9006 - val_loss: 0.9741 - val_accuracy: 0.6979\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.8593 - val_loss: 0.9725 - val_accuracy: 0.6979\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2776 - accuracy: 0.8876 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2759 - accuracy: 0.8888 - val_loss: 0.9736 - val_accuracy: 0.6927\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2745 - accuracy: 0.8902 - val_loss: 0.9746 - val_accuracy: 0.6927\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2725 - accuracy: 0.8784 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.9000 - val_loss: 0.9731 - val_accuracy: 0.6979\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.8929 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.8889 - val_loss: 0.9733 - val_accuracy: 0.6979\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2840 - accuracy: 0.8681 - val_loss: 0.9739 - val_accuracy: 0.6979\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2586 - accuracy: 0.8988 - val_loss: 0.9736 - val_accuracy: 0.6979\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2590 - accuracy: 0.8915 - val_loss: 0.9740 - val_accuracy: 0.6927\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2823 - accuracy: 0.8758 - val_loss: 0.9740 - val_accuracy: 0.6927\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.8933 - val_loss: 0.9742 - val_accuracy: 0.6979\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.8680 - val_loss: 0.9735 - val_accuracy: 0.6979\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.8824 - val_loss: 0.9734 - val_accuracy: 0.6979\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2824 - accuracy: 0.8704 - val_loss: 0.9729 - val_accuracy: 0.7031\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2568 - accuracy: 0.8916 - val_loss: 0.9730 - val_accuracy: 0.6979\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.8638 - val_loss: 0.9730 - val_accuracy: 0.6979\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.8714 - val_loss: 0.9727 - val_accuracy: 0.6979\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8680 - val_loss: 0.9721 - val_accuracy: 0.7031\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8640 - val_loss: 0.9733 - val_accuracy: 0.6979\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3144 - accuracy: 0.8702 - val_loss: 0.9734 - val_accuracy: 0.6979\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.8824 - val_loss: 0.9737 - val_accuracy: 0.6979\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.8860 - val_loss: 0.9742 - val_accuracy: 0.6927\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8756 - val_loss: 0.9732 - val_accuracy: 0.6979\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2576 - accuracy: 0.9110 - val_loss: 0.9738 - val_accuracy: 0.6927\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.8832 - val_loss: 0.9740 - val_accuracy: 0.6979\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.8603 - val_loss: 0.9734 - val_accuracy: 0.6979\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.9022 - val_loss: 0.9739 - val_accuracy: 0.6979\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.8651 - val_loss: 0.9740 - val_accuracy: 0.6979\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8875 - val_loss: 0.9746 - val_accuracy: 0.6927\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2859 - accuracy: 0.8797 - val_loss: 0.9752 - val_accuracy: 0.6927\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.8782 - val_loss: 0.9732 - val_accuracy: 0.6979\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.8592 - val_loss: 0.9734 - val_accuracy: 0.7031\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.8757 - val_loss: 0.9741 - val_accuracy: 0.6979\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.8802 - val_loss: 0.9745 - val_accuracy: 0.6979\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2695 - accuracy: 0.8836 - val_loss: 0.9745 - val_accuracy: 0.6979\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2681 - accuracy: 0.8733 - val_loss: 0.9737 - val_accuracy: 0.6979\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8657 - val_loss: 0.9730 - val_accuracy: 0.6979\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2919 - accuracy: 0.8784 - val_loss: 0.9729 - val_accuracy: 0.6979\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8812 - val_loss: 0.9728 - val_accuracy: 0.6979\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8746 - val_loss: 0.9728 - val_accuracy: 0.7031\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2498 - accuracy: 0.9053 - val_loss: 0.9733 - val_accuracy: 0.6979\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8561 - val_loss: 0.9736 - val_accuracy: 0.6979\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.8918 - val_loss: 0.9739 - val_accuracy: 0.6979\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3287 - accuracy: 0.8752 - val_loss: 0.9739 - val_accuracy: 0.6979\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2766 - accuracy: 0.8700 - val_loss: 0.9737 - val_accuracy: 0.6979\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8801 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2816 - accuracy: 0.8800 - val_loss: 0.9732 - val_accuracy: 0.6979\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2410 - accuracy: 0.8924 - val_loss: 0.9734 - val_accuracy: 0.6979\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2756 - accuracy: 0.8823 - val_loss: 0.9741 - val_accuracy: 0.6979\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3037 - accuracy: 0.8716 - val_loss: 0.9741 - val_accuracy: 0.6927\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2727 - accuracy: 0.8623 - val_loss: 0.9748 - val_accuracy: 0.6927\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2696 - accuracy: 0.8814 - val_loss: 0.9747 - val_accuracy: 0.6927\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2793 - accuracy: 0.8960 - val_loss: 0.9743 - val_accuracy: 0.6927\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8292 - val_loss: 0.9741 - val_accuracy: 0.6927\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.8710 - val_loss: 0.9744 - val_accuracy: 0.6927\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8683 - val_loss: 0.9745 - val_accuracy: 0.6927\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2711 - accuracy: 0.8799 - val_loss: 0.9737 - val_accuracy: 0.6979\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.8849 - val_loss: 0.9732 - val_accuracy: 0.6979\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2741 - accuracy: 0.8736 - val_loss: 0.9736 - val_accuracy: 0.6979\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2605 - accuracy: 0.9014 - val_loss: 0.9746 - val_accuracy: 0.6927\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2815 - accuracy: 0.8805 - val_loss: 0.9741 - val_accuracy: 0.6927\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2807 - accuracy: 0.8662 - val_loss: 0.9729 - val_accuracy: 0.6979\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2857 - accuracy: 0.8747 - val_loss: 0.9744 - val_accuracy: 0.6927\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.8897 - val_loss: 0.9740 - val_accuracy: 0.6979\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8558 - val_loss: 0.9735 - val_accuracy: 0.6979\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2827 - accuracy: 0.8672 - val_loss: 0.9735 - val_accuracy: 0.6979\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.8817 - val_loss: 0.9735 - val_accuracy: 0.6979\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.8580 - val_loss: 0.9731 - val_accuracy: 0.6979\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2525 - accuracy: 0.8872 - val_loss: 0.9725 - val_accuracy: 0.7031\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.8731 - val_loss: 0.9736 - val_accuracy: 0.6979\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.8742 - val_loss: 0.9737 - val_accuracy: 0.6979\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.8654 - val_loss: 0.9742 - val_accuracy: 0.6979\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.8824 - val_loss: 0.9749 - val_accuracy: 0.6927\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2720 - accuracy: 0.8704 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2861 - accuracy: 0.8836 - val_loss: 0.9748 - val_accuracy: 0.6979\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2606 - accuracy: 0.9042 - val_loss: 0.9739 - val_accuracy: 0.6979\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2379 - accuracy: 0.8968 - val_loss: 0.9743 - val_accuracy: 0.6979\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2590 - accuracy: 0.8834 - val_loss: 0.9740 - val_accuracy: 0.6979\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2689 - accuracy: 0.8945 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2819 - accuracy: 0.8767 - val_loss: 0.9736 - val_accuracy: 0.6979\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2684 - accuracy: 0.8828 - val_loss: 0.9732 - val_accuracy: 0.7031\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8820 - val_loss: 0.9736 - val_accuracy: 0.6979\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2912 - accuracy: 0.8791 - val_loss: 0.9736 - val_accuracy: 0.6979\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2726 - accuracy: 0.8900 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.8575 - val_loss: 0.9743 - val_accuracy: 0.6927\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2577 - accuracy: 0.8716 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2910 - accuracy: 0.8877 - val_loss: 0.9731 - val_accuracy: 0.6979\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.8745 - val_loss: 0.9745 - val_accuracy: 0.6927\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8746 - val_loss: 0.9741 - val_accuracy: 0.6927\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2838 - accuracy: 0.8922 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2692 - accuracy: 0.8892 - val_loss: 0.9753 - val_accuracy: 0.6927\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3261 - accuracy: 0.8549 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.8746 - val_loss: 0.9751 - val_accuracy: 0.6927\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8521 - val_loss: 0.9741 - val_accuracy: 0.6979\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2926 - accuracy: 0.8724 - val_loss: 0.9739 - val_accuracy: 0.6979\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2863 - accuracy: 0.8772 - val_loss: 0.9736 - val_accuracy: 0.6979\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2910 - accuracy: 0.8818 - val_loss: 0.9739 - val_accuracy: 0.6979\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2809 - accuracy: 0.8681 - val_loss: 0.9734 - val_accuracy: 0.6979\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.8908 - val_loss: 0.9734 - val_accuracy: 0.7031\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.8857 - val_loss: 0.9743 - val_accuracy: 0.6979\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3074 - accuracy: 0.8668 - val_loss: 0.9748 - val_accuracy: 0.6979\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2942 - accuracy: 0.8835 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2604 - accuracy: 0.8851 - val_loss: 0.9736 - val_accuracy: 0.6979\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2743 - accuracy: 0.8912 - val_loss: 0.9743 - val_accuracy: 0.6979\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.8950 - val_loss: 0.9745 - val_accuracy: 0.6927\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8829 - val_loss: 0.9737 - val_accuracy: 0.6979\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.8982 - val_loss: 0.9735 - val_accuracy: 0.6979\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.8678 - val_loss: 0.9739 - val_accuracy: 0.6979\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2817 - accuracy: 0.8839 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3049 - accuracy: 0.8509 - val_loss: 0.9730 - val_accuracy: 0.7031\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.8734 - val_loss: 0.9740 - val_accuracy: 0.6979\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2718 - accuracy: 0.8905 - val_loss: 0.9742 - val_accuracy: 0.6979\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2955 - accuracy: 0.8793 - val_loss: 0.9735 - val_accuracy: 0.6979\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2757 - accuracy: 0.8966 - val_loss: 0.9749 - val_accuracy: 0.6927\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.8709 - val_loss: 0.9742 - val_accuracy: 0.6979\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2758 - accuracy: 0.8955 - val_loss: 0.9748 - val_accuracy: 0.6979\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2542 - accuracy: 0.8816 - val_loss: 0.9734 - val_accuracy: 0.6979\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2874 - accuracy: 0.8698 - val_loss: 0.9748 - val_accuracy: 0.6979\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.8807 - val_loss: 0.9741 - val_accuracy: 0.6979\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.8921 - val_loss: 0.9740 - val_accuracy: 0.6979\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.8770 - val_loss: 0.9745 - val_accuracy: 0.6927\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2566 - accuracy: 0.8938 - val_loss: 0.9743 - val_accuracy: 0.6979\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2591 - accuracy: 0.8848 - val_loss: 0.9740 - val_accuracy: 0.7031\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3251 - accuracy: 0.8698 - val_loss: 0.9740 - val_accuracy: 0.6979\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.8894 - val_loss: 0.9742 - val_accuracy: 0.6979\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2943 - accuracy: 0.8665 - val_loss: 0.9746 - val_accuracy: 0.6927\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.3024 - accuracy: 0.8671 - val_loss: 0.9741 - val_accuracy: 0.6927\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8466 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.9074 - val_loss: 0.9739 - val_accuracy: 0.6927\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2905 - accuracy: 0.8804 - val_loss: 0.9745 - val_accuracy: 0.6927\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2552 - accuracy: 0.8913 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.8866 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2813 - accuracy: 0.8767 - val_loss: 0.9731 - val_accuracy: 0.7031\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.8792 - val_loss: 0.9733 - val_accuracy: 0.6979\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2986 - accuracy: 0.8627 - val_loss: 0.9739 - val_accuracy: 0.6979\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2973 - accuracy: 0.8689 - val_loss: 0.9748 - val_accuracy: 0.6927\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2614 - accuracy: 0.8908 - val_loss: 0.9743 - val_accuracy: 0.6979\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3149 - accuracy: 0.8776 - val_loss: 0.9752 - val_accuracy: 0.6927\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2810 - accuracy: 0.8679 - val_loss: 0.9756 - val_accuracy: 0.6927\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2893 - accuracy: 0.8707 - val_loss: 0.9753 - val_accuracy: 0.6927\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3036 - accuracy: 0.8802 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.9027 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3133 - accuracy: 0.8730 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2714 - accuracy: 0.8810 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8809 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2721 - accuracy: 0.8908 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2423 - accuracy: 0.8965 - val_loss: 0.9755 - val_accuracy: 0.6927\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2603 - accuracy: 0.8874 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2619 - accuracy: 0.8983 - val_loss: 0.9755 - val_accuracy: 0.6979\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2814 - accuracy: 0.8777 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2845 - accuracy: 0.8707 - val_loss: 0.9740 - val_accuracy: 0.6979\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2930 - accuracy: 0.8702 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2715 - accuracy: 0.8841 - val_loss: 0.9743 - val_accuracy: 0.6979\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2840 - accuracy: 0.8710 - val_loss: 0.9747 - val_accuracy: 0.6927\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.8869 - val_loss: 0.9746 - val_accuracy: 0.6927\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2848 - accuracy: 0.8820 - val_loss: 0.9751 - val_accuracy: 0.6927\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2950 - accuracy: 0.8813 - val_loss: 0.9745 - val_accuracy: 0.6979\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2850 - accuracy: 0.8791 - val_loss: 0.9738 - val_accuracy: 0.7031\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.2802 - accuracy: 0.8873 - val_loss: 0.9737 - val_accuracy: 0.6979\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2465 - accuracy: 0.8989 - val_loss: 0.9745 - val_accuracy: 0.6979\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2921 - accuracy: 0.8755 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2925 - accuracy: 0.8785 - val_loss: 0.9743 - val_accuracy: 0.6979\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2632 - accuracy: 0.8991 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.8758 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2605 - accuracy: 0.8884 - val_loss: 0.9745 - val_accuracy: 0.6927\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2758 - accuracy: 0.8855 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2921 - accuracy: 0.8767 - val_loss: 0.9741 - val_accuracy: 0.6979\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2520 - accuracy: 0.9006 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.8760 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2895 - accuracy: 0.8758 - val_loss: 0.9743 - val_accuracy: 0.7031\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2741 - accuracy: 0.8887 - val_loss: 0.9748 - val_accuracy: 0.6927\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2803 - accuracy: 0.8783 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2801 - accuracy: 0.8720 - val_loss: 0.9739 - val_accuracy: 0.6979\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8605 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2848 - accuracy: 0.8755 - val_loss: 0.9743 - val_accuracy: 0.6979\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.8911 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3090 - accuracy: 0.8799 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.8899 - val_loss: 0.9748 - val_accuracy: 0.6979\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.8740 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.8931 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2449 - accuracy: 0.8890 - val_loss: 0.9745 - val_accuracy: 0.6979\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2908 - accuracy: 0.8776 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.8894 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.8789 - val_loss: 0.9738 - val_accuracy: 0.6979\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.8938 - val_loss: 0.9737 - val_accuracy: 0.6979\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2721 - accuracy: 0.8876 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2943 - accuracy: 0.8723 - val_loss: 0.9748 - val_accuracy: 0.6979\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.8919 - val_loss: 0.9745 - val_accuracy: 0.6979\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2895 - accuracy: 0.8625 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8688 - val_loss: 0.9752 - val_accuracy: 0.6927\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2818 - accuracy: 0.8825 - val_loss: 0.9751 - val_accuracy: 0.6927\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2687 - accuracy: 0.8762 - val_loss: 0.9752 - val_accuracy: 0.6927\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2715 - accuracy: 0.8831 - val_loss: 0.9750 - val_accuracy: 0.6979\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2770 - accuracy: 0.8757 - val_loss: 0.9747 - val_accuracy: 0.7031\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.8922 - val_loss: 0.9756 - val_accuracy: 0.6927\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.8662 - val_loss: 0.9752 - val_accuracy: 0.6927\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8886 - val_loss: 0.9745 - val_accuracy: 0.6979\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2379 - accuracy: 0.8974 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.8689 - val_loss: 0.9750 - val_accuracy: 0.6979\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2423 - accuracy: 0.8966 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2586 - accuracy: 0.8918 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.8775 - val_loss: 0.9753 - val_accuracy: 0.6979\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3141 - accuracy: 0.8685 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.8853 - val_loss: 0.9757 - val_accuracy: 0.6979\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2705 - accuracy: 0.8807 - val_loss: 0.9759 - val_accuracy: 0.6979\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8758 - val_loss: 0.9755 - val_accuracy: 0.6979\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8610 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2765 - accuracy: 0.8825 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2596 - accuracy: 0.9007 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2596 - accuracy: 0.8841 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3177 - accuracy: 0.8500 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2821 - accuracy: 0.8726 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.8748 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.8654 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2650 - accuracy: 0.8878 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8721 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.8837 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.8869 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.8902 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3040 - accuracy: 0.8769 - val_loss: 0.9755 - val_accuracy: 0.6927\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2862 - accuracy: 0.8634 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2836 - accuracy: 0.8699 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2942 - accuracy: 0.8691 - val_loss: 0.9750 - val_accuracy: 0.6979\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3040 - accuracy: 0.8848 - val_loss: 0.9759 - val_accuracy: 0.6927\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2587 - accuracy: 0.8993 - val_loss: 0.9767 - val_accuracy: 0.6927\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.8621 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.8779 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8654 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2425 - accuracy: 0.9121 - val_loss: 0.9753 - val_accuracy: 0.6979\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2745 - accuracy: 0.8977 - val_loss: 0.9763 - val_accuracy: 0.6927\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2823 - accuracy: 0.8929 - val_loss: 0.9766 - val_accuracy: 0.6927\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2804 - accuracy: 0.8751 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2529 - accuracy: 0.9012 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.8903 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.8796 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.8894 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2536 - accuracy: 0.8880 - val_loss: 0.9748 - val_accuracy: 0.6979\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2639 - accuracy: 0.8824 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8767 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2537 - accuracy: 0.8786 - val_loss: 0.9748 - val_accuracy: 0.6979\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.8898 - val_loss: 0.9743 - val_accuracy: 0.7031\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.8965 - val_loss: 0.9744 - val_accuracy: 0.6979\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.8940 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2728 - accuracy: 0.8803 - val_loss: 0.9750 - val_accuracy: 0.6979\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.8665 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2620 - accuracy: 0.8748 - val_loss: 0.9760 - val_accuracy: 0.6927\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8602 - val_loss: 0.9750 - val_accuracy: 0.6979\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.8845 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2596 - accuracy: 0.8880 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2846 - accuracy: 0.8672 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2513 - accuracy: 0.8996 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2563 - accuracy: 0.8943 - val_loss: 0.9758 - val_accuracy: 0.6927\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.8736 - val_loss: 0.9758 - val_accuracy: 0.6927\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2594 - accuracy: 0.8845 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2952 - accuracy: 0.8727 - val_loss: 0.9753 - val_accuracy: 0.6927\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.8801 - val_loss: 0.9743 - val_accuracy: 0.6979\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2452 - accuracy: 0.8983 - val_loss: 0.9745 - val_accuracy: 0.6979\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2895 - accuracy: 0.8590 - val_loss: 0.9748 - val_accuracy: 0.6979\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8505 - val_loss: 0.9749 - val_accuracy: 0.6927\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2818 - accuracy: 0.8840 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.8776 - val_loss: 0.9741 - val_accuracy: 0.7031\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.8529 - val_loss: 0.9745 - val_accuracy: 0.6979\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.8773 - val_loss: 0.9743 - val_accuracy: 0.6979\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.8849 - val_loss: 0.9748 - val_accuracy: 0.6979\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.8742 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2611 - accuracy: 0.8911 - val_loss: 0.9748 - val_accuracy: 0.6979\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2761 - accuracy: 0.8905 - val_loss: 0.9741 - val_accuracy: 0.6979\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2426 - accuracy: 0.9006 - val_loss: 0.9745 - val_accuracy: 0.7031\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.8830 - val_loss: 0.9753 - val_accuracy: 0.6979\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.8749 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8736 - val_loss: 0.9755 - val_accuracy: 0.6979\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.8768 - val_loss: 0.9753 - val_accuracy: 0.6979\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2654 - accuracy: 0.8948 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2872 - accuracy: 0.8775 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.8685 - val_loss: 0.9750 - val_accuracy: 0.6979\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2536 - accuracy: 0.8969 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.8685 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3002 - accuracy: 0.8582 - val_loss: 0.9755 - val_accuracy: 0.6979\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.8930 - val_loss: 0.9745 - val_accuracy: 0.7031\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2849 - accuracy: 0.8558 - val_loss: 0.9753 - val_accuracy: 0.6979\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2568 - accuracy: 0.8935 - val_loss: 0.9751 - val_accuracy: 0.6979\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3066 - accuracy: 0.8633 - val_loss: 0.9753 - val_accuracy: 0.6979\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2998 - accuracy: 0.8790 - val_loss: 0.9748 - val_accuracy: 0.6979\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8646 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.8888 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.8790 - val_loss: 0.9759 - val_accuracy: 0.6927\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2640 - accuracy: 0.8774 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2214 - accuracy: 0.9200 - val_loss: 0.9751 - val_accuracy: 0.6979\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3064 - accuracy: 0.8697 - val_loss: 0.9750 - val_accuracy: 0.6979\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2735 - accuracy: 0.8840 - val_loss: 0.9758 - val_accuracy: 0.6927\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2727 - accuracy: 0.8838 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.8811 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.8682 - val_loss: 0.9759 - val_accuracy: 0.6979\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.8916 - val_loss: 0.9751 - val_accuracy: 0.6979\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.8584 - val_loss: 0.9750 - val_accuracy: 0.6927\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.8868 - val_loss: 0.9752 - val_accuracy: 0.6927\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.8796 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.8896 - val_loss: 0.9756 - val_accuracy: 0.6927\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8787 - val_loss: 0.9751 - val_accuracy: 0.6979\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2864 - accuracy: 0.8761 - val_loss: 0.9755 - val_accuracy: 0.6979\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8739 - val_loss: 0.9755 - val_accuracy: 0.6979\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.8871 - val_loss: 0.9757 - val_accuracy: 0.6927\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2842 - accuracy: 0.8820 - val_loss: 0.9747 - val_accuracy: 0.6979\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2637 - accuracy: 0.8752 - val_loss: 0.9745 - val_accuracy: 0.6979\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2550 - accuracy: 0.9009 - val_loss: 0.9754 - val_accuracy: 0.6979\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2852 - accuracy: 0.8717 - val_loss: 0.9746 - val_accuracy: 0.6979\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2771 - accuracy: 0.8712 - val_loss: 0.9755 - val_accuracy: 0.6979\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2908 - accuracy: 0.8608 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2679 - accuracy: 0.8921 - val_loss: 0.9754 - val_accuracy: 0.6979\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8814 - val_loss: 0.9763 - val_accuracy: 0.6927\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.8661 - val_loss: 0.9762 - val_accuracy: 0.6927\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.8921 - val_loss: 0.9753 - val_accuracy: 0.6979\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2800 - accuracy: 0.8853 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3142 - accuracy: 0.8810 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2854 - accuracy: 0.8782 - val_loss: 0.9754 - val_accuracy: 0.6979\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.8732 - val_loss: 0.9759 - val_accuracy: 0.6979\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2788 - accuracy: 0.8803 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2707 - accuracy: 0.8863 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2583 - accuracy: 0.8859 - val_loss: 0.9758 - val_accuracy: 0.7031\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.8831 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2650 - accuracy: 0.8838 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2857 - accuracy: 0.8734 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2618 - accuracy: 0.8888 - val_loss: 0.9759 - val_accuracy: 0.6979\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2650 - accuracy: 0.8883 - val_loss: 0.9754 - val_accuracy: 0.6979\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.8933 - val_loss: 0.9753 - val_accuracy: 0.6979\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8493 - val_loss: 0.9765 - val_accuracy: 0.6927\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2870 - accuracy: 0.8834 - val_loss: 0.9757 - val_accuracy: 0.6927\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2802 - accuracy: 0.8858 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8478 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2938 - accuracy: 0.8757 - val_loss: 0.9750 - val_accuracy: 0.6979\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8733 - val_loss: 0.9756 - val_accuracy: 0.6927\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3290 - accuracy: 0.8446 - val_loss: 0.9759 - val_accuracy: 0.6979\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3038 - accuracy: 0.8849 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.8813 - val_loss: 0.9757 - val_accuracy: 0.6979\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3002 - accuracy: 0.8540 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2481 - accuracy: 0.8927 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2768 - accuracy: 0.8860 - val_loss: 0.9752 - val_accuracy: 0.7031\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2803 - accuracy: 0.8839 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2887 - accuracy: 0.8854 - val_loss: 0.9753 - val_accuracy: 0.6979\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2567 - accuracy: 0.8994 - val_loss: 0.9764 - val_accuracy: 0.6927\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2799 - accuracy: 0.8673 - val_loss: 0.9754 - val_accuracy: 0.6979\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3225 - accuracy: 0.8629 - val_loss: 0.9769 - val_accuracy: 0.6927\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2816 - accuracy: 0.8730 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2995 - accuracy: 0.8670 - val_loss: 0.9757 - val_accuracy: 0.6979\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3246 - accuracy: 0.8531 - val_loss: 0.9755 - val_accuracy: 0.6979\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2738 - accuracy: 0.8745 - val_loss: 0.9755 - val_accuracy: 0.6979\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.8666 - val_loss: 0.9757 - val_accuracy: 0.6979\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2904 - accuracy: 0.8838 - val_loss: 0.9756 - val_accuracy: 0.7031\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2666 - accuracy: 0.8848 - val_loss: 0.9769 - val_accuracy: 0.6927\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2905 - accuracy: 0.8793 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.8606 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3241 - accuracy: 0.8748 - val_loss: 0.9764 - val_accuracy: 0.6979\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.8989 - val_loss: 0.9766 - val_accuracy: 0.6927\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3070 - accuracy: 0.8753 - val_loss: 0.9769 - val_accuracy: 0.6927\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2728 - accuracy: 0.8897 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8692 - val_loss: 0.9771 - val_accuracy: 0.6927\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2821 - accuracy: 0.8827 - val_loss: 0.9768 - val_accuracy: 0.6927\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2811 - accuracy: 0.8820 - val_loss: 0.9765 - val_accuracy: 0.6979\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2612 - accuracy: 0.8921 - val_loss: 0.9762 - val_accuracy: 0.6979\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2815 - accuracy: 0.8706 - val_loss: 0.9767 - val_accuracy: 0.6979\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3063 - accuracy: 0.8675 - val_loss: 0.9767 - val_accuracy: 0.6927\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.8919 - val_loss: 0.9764 - val_accuracy: 0.6979\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.8979 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.8764 - val_loss: 0.9759 - val_accuracy: 0.6979\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8621 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.8740 - val_loss: 0.9764 - val_accuracy: 0.6979\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.8838 - val_loss: 0.9759 - val_accuracy: 0.6927\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8709 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2987 - accuracy: 0.8713 - val_loss: 0.9752 - val_accuracy: 0.7031\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2706 - accuracy: 0.8781 - val_loss: 0.9770 - val_accuracy: 0.6979\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2891 - accuracy: 0.8726 - val_loss: 0.9770 - val_accuracy: 0.6927\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.8607 - val_loss: 0.9767 - val_accuracy: 0.6927\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8711 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.8972 - val_loss: 0.9766 - val_accuracy: 0.6927\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8784 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3033 - accuracy: 0.8735 - val_loss: 0.9757 - val_accuracy: 0.6927\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2876 - accuracy: 0.8863 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2772 - accuracy: 0.8689 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2767 - accuracy: 0.8885 - val_loss: 0.9753 - val_accuracy: 0.6979\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2927 - accuracy: 0.8691 - val_loss: 0.9763 - val_accuracy: 0.6927\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.8708 - val_loss: 0.9759 - val_accuracy: 0.6979\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2870 - accuracy: 0.8890 - val_loss: 0.9754 - val_accuracy: 0.6979\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2897 - accuracy: 0.8860 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.8701 - val_loss: 0.9750 - val_accuracy: 0.6979\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3002 - accuracy: 0.8695 - val_loss: 0.9754 - val_accuracy: 0.6979\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2876 - accuracy: 0.8815 - val_loss: 0.9749 - val_accuracy: 0.6979\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.8929 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.8940 - val_loss: 0.9767 - val_accuracy: 0.6927\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2818 - accuracy: 0.8789 - val_loss: 0.9768 - val_accuracy: 0.6979\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2596 - accuracy: 0.8863 - val_loss: 0.9762 - val_accuracy: 0.6979\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2836 - accuracy: 0.8913 - val_loss: 0.9765 - val_accuracy: 0.6979\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2605 - accuracy: 0.8920 - val_loss: 0.9769 - val_accuracy: 0.6979\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.8823 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.8785 - val_loss: 0.9763 - val_accuracy: 0.6927\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8988 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2861 - accuracy: 0.8680 - val_loss: 0.9757 - val_accuracy: 0.7031\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2896 - accuracy: 0.8767 - val_loss: 0.9762 - val_accuracy: 0.6979\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2672 - accuracy: 0.8941 - val_loss: 0.9765 - val_accuracy: 0.6979\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.8649 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2631 - accuracy: 0.9010 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2435 - accuracy: 0.9131 - val_loss: 0.9757 - val_accuracy: 0.6979\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.8829 - val_loss: 0.9759 - val_accuracy: 0.6979\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.8818 - val_loss: 0.9759 - val_accuracy: 0.6979\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2768 - accuracy: 0.8823 - val_loss: 0.9764 - val_accuracy: 0.6927\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2596 - accuracy: 0.8916 - val_loss: 0.9757 - val_accuracy: 0.6927\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.8923 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.8875 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2737 - accuracy: 0.8741 - val_loss: 0.9770 - val_accuracy: 0.6927\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.8846 - val_loss: 0.9767 - val_accuracy: 0.6979\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.9012 - val_loss: 0.9769 - val_accuracy: 0.6927\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2582 - accuracy: 0.8977 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2796 - accuracy: 0.8934 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2369 - accuracy: 0.8930 - val_loss: 0.9759 - val_accuracy: 0.6979\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2864 - accuracy: 0.8813 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8702 - val_loss: 0.9762 - val_accuracy: 0.6979\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2616 - accuracy: 0.8937 - val_loss: 0.9764 - val_accuracy: 0.6979\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.8882 - val_loss: 0.9762 - val_accuracy: 0.6927\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2872 - accuracy: 0.8836 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2545 - accuracy: 0.8922 - val_loss: 0.9757 - val_accuracy: 0.6979\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2550 - accuracy: 0.8947 - val_loss: 0.9752 - val_accuracy: 0.6979\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2556 - accuracy: 0.8934 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2637 - accuracy: 0.8975 - val_loss: 0.9764 - val_accuracy: 0.6979\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.8792 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8947 - val_loss: 0.9757 - val_accuracy: 0.7031\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2752 - accuracy: 0.8839 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2711 - accuracy: 0.8915 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.8777 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.8748 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.8884 - val_loss: 0.9771 - val_accuracy: 0.6979\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2582 - accuracy: 0.8955 - val_loss: 0.9770 - val_accuracy: 0.6927\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.9004 - val_loss: 0.9768 - val_accuracy: 0.6927\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.8755 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2780 - accuracy: 0.8871 - val_loss: 0.9772 - val_accuracy: 0.6927\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8856 - val_loss: 0.9768 - val_accuracy: 0.6927\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2832 - accuracy: 0.8770 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2655 - accuracy: 0.8946 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2684 - accuracy: 0.8862 - val_loss: 0.9762 - val_accuracy: 0.6979\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.8758 - val_loss: 0.9757 - val_accuracy: 0.7031\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.8816 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2699 - accuracy: 0.8799 - val_loss: 0.9771 - val_accuracy: 0.6979\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2802 - accuracy: 0.8868 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8701 - val_loss: 0.9756 - val_accuracy: 0.7031\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2797 - accuracy: 0.8728 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2513 - accuracy: 0.9021 - val_loss: 0.9765 - val_accuracy: 0.6979\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.8876 - val_loss: 0.9764 - val_accuracy: 0.6979\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2913 - accuracy: 0.8676 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.8701 - val_loss: 0.9767 - val_accuracy: 0.6979\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2781 - accuracy: 0.8824 - val_loss: 0.9757 - val_accuracy: 0.7031\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2669 - accuracy: 0.8955 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3217 - accuracy: 0.8448 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.8943 - val_loss: 0.9767 - val_accuracy: 0.6979\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2715 - accuracy: 0.8710 - val_loss: 0.9757 - val_accuracy: 0.6979\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2541 - accuracy: 0.8893 - val_loss: 0.9762 - val_accuracy: 0.6979\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2769 - accuracy: 0.8884 - val_loss: 0.9777 - val_accuracy: 0.6927\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2722 - accuracy: 0.8699 - val_loss: 0.9773 - val_accuracy: 0.6979\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2594 - accuracy: 0.8893 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2791 - accuracy: 0.8697 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2851 - accuracy: 0.8893 - val_loss: 0.9759 - val_accuracy: 0.7031\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.8789 - val_loss: 0.9759 - val_accuracy: 0.6979\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.8722 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.8866 - val_loss: 0.9756 - val_accuracy: 0.7031\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.8912 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.8880 - val_loss: 0.9767 - val_accuracy: 0.6927\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3072 - accuracy: 0.8721 - val_loss: 0.9770 - val_accuracy: 0.6979\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2631 - accuracy: 0.8932 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2662 - accuracy: 0.8865 - val_loss: 0.9765 - val_accuracy: 0.6979\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2491 - accuracy: 0.8925 - val_loss: 0.9762 - val_accuracy: 0.6979\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2540 - accuracy: 0.8832 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3161 - accuracy: 0.8542 - val_loss: 0.9764 - val_accuracy: 0.6979\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8716 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2597 - accuracy: 0.8947 - val_loss: 0.9767 - val_accuracy: 0.6979\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.8718 - val_loss: 0.9768 - val_accuracy: 0.6979\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2640 - accuracy: 0.8995 - val_loss: 0.9773 - val_accuracy: 0.6927\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8871 - val_loss: 0.9769 - val_accuracy: 0.6927\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.8790 - val_loss: 0.9774 - val_accuracy: 0.6927\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2482 - accuracy: 0.8941 - val_loss: 0.9769 - val_accuracy: 0.6927\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2722 - accuracy: 0.8890 - val_loss: 0.9774 - val_accuracy: 0.6927\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2889 - accuracy: 0.8781 - val_loss: 0.9761 - val_accuracy: 0.7031\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2861 - accuracy: 0.8828 - val_loss: 0.9753 - val_accuracy: 0.6979\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2912 - accuracy: 0.8784 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2743 - accuracy: 0.8821 - val_loss: 0.9769 - val_accuracy: 0.6979\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8747 - val_loss: 0.9767 - val_accuracy: 0.6927\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.8765 - val_loss: 0.9773 - val_accuracy: 0.6927\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3005 - accuracy: 0.8503 - val_loss: 0.9772 - val_accuracy: 0.6927\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3018 - accuracy: 0.8778 - val_loss: 0.9770 - val_accuracy: 0.6927\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.9006 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2729 - accuracy: 0.8860 - val_loss: 0.9770 - val_accuracy: 0.6979\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2720 - accuracy: 0.8835 - val_loss: 0.9771 - val_accuracy: 0.6979\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.8691 - val_loss: 0.9762 - val_accuracy: 0.7031\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.8845 - val_loss: 0.9761 - val_accuracy: 0.7031\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.8916 - val_loss: 0.9772 - val_accuracy: 0.6979\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2914 - accuracy: 0.8780 - val_loss: 0.9762 - val_accuracy: 0.6979\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2499 - accuracy: 0.8958 - val_loss: 0.9772 - val_accuracy: 0.6979\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2955 - accuracy: 0.8728 - val_loss: 0.9776 - val_accuracy: 0.6927\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.8841 - val_loss: 0.9768 - val_accuracy: 0.6979\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2445 - accuracy: 0.8832 - val_loss: 0.9765 - val_accuracy: 0.6979\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.8852 - val_loss: 0.9771 - val_accuracy: 0.6927\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3215 - accuracy: 0.8463 - val_loss: 0.9764 - val_accuracy: 0.6979\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2828 - accuracy: 0.8820 - val_loss: 0.9756 - val_accuracy: 0.7031\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2921 - accuracy: 0.8874 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2981 - accuracy: 0.8633 - val_loss: 0.9769 - val_accuracy: 0.6927\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8965 - val_loss: 0.9773 - val_accuracy: 0.6979\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2808 - accuracy: 0.8757 - val_loss: 0.9778 - val_accuracy: 0.6927\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8586 - val_loss: 0.9768 - val_accuracy: 0.6979\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2637 - accuracy: 0.8866 - val_loss: 0.9769 - val_accuracy: 0.6979\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2815 - accuracy: 0.8708 - val_loss: 0.9770 - val_accuracy: 0.6979\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2818 - accuracy: 0.8759 - val_loss: 0.9774 - val_accuracy: 0.6927\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8728 - val_loss: 0.9762 - val_accuracy: 0.6979\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2694 - accuracy: 0.8898 - val_loss: 0.9770 - val_accuracy: 0.6979\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2523 - accuracy: 0.8891 - val_loss: 0.9764 - val_accuracy: 0.6927\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2769 - accuracy: 0.8680 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2974 - accuracy: 0.8649 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2761 - accuracy: 0.8858 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3005 - accuracy: 0.8724 - val_loss: 0.9767 - val_accuracy: 0.6979\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2845 - accuracy: 0.8834 - val_loss: 0.9758 - val_accuracy: 0.6979\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2620 - accuracy: 0.8788 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.8956 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2626 - accuracy: 0.8955 - val_loss: 0.9775 - val_accuracy: 0.6927\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8711 - val_loss: 0.9774 - val_accuracy: 0.6927\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3081 - accuracy: 0.8754 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2746 - accuracy: 0.8874 - val_loss: 0.9767 - val_accuracy: 0.6927\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2832 - accuracy: 0.8915 - val_loss: 0.9769 - val_accuracy: 0.6927\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.8620 - val_loss: 0.9756 - val_accuracy: 0.6979\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2645 - accuracy: 0.8874 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2768 - accuracy: 0.8825 - val_loss: 0.9766 - val_accuracy: 0.6927\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2738 - accuracy: 0.8785 - val_loss: 0.9765 - val_accuracy: 0.6979\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.8904 - val_loss: 0.9764 - val_accuracy: 0.6979\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2699 - accuracy: 0.8807 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2742 - accuracy: 0.8737 - val_loss: 0.9755 - val_accuracy: 0.7031\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2617 - accuracy: 0.8730 - val_loss: 0.9760 - val_accuracy: 0.6979\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2514 - accuracy: 0.8954 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.8895 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2920 - accuracy: 0.8727 - val_loss: 0.9770 - val_accuracy: 0.6927\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2585 - accuracy: 0.8886 - val_loss: 0.9770 - val_accuracy: 0.6979\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2804 - accuracy: 0.8775 - val_loss: 0.9770 - val_accuracy: 0.6979\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2935 - accuracy: 0.8839 - val_loss: 0.9768 - val_accuracy: 0.6979\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2453 - accuracy: 0.8911 - val_loss: 0.9771 - val_accuracy: 0.6979\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2689 - accuracy: 0.8851 - val_loss: 0.9767 - val_accuracy: 0.6979\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2527 - accuracy: 0.8950 - val_loss: 0.9772 - val_accuracy: 0.6979\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2582 - accuracy: 0.8850 - val_loss: 0.9764 - val_accuracy: 0.7031\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2643 - accuracy: 0.8919 - val_loss: 0.9769 - val_accuracy: 0.6979\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2825 - accuracy: 0.8746 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2787 - accuracy: 0.8765 - val_loss: 0.9767 - val_accuracy: 0.6979\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2645 - accuracy: 0.8903 - val_loss: 0.9765 - val_accuracy: 0.6979\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2898 - accuracy: 0.8563 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2823 - accuracy: 0.8931 - val_loss: 0.9769 - val_accuracy: 0.6927\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3013 - accuracy: 0.8631 - val_loss: 0.9768 - val_accuracy: 0.6979\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2770 - accuracy: 0.8801 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2676 - accuracy: 0.8755 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2835 - accuracy: 0.8685 - val_loss: 0.9771 - val_accuracy: 0.6979\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.8823 - val_loss: 0.9780 - val_accuracy: 0.6927\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2913 - accuracy: 0.8604 - val_loss: 0.9773 - val_accuracy: 0.6979\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.8817 - val_loss: 0.9773 - val_accuracy: 0.6927\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2678 - accuracy: 0.8937 - val_loss: 0.9767 - val_accuracy: 0.6979\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2621 - accuracy: 0.8813 - val_loss: 0.9768 - val_accuracy: 0.6979\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.8805 - val_loss: 0.9771 - val_accuracy: 0.6979\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2700 - accuracy: 0.8988 - val_loss: 0.9770 - val_accuracy: 0.6979\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2917 - accuracy: 0.8743 - val_loss: 0.9764 - val_accuracy: 0.6979\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.8911 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2802 - accuracy: 0.8872 - val_loss: 0.9771 - val_accuracy: 0.6979\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3055 - accuracy: 0.8568 - val_loss: 0.9769 - val_accuracy: 0.6979\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2844 - accuracy: 0.8849 - val_loss: 0.9775 - val_accuracy: 0.6979\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3049 - accuracy: 0.8510 - val_loss: 0.9774 - val_accuracy: 0.6979\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.8954 - val_loss: 0.9772 - val_accuracy: 0.6979\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.8950 - val_loss: 0.9776 - val_accuracy: 0.6979\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3202 - accuracy: 0.8543 - val_loss: 0.9772 - val_accuracy: 0.6979\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2696 - accuracy: 0.8820 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.8920 - val_loss: 0.9769 - val_accuracy: 0.6979\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8649 - val_loss: 0.9767 - val_accuracy: 0.6979\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8860 - val_loss: 0.9774 - val_accuracy: 0.6979\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2825 - accuracy: 0.8660 - val_loss: 0.9775 - val_accuracy: 0.6979\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2949 - accuracy: 0.8731 - val_loss: 0.9774 - val_accuracy: 0.6979\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2849 - accuracy: 0.8765 - val_loss: 0.9776 - val_accuracy: 0.6979\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2759 - accuracy: 0.8964 - val_loss: 0.9778 - val_accuracy: 0.6927\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.8805 - val_loss: 0.9773 - val_accuracy: 0.6979\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3006 - accuracy: 0.8745 - val_loss: 0.9785 - val_accuracy: 0.6927\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2620 - accuracy: 0.8832 - val_loss: 0.9772 - val_accuracy: 0.6979\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2696 - accuracy: 0.8917 - val_loss: 0.9779 - val_accuracy: 0.6979\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3126 - accuracy: 0.8683 - val_loss: 0.9770 - val_accuracy: 0.6979\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8646 - val_loss: 0.9761 - val_accuracy: 0.6979\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8692 - val_loss: 0.9769 - val_accuracy: 0.6979\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.8882 - val_loss: 0.9780 - val_accuracy: 0.6927\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3264 - accuracy: 0.8514 - val_loss: 0.9776 - val_accuracy: 0.6979\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.8650 - val_loss: 0.9773 - val_accuracy: 0.6979\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2791 - accuracy: 0.8888 - val_loss: 0.9778 - val_accuracy: 0.6979\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2757 - accuracy: 0.8819 - val_loss: 0.9775 - val_accuracy: 0.6979\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2848 - accuracy: 0.8670 - val_loss: 0.9780 - val_accuracy: 0.6979\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.8679 - val_loss: 0.9784 - val_accuracy: 0.6927\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8689 - val_loss: 0.9774 - val_accuracy: 0.6979\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2669 - accuracy: 0.8887 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2745 - accuracy: 0.8799 - val_loss: 0.9781 - val_accuracy: 0.6927\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2550 - accuracy: 0.9003 - val_loss: 0.9784 - val_accuracy: 0.6979\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3047 - accuracy: 0.8730 - val_loss: 0.9774 - val_accuracy: 0.6979\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3010 - accuracy: 0.8641 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.8763 - val_loss: 0.9775 - val_accuracy: 0.6927\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2674 - accuracy: 0.8916 - val_loss: 0.9768 - val_accuracy: 0.6927\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2588 - accuracy: 0.8784 - val_loss: 0.9771 - val_accuracy: 0.6979\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8730 - val_loss: 0.9774 - val_accuracy: 0.6979\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2833 - accuracy: 0.8794 - val_loss: 0.9768 - val_accuracy: 0.6979\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8715 - val_loss: 0.9774 - val_accuracy: 0.6979\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3060 - accuracy: 0.8764 - val_loss: 0.9780 - val_accuracy: 0.6927\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2805 - accuracy: 0.8741 - val_loss: 0.9775 - val_accuracy: 0.6979\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2882 - accuracy: 0.8758 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2629 - accuracy: 0.8838 - val_loss: 0.9775 - val_accuracy: 0.6979\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.8707 - val_loss: 0.9778 - val_accuracy: 0.6979\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.8847 - val_loss: 0.9776 - val_accuracy: 0.6979\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.8781 - val_loss: 0.9775 - val_accuracy: 0.6979\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8717 - val_loss: 0.9772 - val_accuracy: 0.6927\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2775 - accuracy: 0.8697 - val_loss: 0.9769 - val_accuracy: 0.6979\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2728 - accuracy: 0.8791 - val_loss: 0.9768 - val_accuracy: 0.6979\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2745 - accuracy: 0.8808 - val_loss: 0.9771 - val_accuracy: 0.6979\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8819 - val_loss: 0.9771 - val_accuracy: 0.6927\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2792 - accuracy: 0.8774 - val_loss: 0.9767 - val_accuracy: 0.6979\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2463 - accuracy: 0.8927 - val_loss: 0.9763 - val_accuracy: 0.6979\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3039 - accuracy: 0.8645 - val_loss: 0.9770 - val_accuracy: 0.6979\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.9026 - val_loss: 0.9778 - val_accuracy: 0.6979\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2857 - accuracy: 0.8894 - val_loss: 0.9776 - val_accuracy: 0.6927\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2828 - accuracy: 0.8752 - val_loss: 0.9769 - val_accuracy: 0.6979\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.8617 - val_loss: 0.9775 - val_accuracy: 0.6979\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2822 - accuracy: 0.8912 - val_loss: 0.9780 - val_accuracy: 0.6927\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8562 - val_loss: 0.9779 - val_accuracy: 0.6927\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8610 - val_loss: 0.9777 - val_accuracy: 0.6927\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.8832 - val_loss: 0.9775 - val_accuracy: 0.6927\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2657 - accuracy: 0.8872 - val_loss: 0.9772 - val_accuracy: 0.6979\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.8728 - val_loss: 0.9772 - val_accuracy: 0.6979\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.8762 - val_loss: 0.9775 - val_accuracy: 0.6979\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.8771 - val_loss: 0.9774 - val_accuracy: 0.6979\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2893 - accuracy: 0.8724 - val_loss: 0.9776 - val_accuracy: 0.6927\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2721 - accuracy: 0.8976 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2803 - accuracy: 0.8832 - val_loss: 0.9781 - val_accuracy: 0.6979\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2847 - accuracy: 0.8696 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3012 - accuracy: 0.8880 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.8727 - val_loss: 0.9776 - val_accuracy: 0.6979\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2665 - accuracy: 0.8800 - val_loss: 0.9773 - val_accuracy: 0.7031\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.8719 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3294 - accuracy: 0.8663 - val_loss: 0.9791 - val_accuracy: 0.6927\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2640 - accuracy: 0.8813 - val_loss: 0.9786 - val_accuracy: 0.6927\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3159 - accuracy: 0.8660 - val_loss: 0.9779 - val_accuracy: 0.6979\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2911 - accuracy: 0.8759 - val_loss: 0.9783 - val_accuracy: 0.6979\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3062 - accuracy: 0.8695 - val_loss: 0.9786 - val_accuracy: 0.6979\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2947 - accuracy: 0.8806 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.8869 - val_loss: 0.9789 - val_accuracy: 0.6927\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3019 - accuracy: 0.8651 - val_loss: 0.9778 - val_accuracy: 0.6979\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2550 - accuracy: 0.8915 - val_loss: 0.9781 - val_accuracy: 0.6927\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2868 - accuracy: 0.8691 - val_loss: 0.9782 - val_accuracy: 0.6927\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.8945 - val_loss: 0.9777 - val_accuracy: 0.6927\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2691 - accuracy: 0.8922 - val_loss: 0.9768 - val_accuracy: 0.6979\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2834 - accuracy: 0.8817 - val_loss: 0.9772 - val_accuracy: 0.6979\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3009 - accuracy: 0.8601 - val_loss: 0.9785 - val_accuracy: 0.6927\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2848 - accuracy: 0.8735 - val_loss: 0.9787 - val_accuracy: 0.6927\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2957 - accuracy: 0.8721 - val_loss: 0.9782 - val_accuracy: 0.7031\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2920 - accuracy: 0.8706 - val_loss: 0.9781 - val_accuracy: 0.6979\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2900 - accuracy: 0.8768 - val_loss: 0.9785 - val_accuracy: 0.6979\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2780 - accuracy: 0.8739 - val_loss: 0.9778 - val_accuracy: 0.6979\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2803 - accuracy: 0.8957 - val_loss: 0.9784 - val_accuracy: 0.6927\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2564 - accuracy: 0.8870 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2551 - accuracy: 0.8971 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2802 - accuracy: 0.8681 - val_loss: 0.9779 - val_accuracy: 0.6979\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2821 - accuracy: 0.8647 - val_loss: 0.9781 - val_accuracy: 0.6979\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2514 - accuracy: 0.8958 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.8796 - val_loss: 0.9780 - val_accuracy: 0.6979\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2882 - accuracy: 0.8785 - val_loss: 0.9778 - val_accuracy: 0.6979\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2469 - accuracy: 0.8773 - val_loss: 0.9771 - val_accuracy: 0.7031\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2551 - accuracy: 0.8817 - val_loss: 0.9776 - val_accuracy: 0.6979\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2733 - accuracy: 0.8993 - val_loss: 0.9774 - val_accuracy: 0.7031\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2716 - accuracy: 0.8971 - val_loss: 0.9784 - val_accuracy: 0.6927\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2825 - accuracy: 0.8717 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2587 - accuracy: 0.8905 - val_loss: 0.9781 - val_accuracy: 0.6979\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2526 - accuracy: 0.8903 - val_loss: 0.9775 - val_accuracy: 0.6979\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.8971 - val_loss: 0.9784 - val_accuracy: 0.6979\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2871 - accuracy: 0.8898 - val_loss: 0.9782 - val_accuracy: 0.7031\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2440 - accuracy: 0.8970 - val_loss: 0.9784 - val_accuracy: 0.6979\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.8769 - val_loss: 0.9784 - val_accuracy: 0.6979\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2961 - accuracy: 0.8822 - val_loss: 0.9792 - val_accuracy: 0.6927\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.8895 - val_loss: 0.9792 - val_accuracy: 0.6927\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8657 - val_loss: 0.9780 - val_accuracy: 0.6979\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2921 - accuracy: 0.8826 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8744 - val_loss: 0.9784 - val_accuracy: 0.6979\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2805 - accuracy: 0.8758 - val_loss: 0.9785 - val_accuracy: 0.6979\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.8688 - val_loss: 0.9793 - val_accuracy: 0.6927\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2590 - accuracy: 0.8861 - val_loss: 0.9785 - val_accuracy: 0.6927\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2681 - accuracy: 0.8710 - val_loss: 0.9773 - val_accuracy: 0.7031\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8547 - val_loss: 0.9779 - val_accuracy: 0.6979\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3028 - accuracy: 0.8676 - val_loss: 0.9789 - val_accuracy: 0.6927\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2566 - accuracy: 0.8917 - val_loss: 0.9772 - val_accuracy: 0.6979\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2451 - accuracy: 0.8969 - val_loss: 0.9780 - val_accuracy: 0.6979\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.8837 - val_loss: 0.9771 - val_accuracy: 0.6927\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2952 - accuracy: 0.8759 - val_loss: 0.9784 - val_accuracy: 0.6927\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.8734 - val_loss: 0.9782 - val_accuracy: 0.6927\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2787 - accuracy: 0.8798 - val_loss: 0.9778 - val_accuracy: 0.6979\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2489 - accuracy: 0.8956 - val_loss: 0.9776 - val_accuracy: 0.6979\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2582 - accuracy: 0.8913 - val_loss: 0.9778 - val_accuracy: 0.6979\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2847 - accuracy: 0.8741 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2323 - accuracy: 0.9046 - val_loss: 0.9766 - val_accuracy: 0.6979\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2692 - accuracy: 0.8899 - val_loss: 0.9774 - val_accuracy: 0.6927\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2792 - accuracy: 0.8723 - val_loss: 0.9775 - val_accuracy: 0.7031\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3150 - accuracy: 0.8659 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2581 - accuracy: 0.8881 - val_loss: 0.9794 - val_accuracy: 0.6927\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.8905 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2830 - accuracy: 0.8835 - val_loss: 0.9781 - val_accuracy: 0.6979\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3253 - accuracy: 0.8590 - val_loss: 0.9774 - val_accuracy: 0.7031\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2718 - accuracy: 0.8821 - val_loss: 0.9775 - val_accuracy: 0.7031\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2761 - accuracy: 0.8876 - val_loss: 0.9785 - val_accuracy: 0.6979\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.8738 - val_loss: 0.9793 - val_accuracy: 0.6927\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2370 - accuracy: 0.9027 - val_loss: 0.9781 - val_accuracy: 0.6979\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2417 - accuracy: 0.8933 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2522 - accuracy: 0.8897 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2940 - accuracy: 0.8820 - val_loss: 0.9781 - val_accuracy: 0.6927\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.8918 - val_loss: 0.9779 - val_accuracy: 0.6979\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.8709 - val_loss: 0.9785 - val_accuracy: 0.6927\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2404 - accuracy: 0.9041 - val_loss: 0.9779 - val_accuracy: 0.6979\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2910 - accuracy: 0.8955 - val_loss: 0.9780 - val_accuracy: 0.6979\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2854 - accuracy: 0.8877 - val_loss: 0.9786 - val_accuracy: 0.6979\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2776 - accuracy: 0.8786 - val_loss: 0.9772 - val_accuracy: 0.7031\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2705 - accuracy: 0.8789 - val_loss: 0.9775 - val_accuracy: 0.7031\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2673 - accuracy: 0.8944 - val_loss: 0.9780 - val_accuracy: 0.6979\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2692 - accuracy: 0.8846 - val_loss: 0.9784 - val_accuracy: 0.6979\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2885 - accuracy: 0.8683 - val_loss: 0.9778 - val_accuracy: 0.6979\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.8699 - val_loss: 0.9778 - val_accuracy: 0.6979\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8800 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8878 - val_loss: 0.9780 - val_accuracy: 0.7031\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.8673 - val_loss: 0.9784 - val_accuracy: 0.6979\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3013 - accuracy: 0.8689 - val_loss: 0.9793 - val_accuracy: 0.6927\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.8869 - val_loss: 0.9789 - val_accuracy: 0.6927\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2673 - accuracy: 0.8835 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2787 - accuracy: 0.8909 - val_loss: 0.9783 - val_accuracy: 0.6979\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2768 - accuracy: 0.8747 - val_loss: 0.9785 - val_accuracy: 0.6927\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.8672 - val_loss: 0.9783 - val_accuracy: 0.6927\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2507 - accuracy: 0.8981 - val_loss: 0.9785 - val_accuracy: 0.6979\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.8937 - val_loss: 0.9781 - val_accuracy: 0.6979\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2804 - accuracy: 0.8757 - val_loss: 0.9778 - val_accuracy: 0.6927\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2631 - accuracy: 0.9066 - val_loss: 0.9783 - val_accuracy: 0.6979\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2839 - accuracy: 0.8831 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2918 - accuracy: 0.8515 - val_loss: 0.9789 - val_accuracy: 0.6927\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3164 - accuracy: 0.8618 - val_loss: 0.9788 - val_accuracy: 0.6927\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.8805 - val_loss: 0.9784 - val_accuracy: 0.6979\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2740 - accuracy: 0.8843 - val_loss: 0.9780 - val_accuracy: 0.6979\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2815 - accuracy: 0.8758 - val_loss: 0.9773 - val_accuracy: 0.6979\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2705 - accuracy: 0.8850 - val_loss: 0.9790 - val_accuracy: 0.6927\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2430 - accuracy: 0.8957 - val_loss: 0.9789 - val_accuracy: 0.6927\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2636 - accuracy: 0.8835 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.8737 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2670 - accuracy: 0.8773 - val_loss: 0.9774 - val_accuracy: 0.7031\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2667 - accuracy: 0.8864 - val_loss: 0.9781 - val_accuracy: 0.6979\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2732 - accuracy: 0.8852 - val_loss: 0.9786 - val_accuracy: 0.6979\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2704 - accuracy: 0.8936 - val_loss: 0.9783 - val_accuracy: 0.6979\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.8685 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2529 - accuracy: 0.9015 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2771 - accuracy: 0.8670 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2671 - accuracy: 0.8849 - val_loss: 0.9787 - val_accuracy: 0.6979\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2475 - accuracy: 0.8980 - val_loss: 0.9785 - val_accuracy: 0.6979\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.9022 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.8658 - val_loss: 0.9792 - val_accuracy: 0.6927\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2630 - accuracy: 0.8930 - val_loss: 0.9793 - val_accuracy: 0.6927\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2706 - accuracy: 0.8746 - val_loss: 0.9776 - val_accuracy: 0.7031\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2987 - accuracy: 0.8580 - val_loss: 0.9784 - val_accuracy: 0.6979\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2771 - accuracy: 0.8818 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3037 - accuracy: 0.8782 - val_loss: 0.9784 - val_accuracy: 0.6979\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2605 - accuracy: 0.8847 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2800 - accuracy: 0.8787 - val_loss: 0.9796 - val_accuracy: 0.6927\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2584 - accuracy: 0.8854 - val_loss: 0.9787 - val_accuracy: 0.6927\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2659 - accuracy: 0.8935 - val_loss: 0.9792 - val_accuracy: 0.6927\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3027 - accuracy: 0.8755 - val_loss: 0.9801 - val_accuracy: 0.6927\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8788 - val_loss: 0.9794 - val_accuracy: 0.6927\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.8793 - val_loss: 0.9787 - val_accuracy: 0.6979\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2712 - accuracy: 0.8756 - val_loss: 0.9783 - val_accuracy: 0.7031\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2659 - accuracy: 0.8847 - val_loss: 0.9784 - val_accuracy: 0.6979\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2993 - accuracy: 0.8601 - val_loss: 0.9784 - val_accuracy: 0.6927\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2471 - accuracy: 0.8927 - val_loss: 0.9772 - val_accuracy: 0.6979\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2890 - accuracy: 0.8771 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.9068 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2690 - accuracy: 0.8942 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2829 - accuracy: 0.8836 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2845 - accuracy: 0.8824 - val_loss: 0.9786 - val_accuracy: 0.6927\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2734 - accuracy: 0.8755 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2950 - accuracy: 0.8682 - val_loss: 0.9789 - val_accuracy: 0.6927\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2831 - accuracy: 0.8807 - val_loss: 0.9777 - val_accuracy: 0.6979\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2756 - accuracy: 0.8732 - val_loss: 0.9774 - val_accuracy: 0.6979\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2691 - accuracy: 0.8837 - val_loss: 0.9776 - val_accuracy: 0.6979\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.8874 - val_loss: 0.9784 - val_accuracy: 0.6927\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.8937 - val_loss: 0.9783 - val_accuracy: 0.6979\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3015 - accuracy: 0.8652 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2931 - accuracy: 0.8621 - val_loss: 0.9783 - val_accuracy: 0.7031\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2821 - accuracy: 0.8774 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8696 - val_loss: 0.9793 - val_accuracy: 0.6927\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3201 - accuracy: 0.8621 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2586 - accuracy: 0.8876 - val_loss: 0.9783 - val_accuracy: 0.6979\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2743 - accuracy: 0.8710 - val_loss: 0.9783 - val_accuracy: 0.6979\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2844 - accuracy: 0.8754 - val_loss: 0.9784 - val_accuracy: 0.6979\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.8723 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2825 - accuracy: 0.8854 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3072 - accuracy: 0.8574 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.8896 - val_loss: 0.9784 - val_accuracy: 0.7031\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2853 - accuracy: 0.8866 - val_loss: 0.9794 - val_accuracy: 0.6927\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2552 - accuracy: 0.8827 - val_loss: 0.9793 - val_accuracy: 0.6927\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.8670 - val_loss: 0.9785 - val_accuracy: 0.6979\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2900 - accuracy: 0.8696 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8592 - val_loss: 0.9780 - val_accuracy: 0.7031\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2931 - accuracy: 0.8781 - val_loss: 0.9776 - val_accuracy: 0.7031\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2753 - accuracy: 0.8955 - val_loss: 0.9786 - val_accuracy: 0.6979\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2822 - accuracy: 0.8903 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2838 - accuracy: 0.8841 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3184 - accuracy: 0.8696 - val_loss: 0.9796 - val_accuracy: 0.6927\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2461 - accuracy: 0.9010 - val_loss: 0.9796 - val_accuracy: 0.6979\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.8779 - val_loss: 0.9783 - val_accuracy: 0.6979\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2815 - accuracy: 0.8847 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8740 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2785 - accuracy: 0.8834 - val_loss: 0.9781 - val_accuracy: 0.6979\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2847 - accuracy: 0.8884 - val_loss: 0.9780 - val_accuracy: 0.6979\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2743 - accuracy: 0.8848 - val_loss: 0.9781 - val_accuracy: 0.6979\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2387 - accuracy: 0.8999 - val_loss: 0.9780 - val_accuracy: 0.7031\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2764 - accuracy: 0.8709 - val_loss: 0.9800 - val_accuracy: 0.6927\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8743 - val_loss: 0.9798 - val_accuracy: 0.6927\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2907 - accuracy: 0.8756 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2804 - accuracy: 0.8628 - val_loss: 0.9785 - val_accuracy: 0.6979\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.8735 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8716 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2903 - accuracy: 0.8894 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8736 - val_loss: 0.9791 - val_accuracy: 0.6927\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2995 - accuracy: 0.8587 - val_loss: 0.9794 - val_accuracy: 0.6927\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2813 - accuracy: 0.8734 - val_loss: 0.9792 - val_accuracy: 0.6927\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.8700 - val_loss: 0.9780 - val_accuracy: 0.6979\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2887 - accuracy: 0.8671 - val_loss: 0.9784 - val_accuracy: 0.7031\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2825 - accuracy: 0.8751 - val_loss: 0.9797 - val_accuracy: 0.6979\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.8878 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2645 - accuracy: 0.8943 - val_loss: 0.9798 - val_accuracy: 0.6979\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.8777 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.8699 - val_loss: 0.9799 - val_accuracy: 0.6927\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2620 - accuracy: 0.8943 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.8660 - val_loss: 0.9778 - val_accuracy: 0.6979\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2749 - accuracy: 0.8876 - val_loss: 0.9781 - val_accuracy: 0.6979\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2812 - accuracy: 0.8863 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2650 - accuracy: 0.8987 - val_loss: 0.9780 - val_accuracy: 0.6979\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2553 - accuracy: 0.8888 - val_loss: 0.9783 - val_accuracy: 0.6979\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.8805 - val_loss: 0.9785 - val_accuracy: 0.6979\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.8870 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2704 - accuracy: 0.8783 - val_loss: 0.9791 - val_accuracy: 0.6979\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2749 - accuracy: 0.8826 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3224 - accuracy: 0.8622 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2512 - accuracy: 0.8751 - val_loss: 0.9785 - val_accuracy: 0.6979\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2773 - accuracy: 0.8838 - val_loss: 0.9791 - val_accuracy: 0.6927\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2803 - accuracy: 0.8793 - val_loss: 0.9785 - val_accuracy: 0.6979\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2816 - accuracy: 0.8879 - val_loss: 0.9794 - val_accuracy: 0.6927\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.8859 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2550 - accuracy: 0.8881 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2808 - accuracy: 0.8787 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.8668 - val_loss: 0.9783 - val_accuracy: 0.6979\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2734 - accuracy: 0.8840 - val_loss: 0.9796 - val_accuracy: 0.6927\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2618 - accuracy: 0.8820 - val_loss: 0.9798 - val_accuracy: 0.6979\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2742 - accuracy: 0.8892 - val_loss: 0.9801 - val_accuracy: 0.6979\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2688 - accuracy: 0.8735 - val_loss: 0.9792 - val_accuracy: 0.7031\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2696 - accuracy: 0.8819 - val_loss: 0.9798 - val_accuracy: 0.6927\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3122 - accuracy: 0.8486 - val_loss: 0.9795 - val_accuracy: 0.6927\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2847 - accuracy: 0.8844 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2607 - accuracy: 0.8908 - val_loss: 0.9802 - val_accuracy: 0.6927\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2852 - accuracy: 0.8715 - val_loss: 0.9793 - val_accuracy: 0.6927\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2768 - accuracy: 0.8827 - val_loss: 0.9793 - val_accuracy: 0.6927\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2601 - accuracy: 0.8804 - val_loss: 0.9794 - val_accuracy: 0.6927\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.8946 - val_loss: 0.9788 - val_accuracy: 0.6927\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.8746 - val_loss: 0.9779 - val_accuracy: 0.7031\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8505 - val_loss: 0.9786 - val_accuracy: 0.6979\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2825 - accuracy: 0.8858 - val_loss: 0.9789 - val_accuracy: 0.6927\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8732 - val_loss: 0.9788 - val_accuracy: 0.6927\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8744 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2995 - accuracy: 0.8789 - val_loss: 0.9799 - val_accuracy: 0.6927\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3122 - accuracy: 0.8490 - val_loss: 0.9788 - val_accuracy: 0.7031\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2878 - accuracy: 0.8860 - val_loss: 0.9800 - val_accuracy: 0.6979\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8658 - val_loss: 0.9790 - val_accuracy: 0.7031\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3139 - accuracy: 0.8642 - val_loss: 0.9796 - val_accuracy: 0.6979\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.8762 - val_loss: 0.9789 - val_accuracy: 0.7031\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2538 - accuracy: 0.8861 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2513 - accuracy: 0.9022 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2607 - accuracy: 0.8994 - val_loss: 0.9802 - val_accuracy: 0.6927\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2765 - accuracy: 0.8834 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2850 - accuracy: 0.8746 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3081 - accuracy: 0.8617 - val_loss: 0.9799 - val_accuracy: 0.6927\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2765 - accuracy: 0.8823 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.8797 - val_loss: 0.9796 - val_accuracy: 0.6979\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.8880 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2773 - accuracy: 0.8801 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2892 - accuracy: 0.8716 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2871 - accuracy: 0.8847 - val_loss: 0.9801 - val_accuracy: 0.6927\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.8740 - val_loss: 0.9800 - val_accuracy: 0.6927\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2661 - accuracy: 0.8923 - val_loss: 0.9798 - val_accuracy: 0.6979\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2490 - accuracy: 0.9093 - val_loss: 0.9797 - val_accuracy: 0.6979\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2689 - accuracy: 0.9032 - val_loss: 0.9799 - val_accuracy: 0.6979\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2924 - accuracy: 0.8836 - val_loss: 0.9801 - val_accuracy: 0.6979\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2571 - accuracy: 0.9058 - val_loss: 0.9803 - val_accuracy: 0.6927\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2953 - accuracy: 0.8923 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2812 - accuracy: 0.8754 - val_loss: 0.9785 - val_accuracy: 0.7031\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2743 - accuracy: 0.8909 - val_loss: 0.9786 - val_accuracy: 0.7031\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2696 - accuracy: 0.8861 - val_loss: 0.9786 - val_accuracy: 0.6979\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.8733 - val_loss: 0.9783 - val_accuracy: 0.6979\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8758 - val_loss: 0.9787 - val_accuracy: 0.6979\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3062 - accuracy: 0.8650 - val_loss: 0.9788 - val_accuracy: 0.6979\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2702 - accuracy: 0.8900 - val_loss: 0.9789 - val_accuracy: 0.6927\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8951 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8628 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3224 - accuracy: 0.8660 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2669 - accuracy: 0.8768 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2837 - accuracy: 0.8821 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2700 - accuracy: 0.8866 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2704 - accuracy: 0.8692 - val_loss: 0.9803 - val_accuracy: 0.6927\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.8913 - val_loss: 0.9791 - val_accuracy: 0.6979\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2507 - accuracy: 0.8969 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2790 - accuracy: 0.8688 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2671 - accuracy: 0.8704 - val_loss: 0.9796 - val_accuracy: 0.6979\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2540 - accuracy: 0.8776 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2273 - accuracy: 0.9053 - val_loss: 0.9803 - val_accuracy: 0.6979\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2725 - accuracy: 0.8752 - val_loss: 0.9803 - val_accuracy: 0.6979\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.8809 - val_loss: 0.9809 - val_accuracy: 0.6979\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2964 - accuracy: 0.8732 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3242 - accuracy: 0.8735 - val_loss: 0.9787 - val_accuracy: 0.6979\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.8780 - val_loss: 0.9785 - val_accuracy: 0.6979\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2874 - accuracy: 0.8886 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2723 - accuracy: 0.8886 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2575 - accuracy: 0.8857 - val_loss: 0.9785 - val_accuracy: 0.6979\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2658 - accuracy: 0.8879 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3074 - accuracy: 0.8810 - val_loss: 0.9783 - val_accuracy: 0.6979\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.8755 - val_loss: 0.9787 - val_accuracy: 0.6979\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2817 - accuracy: 0.8836 - val_loss: 0.9782 - val_accuracy: 0.6979\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2764 - accuracy: 0.8835 - val_loss: 0.9786 - val_accuracy: 0.6979\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2724 - accuracy: 0.8873 - val_loss: 0.9797 - val_accuracy: 0.6927\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2719 - accuracy: 0.8885 - val_loss: 0.9801 - val_accuracy: 0.6979\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2692 - accuracy: 0.8834 - val_loss: 0.9797 - val_accuracy: 0.6979\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2617 - accuracy: 0.8972 - val_loss: 0.9789 - val_accuracy: 0.7031\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8516 - val_loss: 0.9796 - val_accuracy: 0.6927\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2804 - accuracy: 0.8687 - val_loss: 0.9800 - val_accuracy: 0.6927\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2562 - accuracy: 0.8889 - val_loss: 0.9798 - val_accuracy: 0.6979\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8701 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2688 - accuracy: 0.8747 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.8811 - val_loss: 0.9796 - val_accuracy: 0.6979\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2557 - accuracy: 0.8983 - val_loss: 0.9804 - val_accuracy: 0.6927\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2776 - accuracy: 0.8775 - val_loss: 0.9803 - val_accuracy: 0.6927\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2451 - accuracy: 0.8871 - val_loss: 0.9798 - val_accuracy: 0.6979\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2795 - accuracy: 0.8792 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2914 - accuracy: 0.8704 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3041 - accuracy: 0.8698 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2540 - accuracy: 0.8831 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8729 - val_loss: 0.9797 - val_accuracy: 0.6927\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2374 - accuracy: 0.9040 - val_loss: 0.9791 - val_accuracy: 0.7031\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.8821 - val_loss: 0.9786 - val_accuracy: 0.7031\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2815 - accuracy: 0.8864 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.8581 - val_loss: 0.9796 - val_accuracy: 0.6979\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2724 - accuracy: 0.8922 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2917 - accuracy: 0.8800 - val_loss: 0.9803 - val_accuracy: 0.6927\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3001 - accuracy: 0.8715 - val_loss: 0.9805 - val_accuracy: 0.6927\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3165 - accuracy: 0.8662 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3129 - accuracy: 0.8707 - val_loss: 0.9799 - val_accuracy: 0.6979\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2760 - accuracy: 0.8832 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2579 - accuracy: 0.9015 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2457 - accuracy: 0.9019 - val_loss: 0.9802 - val_accuracy: 0.6979\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2592 - accuracy: 0.8794 - val_loss: 0.9804 - val_accuracy: 0.6979\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2856 - accuracy: 0.8868 - val_loss: 0.9798 - val_accuracy: 0.6979\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.8743 - val_loss: 0.9805 - val_accuracy: 0.6927\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2746 - accuracy: 0.8829 - val_loss: 0.9799 - val_accuracy: 0.6927\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2459 - accuracy: 0.8824 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2704 - accuracy: 0.8886 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2501 - accuracy: 0.8907 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2927 - accuracy: 0.8685 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2701 - accuracy: 0.8947 - val_loss: 0.9800 - val_accuracy: 0.6927\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3202 - accuracy: 0.8791 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2862 - accuracy: 0.8703 - val_loss: 0.9787 - val_accuracy: 0.6979\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2844 - accuracy: 0.8905 - val_loss: 0.9793 - val_accuracy: 0.6927\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.8949 - val_loss: 0.9797 - val_accuracy: 0.6979\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2718 - accuracy: 0.8897 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2874 - accuracy: 0.8814 - val_loss: 0.9805 - val_accuracy: 0.6979\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2821 - accuracy: 0.8579 - val_loss: 0.9797 - val_accuracy: 0.6979\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2858 - accuracy: 0.8731 - val_loss: 0.9797 - val_accuracy: 0.6979\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.8887 - val_loss: 0.9799 - val_accuracy: 0.6979\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2983 - accuracy: 0.8752 - val_loss: 0.9800 - val_accuracy: 0.6979\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2722 - accuracy: 0.8774 - val_loss: 0.9797 - val_accuracy: 0.6979\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.8784 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2769 - accuracy: 0.8979 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2751 - accuracy: 0.8857 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2692 - accuracy: 0.8783 - val_loss: 0.9800 - val_accuracy: 0.6979\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2762 - accuracy: 0.8758 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2834 - accuracy: 0.8859 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2834 - accuracy: 0.8710 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2926 - accuracy: 0.8747 - val_loss: 0.9805 - val_accuracy: 0.6927\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2738 - accuracy: 0.8788 - val_loss: 0.9804 - val_accuracy: 0.6927\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.8589 - val_loss: 0.9800 - val_accuracy: 0.6979\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2892 - accuracy: 0.8706 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2536 - accuracy: 0.8878 - val_loss: 0.9790 - val_accuracy: 0.6927\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3174 - accuracy: 0.8549 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2816 - accuracy: 0.8800 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3075 - accuracy: 0.8668 - val_loss: 0.9806 - val_accuracy: 0.6927\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3127 - accuracy: 0.8798 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2778 - accuracy: 0.8814 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.8967 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.8794 - val_loss: 0.9796 - val_accuracy: 0.6979\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2554 - accuracy: 0.8942 - val_loss: 0.9799 - val_accuracy: 0.6979\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.8762 - val_loss: 0.9800 - val_accuracy: 0.6927\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2752 - accuracy: 0.8873 - val_loss: 0.9800 - val_accuracy: 0.6979\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2885 - accuracy: 0.8816 - val_loss: 0.9799 - val_accuracy: 0.6979\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2905 - accuracy: 0.8714 - val_loss: 0.9804 - val_accuracy: 0.6979\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2534 - accuracy: 0.8932 - val_loss: 0.9801 - val_accuracy: 0.6979\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3199 - accuracy: 0.8762 - val_loss: 0.9808 - val_accuracy: 0.6927\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2489 - accuracy: 0.8985 - val_loss: 0.9798 - val_accuracy: 0.6979\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2798 - accuracy: 0.8757 - val_loss: 0.9802 - val_accuracy: 0.6979\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2453 - accuracy: 0.8998 - val_loss: 0.9803 - val_accuracy: 0.6979\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3079 - accuracy: 0.8730 - val_loss: 0.9797 - val_accuracy: 0.6979\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8736 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2491 - accuracy: 0.8884 - val_loss: 0.9797 - val_accuracy: 0.6979\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2859 - accuracy: 0.8736 - val_loss: 0.9800 - val_accuracy: 0.6979\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8443 - val_loss: 0.9801 - val_accuracy: 0.6979\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2465 - accuracy: 0.9004 - val_loss: 0.9799 - val_accuracy: 0.6927\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.8701 - val_loss: 0.9799 - val_accuracy: 0.6927\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2695 - accuracy: 0.8931 - val_loss: 0.9806 - val_accuracy: 0.6979\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2376 - accuracy: 0.9005 - val_loss: 0.9805 - val_accuracy: 0.6979\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2899 - accuracy: 0.8802 - val_loss: 0.9811 - val_accuracy: 0.6979\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8527 - val_loss: 0.9810 - val_accuracy: 0.6979\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8709 - val_loss: 0.9804 - val_accuracy: 0.6927\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.8728 - val_loss: 0.9798 - val_accuracy: 0.6927\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2680 - accuracy: 0.8930 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.8943 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2647 - accuracy: 0.8919 - val_loss: 0.9795 - val_accuracy: 0.7031\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.8680 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2963 - accuracy: 0.8563 - val_loss: 0.9791 - val_accuracy: 0.6927\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2510 - accuracy: 0.8980 - val_loss: 0.9801 - val_accuracy: 0.6979\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2629 - accuracy: 0.9038 - val_loss: 0.9808 - val_accuracy: 0.6979\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2915 - accuracy: 0.8651 - val_loss: 0.9796 - val_accuracy: 0.6979\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2577 - accuracy: 0.9015 - val_loss: 0.9803 - val_accuracy: 0.6979\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2616 - accuracy: 0.8857 - val_loss: 0.9807 - val_accuracy: 0.6979\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2572 - accuracy: 0.8885 - val_loss: 0.9804 - val_accuracy: 0.6979\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2779 - accuracy: 0.8768 - val_loss: 0.9797 - val_accuracy: 0.6927\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.8896 - val_loss: 0.9791 - val_accuracy: 0.6927\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8675 - val_loss: 0.9789 - val_accuracy: 0.6979\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2432 - accuracy: 0.9081 - val_loss: 0.9790 - val_accuracy: 0.6979\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2759 - accuracy: 0.8675 - val_loss: 0.9787 - val_accuracy: 0.6979\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.8945 - val_loss: 0.9795 - val_accuracy: 0.7031\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.8938 - val_loss: 0.9803 - val_accuracy: 0.6979\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2744 - accuracy: 0.8936 - val_loss: 0.9803 - val_accuracy: 0.6979\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2891 - accuracy: 0.8600 - val_loss: 0.9805 - val_accuracy: 0.6979\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2651 - accuracy: 0.8885 - val_loss: 0.9802 - val_accuracy: 0.6979\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2457 - accuracy: 0.8823 - val_loss: 0.9803 - val_accuracy: 0.6979\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2665 - accuracy: 0.8744 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2630 - accuracy: 0.8797 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2595 - accuracy: 0.9006 - val_loss: 0.9801 - val_accuracy: 0.6927\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2879 - accuracy: 0.8849 - val_loss: 0.9797 - val_accuracy: 0.6927\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2571 - accuracy: 0.8973 - val_loss: 0.9794 - val_accuracy: 0.6979\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2899 - accuracy: 0.8751 - val_loss: 0.9808 - val_accuracy: 0.6927\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2809 - accuracy: 0.8713 - val_loss: 0.9801 - val_accuracy: 0.6979\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2785 - accuracy: 0.8668 - val_loss: 0.9807 - val_accuracy: 0.6927\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2834 - accuracy: 0.8803 - val_loss: 0.9806 - val_accuracy: 0.6927\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.8832 - val_loss: 0.9797 - val_accuracy: 0.6979\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2751 - accuracy: 0.8815 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2959 - accuracy: 0.8836 - val_loss: 0.9806 - val_accuracy: 0.6927\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2636 - accuracy: 0.8941 - val_loss: 0.9809 - val_accuracy: 0.6979\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3021 - accuracy: 0.8648 - val_loss: 0.9804 - val_accuracy: 0.6979\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2589 - accuracy: 0.8891 - val_loss: 0.9804 - val_accuracy: 0.6979\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.8867 - val_loss: 0.9804 - val_accuracy: 0.6979\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2776 - accuracy: 0.8824 - val_loss: 0.9803 - val_accuracy: 0.6979\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8720 - val_loss: 0.9803 - val_accuracy: 0.6979\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3118 - accuracy: 0.8741 - val_loss: 0.9804 - val_accuracy: 0.6979\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2783 - accuracy: 0.8764 - val_loss: 0.9803 - val_accuracy: 0.6979\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8717 - val_loss: 0.9810 - val_accuracy: 0.6979\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2565 - accuracy: 0.8904 - val_loss: 0.9804 - val_accuracy: 0.6979\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2531 - accuracy: 0.8954 - val_loss: 0.9804 - val_accuracy: 0.6979\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.8657 - val_loss: 0.9810 - val_accuracy: 0.6979\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2852 - accuracy: 0.8648 - val_loss: 0.9807 - val_accuracy: 0.6979\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2926 - accuracy: 0.8824 - val_loss: 0.9806 - val_accuracy: 0.6979\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2472 - accuracy: 0.8924 - val_loss: 0.9810 - val_accuracy: 0.6979\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2698 - accuracy: 0.8981 - val_loss: 0.9808 - val_accuracy: 0.6979\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2851 - accuracy: 0.8743 - val_loss: 0.9806 - val_accuracy: 0.6979\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2646 - accuracy: 0.8846 - val_loss: 0.9812 - val_accuracy: 0.6927\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.8604 - val_loss: 0.9806 - val_accuracy: 0.6979\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2705 - accuracy: 0.9085 - val_loss: 0.9806 - val_accuracy: 0.6979\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2459 - accuracy: 0.9003 - val_loss: 0.9804 - val_accuracy: 0.6927\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.8656 - val_loss: 0.9804 - val_accuracy: 0.6979\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2634 - accuracy: 0.8783 - val_loss: 0.9801 - val_accuracy: 0.6979\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2739 - accuracy: 0.9044 - val_loss: 0.9803 - val_accuracy: 0.6979\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3068 - accuracy: 0.8564 - val_loss: 0.9798 - val_accuracy: 0.6979\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2894 - accuracy: 0.8754 - val_loss: 0.9799 - val_accuracy: 0.6979\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2698 - accuracy: 0.8788 - val_loss: 0.9809 - val_accuracy: 0.6979\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.8792 - val_loss: 0.9805 - val_accuracy: 0.6979\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.8698 - val_loss: 0.9800 - val_accuracy: 0.6979\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2922 - accuracy: 0.8720 - val_loss: 0.9791 - val_accuracy: 0.7031\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8693 - val_loss: 0.9798 - val_accuracy: 0.6979\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2556 - accuracy: 0.8986 - val_loss: 0.9796 - val_accuracy: 0.6979\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2673 - accuracy: 0.8818 - val_loss: 0.9797 - val_accuracy: 0.6979\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2452 - accuracy: 0.9042 - val_loss: 0.9795 - val_accuracy: 0.6979\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2725 - accuracy: 0.8861 - val_loss: 0.9792 - val_accuracy: 0.6979\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2718 - accuracy: 0.8727 - val_loss: 0.9796 - val_accuracy: 0.6979\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2922 - accuracy: 0.8629 - val_loss: 0.9798 - val_accuracy: 0.6979\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2781 - accuracy: 0.8743 - val_loss: 0.9804 - val_accuracy: 0.6927\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3042 - accuracy: 0.8597 - val_loss: 0.9793 - val_accuracy: 0.6979\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2633 - accuracy: 0.8966 - val_loss: 0.9797 - val_accuracy: 0.6979\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.8667 - val_loss: 0.9807 - val_accuracy: 0.6979\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2491 - accuracy: 0.8916 - val_loss: 0.9803 - val_accuracy: 0.6979\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2803 - accuracy: 0.8638 - val_loss: 0.9806 - val_accuracy: 0.6979\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2604 - accuracy: 0.8995 - val_loss: 0.9815 - val_accuracy: 0.6927\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2616 - accuracy: 0.8955 - val_loss: 0.9816 - val_accuracy: 0.6927\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2691 - accuracy: 0.8769 - val_loss: 0.9808 - val_accuracy: 0.6927\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3235 - accuracy: 0.8573 - val_loss: 0.9802 - val_accuracy: 0.6927\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2672 - accuracy: 0.8818 - val_loss: 0.9815 - val_accuracy: 0.6927\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2734 - accuracy: 0.8768 - val_loss: 0.9810 - val_accuracy: 0.6979\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2911 - accuracy: 0.8749 - val_loss: 0.9813 - val_accuracy: 0.6979\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2630 - accuracy: 0.9060 - val_loss: 0.9819 - val_accuracy: 0.6927\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2949 - accuracy: 0.8779 - val_loss: 0.9817 - val_accuracy: 0.6979\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2691 - accuracy: 0.8736 - val_loss: 0.9815 - val_accuracy: 0.6979\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3050 - accuracy: 0.8697 - val_loss: 0.9816 - val_accuracy: 0.6979\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2843 - accuracy: 0.8693 - val_loss: 0.9811 - val_accuracy: 0.6979\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2744 - accuracy: 0.8797 - val_loss: 0.9809 - val_accuracy: 0.6979\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2710 - accuracy: 0.8844 - val_loss: 0.9805 - val_accuracy: 0.6979\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2597 - accuracy: 0.8990 - val_loss: 0.9813 - val_accuracy: 0.6979\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3182 - accuracy: 0.8555 - val_loss: 0.9812 - val_accuracy: 0.6979\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2737 - accuracy: 0.8852 - val_loss: 0.9808 - val_accuracy: 0.6979\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2535 - accuracy: 0.9033 - val_loss: 0.9814 - val_accuracy: 0.6979\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2755 - accuracy: 0.8843 - val_loss: 0.9823 - val_accuracy: 0.6927\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2822 - accuracy: 0.8784 - val_loss: 0.9817 - val_accuracy: 0.6979\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3051 - accuracy: 0.8739 - val_loss: 0.9825 - val_accuracy: 0.6927\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2567 - accuracy: 0.8881 - val_loss: 0.9821 - val_accuracy: 0.6927\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2958 - accuracy: 0.8684 - val_loss: 0.9822 - val_accuracy: 0.6979\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2647 - accuracy: 0.8869 - val_loss: 0.9813 - val_accuracy: 0.6979\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8641 - val_loss: 0.9805 - val_accuracy: 0.6979\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3191 - accuracy: 0.8564 - val_loss: 0.9801 - val_accuracy: 0.6979\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2536 - accuracy: 0.8902 - val_loss: 0.9814 - val_accuracy: 0.6979\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2347 - accuracy: 0.8916 - val_loss: 0.9811 - val_accuracy: 0.6979\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2615 - accuracy: 0.8816 - val_loss: 0.9809 - val_accuracy: 0.6927\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2879 - accuracy: 0.8720 - val_loss: 0.9807 - val_accuracy: 0.6979\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2590 - accuracy: 0.8885 - val_loss: 0.9804 - val_accuracy: 0.6979\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.8894 - val_loss: 0.9815 - val_accuracy: 0.6927\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2649 - accuracy: 0.8879 - val_loss: 0.9806 - val_accuracy: 0.6979\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3195 - accuracy: 0.8640 - val_loss: 0.9800 - val_accuracy: 0.6979\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3245 - accuracy: 0.8605 - val_loss: 0.9813 - val_accuracy: 0.6927\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2941 - accuracy: 0.8678 - val_loss: 0.9806 - val_accuracy: 0.6979\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8599 - val_loss: 0.9819 - val_accuracy: 0.6927\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2663 - accuracy: 0.8807 - val_loss: 0.9809 - val_accuracy: 0.6927\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2377 - accuracy: 0.8870 - val_loss: 0.9807 - val_accuracy: 0.6979\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2514 - accuracy: 0.8906 - val_loss: 0.9809 - val_accuracy: 0.6979\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2766 - accuracy: 0.8793 - val_loss: 0.9809 - val_accuracy: 0.6979\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2661 - accuracy: 0.8895 - val_loss: 0.9817 - val_accuracy: 0.6927\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2862 - accuracy: 0.8686 - val_loss: 0.9816 - val_accuracy: 0.6979\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2668 - accuracy: 0.8880 - val_loss: 0.9811 - val_accuracy: 0.6979\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2434 - accuracy: 0.8915 - val_loss: 0.9800 - val_accuracy: 0.6979\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3029 - accuracy: 0.8689 - val_loss: 0.9801 - val_accuracy: 0.6979\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2821 - accuracy: 0.8971 - val_loss: 0.9806 - val_accuracy: 0.6979\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2786 - accuracy: 0.8678 - val_loss: 0.9805 - val_accuracy: 0.6979\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2974 - accuracy: 0.8826 - val_loss: 0.9802 - val_accuracy: 0.6979\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2985 - accuracy: 0.8758 - val_loss: 0.9809 - val_accuracy: 0.6979\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2507 - accuracy: 0.8956 - val_loss: 0.9810 - val_accuracy: 0.6979\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2994 - accuracy: 0.8675 - val_loss: 0.9810 - val_accuracy: 0.6979\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.8707 - val_loss: 0.9807 - val_accuracy: 0.6979\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2680 - accuracy: 0.8779 - val_loss: 0.9812 - val_accuracy: 0.6927\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2683 - accuracy: 0.8835 - val_loss: 0.9813 - val_accuracy: 0.6927\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2762 - accuracy: 0.8786 - val_loss: 0.9812 - val_accuracy: 0.6979\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2695 - accuracy: 0.8798 - val_loss: 0.9812 - val_accuracy: 0.6979\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3151 - accuracy: 0.8620 - val_loss: 0.9814 - val_accuracy: 0.6979\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2471 - accuracy: 0.9067 - val_loss: 0.9815 - val_accuracy: 0.6979\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2683 - accuracy: 0.8737 - val_loss: 0.9809 - val_accuracy: 0.6979\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3016 - accuracy: 0.8649 - val_loss: 0.9808 - val_accuracy: 0.6979\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2967 - accuracy: 0.8640 - val_loss: 0.9807 - val_accuracy: 0.6979\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2744 - accuracy: 0.8916 - val_loss: 0.9806 - val_accuracy: 0.6979\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2956 - accuracy: 0.8670 - val_loss: 0.9801 - val_accuracy: 0.6979\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2891 - accuracy: 0.8854 - val_loss: 0.9807 - val_accuracy: 0.6979\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.2769 - accuracy: 0.8823 - val_loss: 0.9811 - val_accuracy: 0.6979\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2566 - accuracy: 0.8808 - val_loss: 0.9801 - val_accuracy: 0.6979\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2714 - accuracy: 0.8900 - val_loss: 0.9800 - val_accuracy: 0.6927\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.8781 - val_loss: 0.9807 - val_accuracy: 0.6927\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2819 - accuracy: 0.8864 - val_loss: 0.9808 - val_accuracy: 0.6979\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2836 - accuracy: 0.8681 - val_loss: 0.9803 - val_accuracy: 0.7031\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.8838 - val_loss: 0.9803 - val_accuracy: 0.7031\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8833 - val_loss: 0.9802 - val_accuracy: 0.7031\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2733 - accuracy: 0.8819 - val_loss: 0.9801 - val_accuracy: 0.7031\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2655 - accuracy: 0.8817 - val_loss: 0.9810 - val_accuracy: 0.6927\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3126 - accuracy: 0.8704 - val_loss: 0.9805 - val_accuracy: 0.6979\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2947 - accuracy: 0.8508 - val_loss: 0.9810 - val_accuracy: 0.6979\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2959 - accuracy: 0.8851 - val_loss: 0.9813 - val_accuracy: 0.6979\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3003 - accuracy: 0.8672 - val_loss: 0.9814 - val_accuracy: 0.6979\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2426 - accuracy: 0.9027 - val_loss: 0.9809 - val_accuracy: 0.7031\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3218 - accuracy: 0.8699 - val_loss: 0.9818 - val_accuracy: 0.6979\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2681 - accuracy: 0.8884 - val_loss: 0.9818 - val_accuracy: 0.6927\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.8553 - val_loss: 0.9811 - val_accuracy: 0.6979\n",
            "accuracy is 0.698\n",
            "roc-auc is 0.736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU5dn/8e9FV4RFihi6uiAimoGswfiQuLErRqNGf4IK5jExRaOCdAHBAioKaiLGNZYHzSr2gKJiW1EsgLhKE6RJEZC2dNh2//6YgSzrltndmbmnfN6vFy+nnD3znXvGueY6555zzDknAAAQP2r5DgAAAA5FcQYAIM5QnAEAiDMUZwAA4gzFGQCAOENxBgAgzlCckXLM7DAzm2Zm283sRd95UpWZPW1md4Uu/9LMloT5d9ea2cfRTedXZc/RzHLM7A+xzITYojgnOTNbZWZ7zWyXmW0IfSAeUWqZ08zsfTPbGSpY08ysS6llGpvZg2a2OrSu5aHrzct5XDOzm8xsgZntNrO1ZvaimZ0Uzecbpt9JaimpmXPu8pquzMwyzcyZ2aRSt39sZteGLl8bWmZwqWXWmllmTTOEkbHk+2BjyfdByQ/6Es/l1VJ//9PQ7TmlbjczW2Fmi2qSzzn3kXPu+JqsIxypUNiRHCjOqeE3zrkjJAUkdZM07MAdZvYLSTMk/UdSK0nHSPpK0iwzOza0TD1J70k6UdJ5khpL+oWkLZJ+Xs5jPiTpZkk3SWoqqZOk1yT1qmp4M6tT1b+pRHtJS51zhRHMslvSNWbWoYI/3yppsJk1qurjRsiB90F3SRmSRpSz3CZJvzCzZiVu6ydpaRnL/krSUZKONbNTIhk2mUXhPY0kQ3FOIc65DZLeVrBIH3CfpMnOuYecczudc1udcyMkfSZpdGiZvpLaSbrEObfIOVfsnPvBOXenc2566ccxs46SbpDU2zn3vnNuv3Nuj3Pu3865e0LLHLJZrnRHE+rSbjCzbyV9a2aPmtn9pR7nP2Y2IHS5lZm9bGabzGylmd1U1hiY2RhJoyT9v1AXeZ2Z1TKzEWb2nZn9YGaTzSwttHyHUJbrzGy1pPfLGd48SU9Lur2c+yVpsaRPJQ2oYJmSWdNCWTaFso0ws1qh+64Ndeb3m9m20HM+P5z1OufWSXpTUtdyFslX8IvUlaHHqi3p/0n6dxnL9lPwi9300OWKnk83M5sX2kIzRVKDEvdlmtnaEteHhrbO7DSzRWZ2yY9XZ/8Iben5xszOLHFHmpk9YWbrzWydmd1lZrXN7ARJ/1Twi8cuM8sLLV8/NI6rQ1sV/mlmh4Xua25mr5tZnpltNbOPDrwGZTw/Z8GtRSvMbLOZjS/1es0ys4lmtkXS6Ipe38qeYxmP/b9mtjj0XnjbzNqXyvVXM/s2NJ53mtlxZvaJme0wsxdCX8ARRyjOKcTM2kg6X9Ky0PXDJZ0mqaz9ri9IOjt0+SxJbznndoX5UGdKWuucm12zxPqtpB6Sukh6TsGCapJkZkdKOkfS86EPtGkKdvytQ49/i5mdW3qFzrnbJY2VNMU5d4Rz7glJ14b+/VrSsZKOkPSPUn96uqQTJP1onSXcLekyM6to8+zIULamFSxzwN8lpYUyna7gl6Tfl7i/h6Qlkpor+CXriQPjUxEzayvpAklfVrDY5NDjScHnvEDS96XWc7iCuwj+Hfp3ZXkf8qHbX5P0jIJbUl6UdFkFj79c0i8VfP5jJD1rZj8pcX+P0DLNFfxC9EqJMX1aUqGkdAW3FJ0j6Q/OucWS/izp09Br3yS0/D0KbtkJhP6mtYJf4CTpVklrJbVQcFfIcEkVHfP4EgW3SnSXdLGk/y2VeUVoPXcrvNe3vOd4kJldHMp1aSjnRwr+/1LSuZJ+JulUSYMlZUm6WlJbBb+k9a7gOcEDinNqeM3MdkpaI+kH/be7a6rge2B9GX+zXsEPBUlqVs4y5anq8uUZF+rk9yr4geMU/MCWgkXhU+fc95JOkdTCOXeHcy7fObdC0uMKdX5huErSBOfcitAXkGEKFpqSmx5HO+d2h7KUKbRl4p+S7qhgmVxJ70gaUlGgULd6paRhoS0aqyQ9IOmaEot955x73DlXJOn/JP1EwQ/+8rwW6hY/lvShgl9Sysv5iaSmoS8afRUs1qVdKmm/grtF3pBUV+Xvtjg1dP+DzrkC59xLkuZU8PgvOue+D22lmSLpWx26C+WHEuuaouCXlF5m1lLBLx63hF6vHyRNVDnvhdCXmesl9Q+913YqOC4Hli9QcFzbhx7rI1fxCQnuDa1ntaQHdWjR+9459/fQ7pR8Vf76lvkcy3jMPyv4/8ri0LrHSgqU7J4l3eec2+GcW6jgF60Zoff7dgW3onSr4DnBA4pzavitc66RpExJnfXfortNUrGCHz6l/UTS5tDlLeUsU56qLl+eNQcuhD4Qn9d/P+z66L+bWdtLahXa9JgXKkDDVXGhKqmVpO9KXP9OUp1Sf79G4blX0rlm9tMKlhkl6S+hQlKe5goWs9K5Wpe4vuHABefcntDFQyb7lfJb51wT51x759xfK/qiEfKMpBsV3KLwahn395P0gnOu0Dm3T9LLKn/TditJ60oVtu/KWVZm1tfMcku8nl313/etyllXKwXfC3UlrS/xt48puF+8LC0kHS7pixLLvxW6XZLGK7ilaUZoc/XQ8jKHlHyfHMhU1n3hvL7lPcfS2kt6qET+rZKs1Lo2lri8t4zrFb1v4AHFOYU45z5UcJPf/aHruxXcB1rWjOUrFJwEJknvKlhwGob5UO9JamNmGRUss1vBD8UDji4rcqnrz0n6Xagj6KFgMZCCH3orQ4XnwL9GzrkLwsz7vYIfcAe0U3CzaMkPsLBO3+ac26Jgx3RnBct8I+kVSbdVsKrNCnZtpXOtCydHhDwj6a+Sppco/pIO7iI5Q9LVFvwVwAYFt2ZcYGXP4F8vqXWpze7tynrQ0Ov7uIJfDJqFNj8vULDgHFDWur5X8L2wX1LzEu+Fxs65E0PLlX4dNytYnE4ssXxaaOKcQl3trc65YyVdJGlARft+FdxMXDrTASUfO5zXt7znWNoaSX8q9f4/LLT1AwmK4px6HpR0donObqikfqGJLI3M7EgL/vb0Fwru65OCH9JrJL1sZp0tOIGqmZkNN7MfFUDn3LeSJkl6zoITfeqZWQMzu7JE55Er6VIzO9zM0iVdV1lw59yXCn6o/UvS2865vNBdsyXtNLMhFvwNc20z62rhzx5+TlJ/MzvGgj8vOrBPusqzuUMmKLgv/4QKlhmj4P7FJmXdGdpU/YKku0OvS3sFJ5I9W81MVeacW6ngvtCyvkRco+Ds7eMV3FcbUHC/7VqVvf/yUwW/8NxkZnXN7FKVP9O/oYKFbJMkmdnv9ePJa0eVWNflCo71dOfcegU3sz9gwZ//1QpNfjo99HcbFfziWC/0HIsV/CIw0cyOCj1e6wPzFczsQjNLDxXJ7ZKKFNzaVJ5Bof+H2ir4a4UpZS0U5utb5nMsY3X/lDTMzE4MZU4LLY8ERnFOMc65TQruPxwVuv6xgpNFLlWwu/lOwf1PPUNFVs65/QpOCvtGwf2lOxQsiM0lfV7OQ92k4KSqRxScybxcwcky00L3T1Rwv9tGBfeXljUTuCzZoSzZJZ5TkaQLFSwQK/XfAp4W5jqfVPALyMzQ3++T9Lcw//ZHnHM7FJygVe6kr1Dhe0bBQlSevym4hWGFgvuJs0NZY8Y593Fov35p/SRNcs5tKPlPwULxo03bzrl8Bd9j1yq42fX/Kbj1oKzHXKTg/tdPFXx/nCRpVqnFPpfUUcHX+m5JvwtttZCC+8jrSVqk4K6bl/Tf3SzvS1ooaYOZHdhtM0TBTdefmdkOBbcUHZjU1zF0fVcozyTn3Adl5Q75j6QvFPzy+YakJypYtrLXt6LneJBz7lUFd6c8H8q/QMGJn0hgVvHcBgBAOMzMSeronFvmOwsSH50zAABxhuIMAECcYbM2AABxhs4ZAIA4Q3EGACDOVHpmFDN7UsGfqfzgnPvRgfJDv/97SMFD5u2RdK1zbl5l623evLnr0KHDweu7d+9Ww4bhHuMCVcX4RhfjGz2MbXQxvtFTemy/+OKLzc65FhX8yUHhnLbsaQV/r1rWsXWl4O/pOob+9ZD0aOi/FerQoYPmzp178HpOTo4yMzPDiIPqYHyji/GNHsY2uhjf6Ck9tmZW7iFrS6t0s7ZzbqaCBw0oz8UKnnLQOec+k9Sk1NljAABAFUTihN+tdegB3deGbovEWYkAAAhLVlaWsrOzK18wRpo3b17trRKRKM5hM7PrFTw9m1q2bKmcnJyD9+3ateuQ64gsxje6GN/oYWyjK5nGd9KkSVq2bJnS09O95nDOaePGjQoEAtUe20gU53U69EwsbVTOmXOcc1kKnuRbGRkZruQ3CvZ7RBfjG12Mb/QwttGVTOPbpEkTZWRkeP2yUVxcrMWLF6tevXpat25dtcc2Ej+lmiqprwWdKml76MwwAACkDOechg0bJuecOnbsWKN1hfNTquckZUpqbmZrJd2u4EnC5Zz7p4KnMLtAwbO67FHwNHgAAKSMgoICzZo1S0OHDtWRRx5Z4/VVWpydc2Wdm7Xk/U7SDTVOAgBAgrrzzjvVt2/fiBRmKcYTwgAAiNas6tzcXAUCgYivtyL79+/Xyy+/rNtvv121a9eO2Ho5fCcAIKays7OVm5sb8fUGAgH16dMn4uutyKRJk9SzZ8+IFmaJzhkA4EFNfmYUD3bv3q3HHntMAwYMiMr66ZwBAKii1157LapdOsUZAIAwbd++XUOGDFGfPn109NFHR+1xKM4AAIQhPz9fs2fP1pAhQxQ8IWP0UJwBAKjE5s2b1b9/f51++ulq2rRp1B+PCWEAkGJK/pQpLy9PTZo0ienj+/jJU01s2bJF3333ncaNG6d69erF5DHpnAEgxUTrp0zh8vGTp+pav369Ro0apc6dO6tx48Yxe1w6ZwBIQQd+ypRMJ76ItLVr12rbtm0aP368Dj/88Jg+Np0zAAClrF+/Xvfdd586duwY88Is0TkDAHCI5cuXa+fOnRo/frzq16/vJQOdMwAAITt27NCjjz6qE0880VthluicAQCQJC1atEgbN27U+PHjo/475srQOQMAUl5hYaFefvll/epXv/JemCU6ZwBAips3b55WrFihkSNH+o5yEJ0zACBlOec0Z84cXXbZZb6jHILOGQCQkmbNmqUFCxboT3/6k+8oP0LnDABIObt379a2bdt0/fXX+45SJjpnAIiBksez9i3Rjm0dae+++64WLlyom2++2XeUctE5A0AM+D6edUmJdGzrSFu5cqWaNWsW14VZonMGgJg5cDxr+PH6669r9erV+utf/+o7SqUozgCApPfxxx/rlFNO0YUXXug7SljYrA0ASGrTp0/XsmXL1LJlS99RwkbnDABIWq+88orOOeccHXHEEb6jVAnFGUDCiqcZ0JVJ9RnSPsycOVP5+fkJV5glNmsDSGDxNAO6Mqk8Q9qHJ554Ql27dtWVV17pO0q10DkDSGjMgEZpCxYsUPPmzdW0aVPfUaqNzhkAkDQeeughHX744br44ot9R6kRijMAICmsWbNGXbp00bHHHus7So1RnAEACc05p3vuuUebN2/W2Wef7TtORLDPGUBcmzZtmkaPHl3mfcyAhnNOa9eu1a9//Wt169bNd5yIoXMGENfee++9cmdkMwM6tTnnNGbMGG3YsEE9evTwHSei6JwBxD1mZKO04uJiLVy4UFdffbXS09N9x4k4OmcAQEJxzmnEiBEqLi5OysIs0TkDABJIYWGhcnJyNGTIEKWlpfmOEzV0zgCAhDF27Fi1bds2qQuzROcMIEKidZzrZcuWKSMjI+LrRWLJz8/XlClTNGLECNWqlfx9ZfI/QwAxEa3jXKenpzMjG3r88cf1y1/+MiUKs0TnDCCCojGrOicnR5mZmRFdJxLH3r179Y9//EODBg3yHSWmUuMrCAAg4TjnNG3aNF111VW+o8QcxRkAEHd27typQYMG6Xe/+51atWrlO07MUZwBAHFl3759+uKLLzR06NCU2cdcWmo+awBAXNq6dasGDBigU089Vc2bN/cdxxsmhAGIyM+gOAkFamrLli1avXq1xo0bpwYNGviO4xWdM4CI/AyKk1CgJjZu3KhRo0YpPT096Q8wEg46ZwCSOLkE/Pn++++1efNm3XfffWrYsKHvOHGBzhkA4M2mTZt0zz33qGPHjhTmEuicAQBerFq1Slu2bNH48eNVv35933HiCp0zACDm9uzZo7///e866aSTKMxloHMGkkRNZlwz0xqxtGTJEq1atUr333+/zMx3nLhE5wwkiZrMuGamNWKlqKhIL730ks4880wKcwXonIEkwoxrxLOvvvpKCxYs0G233eY7StyjcwYARF1xcbHmzJmj3r17+46SEOicAQBR9dlnn2nOnDn629/+5jtKwqBzBgBEzc6dO7Vt2zbdeOONvqMkFDpnIA5wbGsko5ycHM2dO1cDBw70HSXh0DkDcYBjWyPZLFu2TE2bNqUwVxOdMxAnmGmNZPHWW29p6dKluummm3xHSVgUZwBAxMycOVPdu3fXeeed5ztKQmOzNgAgImbMmKElS5boqKOO8h0l4dE5AwBq7JVXXtFZZ52lc845x3eUpEDnDACokc8//1x79+5V48aNfUdJGhRnAEC1PfXUU+rQoYOuuuoq31GSCsUZAFAt3377rRo3bqyWLVv6jpJ0KM4AgCp75JFHVFRUpMsuu8x3lKREcQYAVMmGDRuUnp6uzp07+46StCjOAICwOOd0//33a/Xq1Tr33HN9x0lqFGcAQKWcc1q3bp169uypn//8577jJD2KMwCgQs453XXXXVqzZo1OPfVU33FSAgchAQCUyzmn+fPnq0+fPjruuON8x0kZdM4AgHKNHj1ahYWFFOYYo3MGAPxIUVGR3n33XQ0cOFCNGjXyHSfl0DkDAH7kvvvuU9u2bSnMntA5AwAOKigo0LPPPqshQ4aoVi36N18YeQDAQU8//bR+9atfUZg9o3MGAGjfvn164IEHNHz4cJmZ7zgpL6yvRmZ2npktMbNlZja0jPvbmdkHZvalmX1tZhdEPioAIBqcc3rzzTfVr18/CnOcqLQ4m1ltSY9IOl9SF0m9zaxLqcVGSHrBOddN0pWSJkU6KAAg8vbu3asBAwboN7/5jdq0aeM7DkLC6Zx/LmmZc26Fcy5f0vOSLi61jJN04CzbaZK+j1xEAEA07N27V8uWLdOwYcNUpw57OeNJOK9Ga0lrSlxfK6lHqWVGS5phZn+T1FDSWWWtyMyul3S9JLVs2VI5OTkH79u1a9ch1xFZjG901XR88/LyJInXqAy8d6Nj165devzxx3X11Vdr0aJFWrRoke9ISacm791IfVXqLelp59wDZvYLSc+YWVfnXHHJhZxzWZKyJCkjI8NlZmYevC8nJ0clryOyGN/oqun4NmnSRJJ4jcrAezfytm7dqjVr1ujpp5/WV199xfhGSU3eu+Fs1l4nqW2J621Ct5V0naQXJMk596mkBpKaVysRACBqNm/erJEjR6pDhw468sgjfcdBOcIpznMkdTSzY8ysnoITvqaWWma1pDMlycxOULA4b4pkUABAzWzYsEHr1q3TPffco7S0NN9xUIFKi7NzrlDSjZLelrRYwVnZC83sDjO7KLTYrZL+aGZfSXpO0rXOORet0ACAqtm2bZvuvPNOpaenc0jOBBDWPmfn3HRJ00vdNqrE5UWS/iey0QAAkbB69Wp9//33mjBhgurXr+87DsLA8dkAIInt379fDz30kLp160ZhTiD8sA2IkqysLGVnZ4e1bG5urgKBQJQTIdV8++23WrJkie6//36O/JVg6JyBKMnOzlZubm5YywYCAfXp0yfKiZBKnHN66aWXdN5551GYExCdMxBFgUCAA2gg5hYsWKC5c+dq2LBhvqOgmuicASCJFBcXa+7cuerbt6/vKKgBOmcASBJz587VzJkzNWDAAN9RUEN0zgCQBLZv366tW7eqf//+vqMgAijOAJDgPvroIz366KM655xzmPyVJCjOAJDAlixZoqZNm2rIkCG+oyCCKM4AkKDeffddvfHGGzrxxBPpmJMME8IAIAHNnDlTJ598ss466yzfURAFdM4AkGBycnK0aNEiHXXUUb6jIEronAEggbz66qvKzMxUZmam7yiIIoozUEpVjol9QF5enpo0aXLIbRwvG5GWm5urHTt26Mgjj/QdBVHGZm2glKocE7siHC8bkfTMM8+oWbNm6tevn+8oiAE6Z6AMVT0mdk5ODpsZETWrV69W/fr11bZtW99RECN0zgAQxx577DFt27ZNV1xxhe8oiCGKMwDEqU2bNqldu3b66U9/6jsKYoziDABxaOLEiVqyZInOP/9831HgAfucASCOOOe0bt06nXbaaerRo4fvOPCEzhkA4oRzTuPGjdPKlSspzCmOzhkA4oBzTrm5uerdu7eOOeYY33HgGZ0zAMSBu+66S4WFhRRmSKJzBgCviouLNX36dA0YMEANGzb0HQdxgs4ZADyaMGGC2rdvT2HGIeicAcCDwsJCPfXUU7r11ls5FzN+hOKMpFGdE1aUhRNWIBaeffZZnX766RRmlInN2kganLACiWD//v2644471K9fP3Xq1Ml3HMQpOmcklaqesAKIJeec3n33XfXr14+OGRWicwaAGNizZ4/69++vs88+W+3bt/cdB3GO4gwAUbZ3717Nnz9fQ4cOVb169XzHQQKgOANAFO3YsUMDBw5U586ddfTRR/uOgwTBPmcklIpmZDPLGvFm27ZtWr16te644w6lpaX5joMEQueMhFLRjGxmWSOebN26VSNGjFD79u3VrFkz33GQYOickXCYkY14t2nTJq1bt07jxo1T48aNfcdBAqJzBoAI2rlzp8aMGaP09HQKM6qNzhkAImTdunVauXKlJkyYwKxs1AidMwBEQGFhoR566CFlZGRQmFFjdM6IeyVnaDMjG/FoxYoV+uqrr3Tffff5joIkQeeMuFdyhjYzshFvnHN6+eWXdeGFF/qOgiRC54yEwAxtxKPFixfro48+0qBBg3xHQZKhcwaAaigqKtIXX3yh6667zncUJCE6ZwCooi+//FIzZszQkCFDfEdBkqJzBoAq2LZtm7Zt28ambEQVnTO8qOgY2aUxQxvx4pNPPtH777+vESNG+I6CJEfnDC8qOkZ2aczQRjxYvHixjjzySN12222+oyAF0DnDG2ZgI1F8+OGHmj17tgYOHCgz8x0HKYDiDAAV+PDDD9W5c2edfvrpvqMghbBZGwDK8cknn2j+/Plq2bKl7yhIMXTOAFCG//znPzrttNN02mmn+Y6CFERxRtRUNCObGdiIZ4sWLdLmzZvVokUL31GQotisjaipaEY2M7ARr/7973+rfv36HPkLXtE5I6qYkY1EsmHDBtWqVUvHHXec7yhIcXTOACDpX//6l9asWaPevXv7jgJQnAFg69at+slPfqJTTjnFdxRAEpu1AaS4hx9+WCeddJJ69erlOwpwEMUZQMpau3atevTooR49eviOAhyCzdoAUtI999yjb7/9lsKMuETnDCClOOf0xRdfqE+fPmrXrp3vOECZ6JwBpJR7771XBQUFFGbENTpnACmhuLhY06ZN080336zDDjvMdxygQnTOAFLCI488ovbt21OYkRDonAEktaKiIj3++OO68cYbORczEgadM4CkNmXKFGVmZlKYkVDonAEkpfz8fI0dO1ajRo1SrVr0IUgsvGMBJJ3i4mJ9+OGH6tevH4UZCYl3LYCksnfvXvXv3189e/bUMccc4zsOUC1s1gaQNPbs2aPFixdr8ODBzMpGQqNzBpAUdu7cqUGDBqlDhw5q3bq17zhAjdA5o0qysrKUnZ0d1rK5ubkKBAJRTgRI27dv16pVqzR69Gg1a9bMdxygxuicUSXZ2dnKzc0Na9lAIKA+ffpEORFSXV5enoYNG6a2bduqRYsWvuMAEUHnjCoLBALKycnxHQPQ5s2btXr1ao0bN05paWm+4wARQ+cMICHt3btXo0ePVseOHSnMSDp0zgASzvr167V48WJNnDhRdevW9R0HiDg6ZwAJpbi4WA8++KBOPfVUCjOSFp0zgISxatUqffbZZ7r33nt9RwGiKqzO2czOM7MlZrbMzIaWs8wVZrbIzBaaWXi/tQGAKnjllVd06aWX+o4BRF2lnbOZ1Zb0iKSzJa2VNMfMpjrnFpVYpqOkYZL+xzm3zcyOilZgAKlnyZIleueddzRgwADfUYCYCKdz/rmkZc65Fc65fEnPS7q41DJ/lPSIc26bJDnnfohsTACpqqioSPPmzdOf//xn31GAmAmnOLeWtKbE9bWh20rqJKmTmc0ys8/M7LxIBQSQur7++mtlZ2erd+/eqlOHKTJIHZF6t9eR1FFSpqQ2kmaa2UnOubySC5nZ9ZKul6SWLVseciCLXbt2cWCLKIrU+OblBV9SXqtD8f6NvO3bt2vlypW6+OKLGdso4r0bPTUZ23CK8zpJbUtcbxO6raS1kj53zhVIWmlmSxUs1nNKLuScy5KUJUkZGRkuMzPz4H05OTkqeR2RFanxbdKkiSTxWpXC+zeyZs+erQ8++EBjxoxhbKOM8Y2emoxtOJu150jqaGbHmFk9SVdKmlpqmdcU7JplZs0V3My9olqJAKS0hQsXKi0tTaNHj/YdBfCm0uLsnCuUdKOktyUtlvSCc26hmd1hZheFFntb0hYzWyTpA0mDnHNbohUaQHKaNWuWpk6dqk6dOsnMfMcBvAlrn7Nzbrqk6aVuG1XispM0IPQPAKps5syZ6tSpk0477TQKM1Ieh+8E4N3cuXM1b948HX300RRmQBRnAJ5NmzZNrVq10i233OI7ChA3+OEgfiQrK0vZ2WUfgTU3N1eBQCDGiZCsli9frvXr16tVq1a+owBxhc4ZP5Kdna3c3Nwy7wsEAurTp0+MEyEZTZkyRfv379f111/vOwoQd+icUaZAIMCBCRA1W7ZsUWFhobp06eI7ChCXKM4AYurpp59Wenq6rrrqKt9RgLjFZm0AMbN9+3a1aOvoPbQAABzKSURBVNFCPXv29B0FiGt0zgBiYtKkSUpPT1evXr18RwHiHsUZQNStWbNGp5xyik455RTfUYCEQHFOUfxcCrHywAMP6OSTT9bZZ5/tOwqQMNjnnKL4uRSizTmnzz//XFdeeSWFGagiOucUxs+lEE0TJkzQqaeeqtatW/uOAiQcijOAiHLO6dVXX9UNN9ygBg0a+I4DJCQ2awOIqKysLLVv357CDNQAnTOAiCgqKtKkSZN04403cmYpoIbonAFExCuvvKIzzjiDwgxEAMUZQI0UFBRo5MiRuuSSS3TiiSf6jgMkBYozgGorLi7WrFmz1K9fP9Wpw14yIFIozgCqZd++ferfv79+9rOfKT093XccIKnwVRdAle3du1dLlizRwIED1ahRI99xgKRD5wygSnbv3q1BgwapVatWatu2re84QFKicwYQtp07d2rlypUaOXKkjjrqKN9xgKRF5wwgLDt37tTQoUPVqlUrtWzZ0nccIKnROQOo1NatW7VixQqNHTtWaWlpvuMASY/OGUCF8vPzNWrUKHXs2JHCDMQInTOAcm3cuFG5ubl68MEH+R0zEEN0zgDK5JzTww8/rJ49e1KYgRjj/zgAP7JmzRrl5OTo7rvv9h0FSEl0zgB+5LXXXtPll1/uOwaQsuicARy0fPlyTZ06Vf379/cdBUhpdM4AJAXPLjVv3jzdeOONvqMAKY/OGYAWLlyoF154QWPGjPEdBYDonIGU98MPPygvL0+jRo3yHQVACMU5RUybNk2ZmZkH/+Xm5vqOhDjwxRdf6OGHH9Zpp52m2rVr+44DIITinCLee++9QwpyIBBQnz59PCaCbwsWLFCjRo105513ysx8xwFQAvucU0ggEFBOTo7vGIgDs2fP1owZM3TbbbdRmIE4ROcMpJiPPvpIbdq0oTADcYziDKSQr7/+WrNnz1arVq0ozEAcozgDKWL69OlKS0vTrbfe6jsKgEqwzzmJZGVlKTs7u8z7li1bpoyMjBgnQrxYs2aNVq1apQsuuMB3FABhoHNOItnZ2eX+RCo9PZ3Z2SnqpZde0pYtW/TXv/7VdxQAYaJzTjLlzcjOyclRZmZmzPPAr+3bt2vv3r0KBAK+owCoAoozkKSeeeYZtW7dWtdcc43vKACqiM3aQBLasWOHmjVrpjPOOMN3FADVQOcMJJnHHntMbdq0Ua9evXxHAVBNFGcgiXz33XfKyMjQz372M99RANQAm7WBJPHQQw9p0aJFFGYgCdA5AwnOOadPPvlEV1xxhX7yk5/4jgMgAuicgQT38MMPq7CwkMIMJBE6ZyBBOef04osv6s9//rPq16/vOw6ACKJzBhLUU089pfbt21OYgSRE5wwkmOLiYj388MO6+eabObMUkKTonIEE8/rrr+uMM86gMANJjOIMJIjCwkKNHDlS5557rk4++WTfcQBEEcUZSABFRUWaPXu2rrnmGvYxAymA4gzEufz8fA0cOFAnnHCCOnXq5DsOgBhgQhgQx/bt26elS5fqlltu0ZFHHuk7DoAYoXMG4tSePXs0aNAgtWjRQu3bt/cdB0AM0TkDcWj37t1avny5hg8fzpG/gBRE5wzEmd27d2vw4ME6+uijKcxAiqJzBuJIXl6elixZorFjxyotLc13HACe0DkDcaKwsFCjRo1Sp06dKMxAiqNzBuLApk2b9Pnnn2vixImqXbu27zgAPKNzBjxzzukf//iHMjMzKcwAJNE5A16tW7dOb7/9tsaMGeM7CoA4QucMeOKc09SpU9W7d2/fUQDEGTpnwIOVK1dqypQpGjp0qO8oAOIQnTMQY/v371dubq4GDBjgOwqAOEVxBmJo8eLFGjNmjC655BLVq1fPdxwAcYriDMTIhg0btH37dt15552+owCIc+xzTgBZWVnKzs6udLnc3FwFAoEYJEJV5ebmasqUKbr77rtVqxbfiQFUjE+JBJCdna3c3NxKlwsEAurTp08MEqEqFixYoIYNG1KYAYSNzjlBBAIB5eTk+I6BKpo3b56mTp2q22+/XWbmOw6ABMHXeCBKZs2apebNm1OYAVQZxRmIgm+++UYff/yx2rZtS2EGUGUUZyDCZsyYoVq1amnIkCEUZgDVElZxNrPzzGyJmS0zs3IPaWRml5mZM7OMyEUEEsfGjRv1zTffqFOnTr6jAEhglRZnM6st6RFJ50vqIqm3mXUpY7lGkm6W9HmkQwKJ4LXXXtOqVat00003+Y4CIMGF0zn/XNIy59wK51y+pOclXVzGcndKulfSvgjmAxLC3r17tWPHDvXo0cN3FABJIJzi3FrSmhLX14ZuO8jMuktq65x7I4LZgITw3HPPaf78+erbt6/vKACSRI1/52xmtSRNkHRtGMteL+l6SWrZsuUhv9vdtWsXv+MtR15eniTVaHwY3+jYvXu3vvvuO3Xt2pXxjRLeu9HF+EZPTcY2nOK8TlLbEtfbhG47oJGkrpJyQjNTj5Y01cwucs7NLbki51yWpCxJysjIcJmZmQfvy8nJUcnr+K8mTZpIUo3Gh/GNvCeffFJNmzbV0KFDGd8oYmyji/GNnpqMbTjFeY6kjmZ2jIJF+UpJB48R6ZzbLqn5getmliNpYOnCDCSTFStWqHv37hzLHEBUVFqcnXOFZnajpLcl1Zb0pHNuoZndIWmuc25qtEMmu8pObMEJLeLLI488onbt2uk3v/mN7ygAklRY+5ydc9MlTS9126hyls2seazUcuDEFuUVYE5oET8++ugjXX755TrqqKN8RwGQxDjxRZzgxBbx79FHH9Xxxx9PYQYQdRRnoBLOOT3//PP6wx/+oLp16/qOAyAFcGxtoBLZ2dnq0KEDhRlAzNA5A+UoLi7Wgw8+qJtvvlm1a9f2HQdACqE4x0hFM7KZjR2fZsyYoV//+tcUZgAxx2btGDkwI7sszMaOL0VFRRoxYoR+9atfqVu3br7jAEhBdM4xxIzs+FdUVKR58+bpqquu0uGHH+47DoAURecMhBQUFGjQoEFq3769TjjhBN9xAKQwOmdA0v79+/Xtt9/qxhtv5HfMALyjc0bK27dvnwYNGqQmTZro2GOP9R0HACjO0ZSVlaXMzExlZmaWOxkMfu3Zs0dLly7V0KFD1aZNG99xAEASxTmqSs7QZkZ2/Nm3b58GDx6so446Sq1atfIdBwAOYp9zlDFDOz7t2LFD8+fP19ixY9W4cWPfcQDgEHTOSDnFxcUaOXKkOnfuTGEGEJfonJFStmzZopkzZ2rixImqVYvvpgDiE59OSCmTJk3SmWeeSWEGENfonJESNmzYoP/85z8aOXKk7ygAUCnaByQ955ymTZuma665xncUAAgLnTOS2nfffafJkyfTMQNIKHTOSFr79u3T119/rcGDB/uOAgBVQnFGUlq6dKlGjRqlCy+8UPXr1/cdBwCqhOKMpPP9999r+/btGjt2rMzMdxwAqDKKM5LK/Pnz9dBDD6l79+6qU4cpFQASE59eSBoLFixQgwYNNG7cOH7HDCCh8QmGpLBgwQK98MILOu644yjMABIen2JIeJ9++qkaNmyoMWPGUJgBJAU+yZDQVqxYoQ8++EAdOnRg8heApEFxRsJ67733tGfPHg0bNozCDCCpUJyRkLZu3aoFCxaoa9euFGYASYfZ2hGUlZWl7Ozsg9dzc3MVCAQ8JkpOr7/+utLS0nTzzTf7jgIAUUHnHEHZ2dnKzc09eD0QCKhPnz4eEyWfffv2aevWrfrlL3/pOwoARA2dc4QFAgHl5OT4jpGUXnjhBTVo0EB9+/b1HQUAoorijISwY8cONW7cWOedd57vKAAQdRRnxL3/+7//0+GHH67LL7/cdxQAiAmKM+Lat99+q+7du+ukk07yHQUAYoYJYYhbjz32mBYtWkRhBpBy6JwRlz744ANddtllat68ue8oABBzdM6IO//6179UUFBAYQaQsuicETecc3r22Wd17bXXci5mACmNzhlx46WXXlKHDh0ozABSHp+C8M45pwkTJuimm25S3bp1fccBAO/onGsoKytLmZmZyszMPOTQnQjfBx98oNNPP53CDAAhFOcaKnk8bY6lXTXFxcUaMWKEMjIylJGR4TsOAMQNNmtHAMfTrrqioiLNnz9fV155pRo3buw7DgDEFTpnxFxBQYGGDBmiFi1aqGvXrr7jAEDcoXNGTOXn52vZsmX605/+pNatW/uOAwBxic4ZMbN//34NHjxYhx9+uDp27Og7DgDELTrnMGRlZSk7O7vM+3JzcxUIBGKcKPHs3btXS5cu1aBBg+iYAaASdM5hKDkjuzRmaFeuoKBAgwYNUvPmzSnMABAGOucwMSO7enbu3Kl58+Zp3LhxatSoke84AJAQ6JwRNc45jR49Wl26dKEwA0AV0DkjKrZt26Z33nlH48ePV61afAcEgKrgUxNRkZWVpXPOOYfCDADVQOdchtKzs5mRHb4ffvhBL7zwgoYMGeI7CgAkLNqaMpSenc2M7PA45/TGG2/o97//ve8oAJDQ6JzLwezsqlm7dq2ysrJ0xx13+I4CAAmPzhk1tnfvXi1YsEDDhw/3HQUAkgLFGTWyfPly3XbbbTr33HPVoEED33EAIClQnFFta9eu1fbt23XvvffKzHzHAYCkQXFGtSxevFgPP/ywTj75ZNWtW9d3HABIKhRnVNnChQtVp04djRs3TnXqMKcQACKN4owq+eabb5Sdna3jjjtOtWvX9h0HAJISxRlhmz17tmrXrq277rqLI38BQBTxCYuwrF27Vm+99ZbS09OZ/AUAUcYOQ1Tqww8/VKNGjTRy5EgKMwDEAJ0zKrRz5059+eWX6tatG4UZAGKEzhnlevPNN1W3bl3dcsstvqMAQEqhc0aZ8vPztWnTJp111lm+owBAyqFzxo+88sorKi4uVt++fX1HAYCURHHGIbZv364jjjhC55xzju8oAJCyKM446Nlnn1WtWrU4dzUAeEZxhqTgkb+6d++uLl26+I4CACmPCWHQE088oYULF1KYASBO0DmnuPfee0+XXHKJmjZt6jsKACCEzjmFTZ48Wfv376cwA0CcoXNOUZMnT1afPn045SMAxCE65xQ0depUtWvXjsIMAHEqrOJsZueZ2RIzW2ZmQ8u4f4CZLTKzr83sPTNrH/moqCnnnB544AGde+65yszM9B0HAFCOSouzmdWW9Iik8yV1kdTbzEpP6/1SUoZz7mRJL0m6L9JBUXOzZs1Sz549Vb9+fd9RAAAVCKdz/rmkZc65Fc65fEnPS7q45ALOuQ+cc3tCVz+T1CayMVETxcXFevLJJ3XCCSeoR48evuMAACoRzk7H1pLWlLi+VlJFn/DXSXqzrDvM7HpJ10tSy5YtlZOTc/C+Xbt2HXLdp7y8PEmKmzw1UVRUpNWrV+uUU07R/PnzfcdJWvH0/k02jG10Mb7RU5OxjeiMIDO7WlKGpNPLut85lyUpS5IyMjJcyf2eOTk5cbMftEmTJpIUN3mqq7CwUMOHD9cNN9yglStXJvzziWfx9P5NNoxtdDG+0VOTsQ1ns/Y6SW1LXG8Tuu0QZnaWpNskXeSc21+tNIiYgoICLVu2TNddd53at2d+HgAkknCK8xxJHc3sGDOrJ+lKSVNLLmBm3SQ9pmBh/iHyMVEV+fn5Gjx4sOrWravjjz/edxwAQBVVulnbOVdoZjdKeltSbUlPOucWmtkdkuY656ZKGi/pCEkvmpkkrXbOXRTF3CjHvn379M0332jgwIFq3bq17zgAgGoIa5+zc266pOmlbhtV4vJZEc6FaigqKtLgwYM1aNAgCjMAJDAOEZUkdu/erc8++0zjxo1Tw4YNfccBANQAh+9MEnfccYe6du1KYQaAJEDnnODy8vL0xhtv6J577lFofz8AIMHROSe4J554Queffz6FGQCSCJ1zgtq8ebMmT56sW2+91XcUAECE0TknIOec3nrrLf3xj3/0HQUAEAUU5wTz/fffa/jw4br66qvVqFEj33EAAFFAcU4gu3fv1qJFizRq1KjKFwYAJCyKc4JYtWqVhg8frjPOOEOHHXaY7zgAgCiiOCeAtWvXKi8vT+PHj1etWrxkAJDs+KSPc0uXLtXEiRN14oknql69er7jAABigOIcxxYtWiRJuvfee1W3bl3PaQAAsUJxjlPLly/X5MmTddxxx6lOHX6ODgCphOIch7744gvt379fY8eOVe3atX3HAQDEGMU5zvzwww+aNm2aTjjhBCZ/AUCKYntpHPn4449Vp04djR492ncUAIBHtGZxYu/evZozZ4569OjhOwoAwDM65zjwzjvvKD8/X/379/cdBQAQB+icPSsoKNDGjRvVq1cv31EAAHGCztmjqVOnateuXbr66qt9RwEAxBGKsyfbtm1Tw4YNddFFF/mOAgCIMxRnD55//nnl5+erb9++vqMAAOIQxTnGFi5cqG7duun444/3HQUAEKcozpKysrKUnZ198Hpubq4CgUDEH2fy5Mlq0KCBrrjiioivGwCQPCjOkrKzsw8pyIFAQH369InoY8yYMUMXX3yx0tLSIrpeAEDyoTiHBAIB5eTkRGXdzz//vBo2bEhhBgCEheIcZU8//bSuuuoqTvkIAAgbByGJorfeektt2rShMAMAqoTOOQqcc3rggQf0l7/8RQ0bNvQdBwCQYFK2c87KylJmZqYyMzOVm5sbsfU65zRnzhz94he/oDADAKolZYvzgRnaUuRmZxcXF+v2229Xu3bt9D//8z81Xh8AIDWl9GbtSM7QLi4u1tKlS/Xb3/5WRx99dETWCQBITSnbOUdSUVGRhg0bpjp16qh79+6+4wAAElxKd86RUFhYqOXLl+v3v/+90tPTfccBACQBOucaKCgo0ODBg2Vm6ty5s+84AIAkQedcTfv379fChQt16623qnXr1r7jAACSCJ1zNRQXF2vIkCFq1qwZhRkAEHF0zlW0Z88ezZw5U+PGjdNhhx3mOw4AIAnROVfR3XffrZ/+9KcUZgBA1NA5h2nHjh169dVXddddd8nMfMcBACQxOucwPfXUU+rVqxeFGQAQdXTOldi6dav+9a9/afDgwb6jAABSBJ1zBYqLi/XOO+/oT3/6k+8oAIAUQnEux4YNGzRkyBBdccUVSktL8x0HAJBCKM5l2Llzp7755huNHj2afcwAgJijOJeyevVqDR8+XD179uR8zAAALyjOJaxZs0Z5eXm6//77VacOc+UAAH5QnEOWL1+uiRMnqnPnzqpfv77vOACAFEZ7KOmbb76RJN17772qW7eu5zQAgFSX8p3z6tWr9dRTT6ljx44UZgBAXEjpznnXrl3Ky8vTuHHjVKtWyn9PAQDEiZStSIWFhdq8ebO6du1KYQYAxJWUrEqfffaZdu3apQ4dOlCYAQBxJ+UqU35+vj799FOO+gUAiFspVZzff/99vf766+rfvz9H/gIAxK2UKc4FBQVav369Lr30Ut9RAACoUErM1n7jjTe0adMmXXvttb6jAABQqaQvzps3b1bDhg3Vq1cv31EAAAhLUhfnF198UTt37tT//u//+o4CAEDYkrY4f/311+rWrZvS09N9RwEAoEqSckLYc889p/nz51OYAQAJKek65zfffFO9evVS48aNfUcBAKBakqo4v/zyy6pVqxaFGQCQ0JKmOD/99NPq3bs352IGACS8pNjn/P777+voo4+mMAMAkkJCd87OOU2YMEF/+MMfOFY2ACBpJGxxds7p66+/1vr163XxxRdX+e9zc3MVCASikAwAgJpJyM3azjndeeedOvLIIzV37lzl5uZWeR2BQEB9+vSJQjoAAGom4Trn4uJirVixQueff77atWsnKVhoc3Jy/AYDACBCEqpzLi4u1ogRI1RQUKBTTjnFdxwAAKIiYTrnoqIiLV++XFdffbVOOOEE33EAAIiahOicCwsLNWTIEBUVFalLly6+4wAAEFVx0TlnZWVp0qRJatKkyY/uKy4u1u7du1WvXj3NnTv3R/cz6xoAkGzionPOzs7WsmXLfnS7c04rV65UnTp1yj3ACLOuAQDJJi46Z0lKT08/ZMb1vn379O677+qss85SgwYN/AUDACDG4qJzLst9992nbt26UZgBACknrOJsZueZ2RIzW2ZmQ8u4v76ZTQnd/7mZdahuoF27dumJJ57QyJEj1bp16+quBgCAhFVpcTaz2pIekXS+pC6SeptZ6SnT10na5pxLlzRR0r3VDfTMM8/ooosukplVdxUAACS0cDrnn0ta5pxb4ZzLl/S8pNIHs75Y0v+FLr8k6UyrYnUtLCzU3Xffrb/85S9q0aJFVf4UAICkEk5xbi1pTYnra0O3lbmMc65Q0nZJzaoSZNeuXbrhhhuq8icAACSlmM7WNrPrJV0vSS1btjw4O7t58+ZKS0ur1gksEJ5du3Zx/PEoYnyjh7GNLsY3emoytuEU53WS2pa43iZ0W1nLrDWzOpLSJG0pvSLnXJakLEnKyMhwmZmZkqTMzEzl5OTowHVEHuMbXYxv9DC20cX4Rk9NxjaczdpzJHU0s2PMrJ6kKyVNLbXMVEn9Qpd/J+l955yrViIAAFJcpZ2zc67QzG6U9Lak2pKedM4tNLM7JM11zk2V9ISkZ8xsmaStChZwAABQDearwTWzTZK+K3FTc0mbvYRJDYxvdDG+0cPYRhfjGz2lx7a9cy6snyN5K86lmdlc51yG7xzJivGNLsY3ehjb6GJ8o6cmYxu3h+8EACBVUZwBAIgz8VScs3wHSHKMb3QxvtHD2EYX4xs91R7buNnnDAAAguKpcwYAAPJQnGN5+slUFMb4DjCzRWb2tZm9Z2btfeRMRJWNbYnlLjMzZ2bMgK2CcMbXzK4IvX8Xmll2rDMmqjA+F9qZ2Qdm9mXos+ECHzkTkZk9aWY/mNmCcu43M3s4NPZfm1n3sFbsnIvZPwUPYrJc0rGS6kn6SlKXUsv8VdI/Q5evlDQllhkT+V+Y4/trSYeHLv+F8Y3c2IaWayRppqTPJGX4zp0o/8J873aU9KWkI0PXj/KdOxH+hTm2WZL+ErrcRdIq37kT5Z+kX0nqLmlBOfdfIOlNSSbpVEmfh7PeWHfOMTn9ZAqrdHydcx845/aErn6m4LHSUblw3ruSdKeC5zPfF8twSSCc8f2jpEecc9skyTn3Q4wzJqpwxtZJahy6nCbp+xjmS2jOuZkKHhmzPBdLmuyCPpPUxMx+Utl6Y12cY3L6yRQWzviWdJ2C3+hQuUrHNrS5qq1z7o1YBksS4bx3O0nqZGazzOwzMzsvZukSWzhjO1rS1Wa2VtJ0SX+LTbSUUNXPZUkxPmUk4oeZXS0pQ9LpvrMkAzOrJWmCpGs9R0lmdRTctJ2p4BafmWZ2knMuz2uq5NBb0tPOuQfM7BcKniuhq3Ou2HewVBXrzrkqp59URaefRJnCGV+Z2VmSbpN0kXNuf4yyJbrKxraRpK6ScsxslYL7lqYyKSxs4bx310qa6pwrcM6tlLRUwWKNioUzttdJekGSnHOfSmqg4HGhUXNhfS6XFuvizOkno6vS8TWzbpIeU7Aws88ufBWOrXNuu3OuuXOug3Oug4L78y9yzs31EzfhhPPZ8JqCXbPMrLmCm7lXxDJkggpnbFdLOlOSzOwEBYvzppimTF5TJfUNzdo+VdJ259z6yv4oppu1HaefjKowx3e8pCMkvRiaZ7faOXeRt9AJIsyxRTWFOb5vSzrHzBZJKpI0yDnHVrVKhDm2t0p63Mz6Kzg57FqaovCY2XMKfmlsHtpnf7ukupLknPungvvwL5C0TNIeSb8Pa72MPwAA8YUjhAEAEGcozgAAxBmKMwAAcYbiDABAnKE4AwAQZyjOAADEGYozAABxhuIMAECc+f/YNPKndrEe3QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Cutcq36sS39S",
        "outputId": "8f19e1c5-0dd6-4cbb-cd1a-5499256df6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# grfico de perca\n",
        "run_hist_2.history.keys()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_2.history[\"accuracy\"], 'y', marker='.', label='Train Accuracy')\n",
        "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.plot(run_hist_2.history[\"val_accuracy\"], 'g', marker='.', label=\"Validation Accuracy\")\n",
        "ax.legend()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7e52c63510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}